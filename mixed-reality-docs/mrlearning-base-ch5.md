---
title: Серия руководств по началу работы, часть 6. Изучение дополнительных входных параметров
description: В рамках этого курса вы узнаете, как реализовать функцию распознавания лиц Azure в приложении смешанной реальности.
author: jessemcculloch
ms.author: jemccull
ms.date: 02/26/2019
ms.topic: article
keywords: mixed reality, unity, tutorial, hololens
ms.localizationpriority: high
ms.openlocfilehash: ec078015304e1cddc9b042fb5e94cf1904a302cb
ms.sourcegitcommit: 0a1af2224c9cbb34591b6cb01159b60b37dfff0c
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/14/2020
ms.locfileid: "79376091"
---
# <a name="6-exploring-advanced-input-options"></a>6. Изучение дополнительных входных параметров

В этом руководстве мы рассмотрим несколько вариантов расширенного ввода для HoloLens 2, в том числе голосовые команды, жесты сдвига и отслеживание взгляда.

## <a name="objectives"></a>Задачи

* Активировать события с помощью голосовых команд и ключевых слов.
* Применить отслеживаемые руки для сдвига текстур и трехмерных объектов.
* Использовать функцию отслеживания взгляда в HoloLens 2 для выбора объектов.

## <a name="enabling-voice-commands"></a>Включение голосовых команд
<!-- TODO: Consider changing to 'Enabling Speech Commands -->

В рамках этого раздела будет реализована речевая команда, которая позволяет пользователю воспроизвести звук на объекте Octa. Для этого вы создадите новую речевую команду и настроите событие, которое запускает нужное действие при произнесении ключевого слова для этой команды.

Для получения этого результата вам нужно выполнить следующие шаги:

1. Клонирование профиля по умолчанию для системы ввода.
2. Клонирование профиля по умолчанию для речевых команд.
3. Добавление новой речевой команды.
4. Добавление и настройка компонента "Speech Input Handler (Script)" (Обработчик речевого ввода — скрипт).
5. Реализация события ответа для речевой команды.

### <a name="1-clone-the-default-input-system-profile"></a>1. Клонирование профиля по умолчанию для системы ввода

В окне "Иерархия" выберите объект **MixedRealityToolkit**, затем в окне "Инспектор" выберите вкладку **Input** (Ввод) и клонируйте объект **DefaultHoloLens2InputSystemProfile**, чтобы заменить его собственным настраиваемым **профилем системы ввода**:

![mrlearning-base](images/mrlearning-base/tutorial5-section1-step1-1.png)

> [!TIP]
> Чтобы вспомнить, как правильно клонировать профили MRTK, воспользуйтесь инструкциями из раздела о [настройке Набора средств для смешанной реальности](mrlearning-base-ch2.md#how-to-configure-the-mixed-reality-toolkit-profiles-change-spatial-awareness-display-option).

### <a name="2-clone-the-default-speech-commands-profile"></a>2. Клонирование профиля по умолчанию для речевых команд

Разверните раздел **Speech** (Речь) и клонируйте **DefaultMixedRealitySpeechCommandsProfile**, чтобы заменить его собственным настраиваемым **профилем речевых команд**:

![mrlearning-base](images/mrlearning-base/tutorial5-section1-step2-1.png)

### <a name="3-create-a-new-speech-command"></a>3. Добавление новой речевой команды

В разделе **Speech Commands** (Речевые команды) щелкните **+ Add a New Speech Command** (Добавить голосовую команду), чтобы добавить новую речевую команду в конец списка существующих речевых команд, а затем в поле **Keyword** (Ключевое слово) введите подходящее слово или фразу, например **Play Music** (Воспроизвести музыку):

![mrlearning-base](images/mrlearning-base/tutorial5-section1-step3-1.png)

> [!TIP]
> Если у компьютера нет микрофона и вы хотите протестировать речевую команду с помощью имитации в редакторе, можно назначить этой команде код клавиши, чтобы активировать команду нажатием соответствующей клавиши.

### <a name="4-add-and-configure-the-speech-input-handler-script-component"></a>4. Добавление и настройка компонента "Speech Input Handler (Script)" (Обработчик речевого ввода — скрипт)

В окне "Иерархия" выберите объект **Octa** и добавьте в этот объект компонент **Speech Input Handler (Script)** (Обработчика речевого ввода — скрипт). Снимите флажок **Is Focus Required** (Требуется фокус), чтобы пользователю не нужно было смотреть на объект Octa для активации этой речевой команды:

![mrlearning-base](images/mrlearning-base/tutorial5-section1-step4-1.png)

### <a name="5-implement-the-response-event-for-the-speech-command"></a>5. Реализация события ответа для речевой команды

В компоненте "Speech Input Handler (Script)" (Обработчик речевого ввода — скрипт) нажмите небольшую кнопку **+** , чтобы добавить элемент keyword (ключевое слово) в соответствующий список:

![mrlearning-base](images/mrlearning-base/tutorial5-section1-step5-1.png)

Щелкните только что созданный элемент **Element 0** (Элемент 0), чтобы развернуть его. Затем в раскрывающемся списке **Keyword** (Ключевое слово) выберите ранее созданное ключевое слово **Play Music** (Воспроизвести музыку):

![mrlearning-base](images/mrlearning-base/tutorial5-section1-step5-2.png)

> [!NOTE]
> Ключевые слова в раскрывающемся списке указываются из списка речевых команд в профиле речевых команд.

Создайте новое событие **Response ()** , настройте получение этого события в объекте **Octa**, определите **AudioSource.PlayOneShot** в качестве действия для активации и назначьте подходящий звуковой клип в поле **Audio Clip** (Звуковой клип), например, MRTK_Gem:

![mrlearning-base](images/mrlearning-base/tutorial5-section1-step5-3.png)

> [!TIP]
> В разделе о [реализации события On Touch Started](mrlearning-base-ch4.md#4-implement-the-on-touch-started-event) вы можете освежить свои знания о реализации событий и назначении аудиоклипа.

## <a name="the-pan-gesture"></a>Жест сдвига

Жест сдвига для прокрутки содержимого движением пальца или руки. В рамках нашего примера вы сначала научитесь прокручивать двумерный пользовательский интерфейс, а затем дополните пример возможностью прокручивать коллекцию трехмерных объектов.

Для получения этого результата вам нужно выполнить следующие шаги:

1. Создание объекта Quad, который можно использовать для жеста сдвига.
2. Добавление компонента "Near Interaction Touchable (Script)" (Возможность касания при ближнем взаимодействии — скрипт).
3. Добавление компонента "Hand Interaction Pan Zoom (Script)" (Масштабирование сдвигом при взаимодействии рукой — скрипт).
4. Добавление двумерного содержимого для прокрутки.
5. Добавление трехмерного содержимого для прокрутки.
6. Добавление компонента "Move With Pan (Script)" (Смещение жестом сдвига — скрипт).

> [!NOTE]
> Компонент "Move With Pan (Script)" (Смещение жестом сдвига — скрипт) не входит в состав MRTK. Он был предоставлен с активами для этого руководства.

### <a name="1-create-a-quad-object-that-can-be-used-for-panning"></a>1. Создание объекта Quad, который можно использовать для жеста сдвига

Щелкните правой кнопкой мыши пустое место в окне "Иерархия" и выберите **Трехмерный объект** > **Quad**, чтобы добавить его в сцену. Присвойте ему подходящее имя, например **PanGesture**, и разместите его в подходящем расположении, например с координатами X = 0, Y = –0,2, Z = 2.

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step1-1.png)

> [!TIP]
> В разделе о [добавлении куба в сцену](mrlearning-base-ch2.md#2-add-a-cube-to-the-scene) вы можете освежить свои знания о добавлении примитивов Unity.

Как и при любом другом взаимодействии, для жеста сдвига требуется коллайдер. По умолчанию объект Quad имеет коллайдер сетки. Этот вариант нам подходит плохо, так как коллайдер сетки очень тонкий. Чтобы упростить взаимодействие пользователя с коллайдером, мы заменили коллайдер сетки блочным коллайдером.

Сохраняя выделение объекта PanGesture, щелкните значок **Параметры** компонента **Коллайдер сетки** и выберите команду **Удалить компонент**, чтобы удалить этот коллайдер сетки:

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step1-2.png)

В окне "Инспектор" нажмите кнопку **Добавить компонент**, чтобы добавить **блочный коллайдер**. Затем укажите для поля **Размер** значение Z = 0,15, чтобы увеличить толщину коллайдера.

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step1-3.png)

### <a name="2-add-the-near-interaction-touchable-script-component"></a>2. Добавление компонента "Near Interaction Touchable (Script)" (Возможность касания при ближнем взаимодействии — скрипт)

Оставляя выделенным объект **PanGesture**, добавьте компонент **Near Interaction Touchable (Script)** (Возможность касания при ближнем взаимодействии — скрипт). Нажмите кнопки **Fix Bounds** (Зафиксировать границы) и **Fix Center** (Зафиксировать центр) для компонента "Near Interaction Touchable (Script)" (Возможность касания при ближнем взаимодействии — скрипт), чтобы он совпадал с объектом BoxCollider:

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step2-1.png)

### <a name="3-add-the-hand-interaction-pan-zoom-script-component"></a>3. Добавление компонента "Hand Interaction Pan Zoom (Script)" (Масштабирование сдвигом при взаимодействии рукой — скрипт)

Сохраняя выделение объекта **PanGesture**, добавьте в этот объект PanGesture компонент **Hand Interaction Pan Zoom** (Script)" (Масштабирование сдвигом при взаимодействии рукой — скрипт). Установите флажок **Lock Horizontal** (Блокировка по горизонтали), чтобы разрешить только вертикальную прокрутку:

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step3-1.png)

### <a name="4-add-2d-content-to-be-scrolled"></a>4. Добавление двумерного содержимого для прокрутки

На панели "Проект" найдите материал **PanContent**, а затем щелкните его и перетащите в область свойства **Материал** для элемента 0 отрисовщика сетки для объекта **PanContent**:

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step4-1.png)

В окне "Инспектор" разверните добавленный компонент материала **PanContent**. Затем укажите для параметра **Tiling** (Мозаичное заполнение) значение Y = 0,5, чтобы оно совпадало со значением X, то есть отображалась квадратная плитка:

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step4-2.png)

Если теперь перейти в игровой режим, вы сможете протестировать прокрутку двумерного содержимого с помощью жеста панорамирования в имитации в редакторе:

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step4-3.png)

### <a name="5-add-3d-content-to-be-scrolled"></a>5. Добавление трехмерного содержимого для прокрутки

В окне "Иерархия" **создайте четыре куба** в качестве дочерних объектов для объекта **PanGesture**. Присвойте значению преобразования **Масштаб** координаты X = 0,15, Y = 0,15, Z = 0,15:

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step5-1.png)

Чтобы равномерно распределить эти кубы и сэкономить некоторое время, добавьте компонент **Grid Object Collection (Script)** (Коллекция объектов сетки — скрипт) в родительский объект кубов, т. е. в объект **PanGesture**. Затем настройте эту коллекцию объектов сетки следующим образом:

* Для параметра **Num Rows** (Число строк) установите значение 1, чтобы все кубы разместились в одном ряду.
* Для параметра **Cell Width** (Ширина ячейки) установите значение 0,25, чтобы задать расстояние между кубами в одном ряду.

Нажмите кнопку **Update Collection** (Обновить коллекцию), чтобы применить новую конфигурацию.

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step5-2.png)

### <a name="6-add-the-move-with-pan-script-component"></a>6. Добавление компонента "Move With Pan (Script)" (Смещение жестом сдвига — скрипт)

В окне "Иерархия"выберите объект **Cube**, а затем в окне "Инспектор" с помощью кнопки **Добавить компонент** добавьте компонент **Move With Pan (Script)** (Смещение при сдвиге — скрипт) к каждому кубу.

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step6-1.png)

> [!TIP]
> В разделе о [добавлении компонента "Manipulation Handler (Script)" (Обработчик манипуляций — скрипт) ко всем объектам](mrlearning-base-ch4.md#1-add-the-manipulation-handler-script-component-to-all-the-objects) вы можете освежить свои знания о выборе нескольких объектов в окне "Иерархия".

Выбрав все кубы, щелкните и перетащите объект **PanGesture** в поле **Pan Input Source** (Источник входа сдвига).

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step6-2.png)

> [!TIP]
> Компонент "Move With Pan (Script)" (Смещение при сдвиге — скрипт) в каждом кубе ожидает событие Pan Updated (Обновление сдвига) от компонента HandInteractionPanZoom (Script), размещенного в объекте PanGesture, который ранее был назначен как источник входных данных для сдвига, и соответствующим образом обновляет положение каждого куба.

В окне "Иерархия" выберите объект **PanGesture**, а затем в окне "Инспектор" **снимите** флажок **Mesh Renderer** (Отрисовщик сетки), чтобы отключить компонент отрисовщика сетки.

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step6-3.png)

Если теперь перейти в игровой режим, вы сможете протестировать прокрутку трехмерного содержимого с помощью жеста панорамирования в имитации в редакторе:

![mrlearning-base](images/mrlearning-base/tutorial5-section2-step6-4.png)

## <a name="eye-tracking"></a>Отслеживание взгляда

Из этого раздела вы узнаете, как включить отслеживание взгляда в нашем демонстрационном проекте. В рамках этого примера вы реализуете возможность медленно вращать каждый объект в коллекции 3DObjectCollection, когда на него смотрит пользователь. Кроме того, вы научитесь включать эффект звукового сигнала, когда просматриваемый объект выбирают с помощью действия касания или речевой команды.

Для получения этого результата вам нужно выполнить следующие шаги:

1. Добавление компонента Eye Tracking Target (Script) (Целевой объект отслеживания взгляда — скрипт) в целевые объекты.
2. Добавление компонента Eye Tracking Tutorial Demo (Script) (Демонстрация отслеживания взгляда для руководства — скрипт) в целевые объекты.
3. Реализация события While Looking At Target.
4. Реализация события On Selected.
5. Включение имитации отслеживания взгляда для имитации в редакторе.
6. Включение ввода с помощью взгляда в возможностях приложения проекта Visual Studio.

### <a name="1-add-the-eye-tracking-target-script-component-to-all-target-objects"></a>1. Добавление компонента Eye Tracking Target (Script) (Целевой объект отслеживания взгляда — скрипт) в целевые объекты

В окне "Иерархия" разверните объект **3DObjectCollection**. Выберите все его **дочерние объекты**. Затем в окне "Инспектор" с помощью кнопки **Добавить компонент** добавьте компонент **Eye Tracking Target (Script)** (Целевой объект отслеживания взгляда — скрипт) во все дочерние объекты:

![mrlearning-base](images/mrlearning-base/tutorial5-section3-step1-1.png)

Сохраняя выделение всех **дочерних объектов**, настройте компонент **Eye Tracking Target (Script)** (Целевой объект отслеживания взгляда — скрипт) следующим образом:

* Для параметра **Select Action** (Выберите действие) укажите значение **Select** (Выбор), чтобы определить действие "Выбор" при касании для этого объекта.
* Разверните раздел **Voice Select** (Голосовой выбор). Задайте для **размера** списка голосовых команд значение 1. Затем в новом списке измените **Element 0** (Элемент 0) на **Select** (Выбор), чтобы определить действие "Выбор" для речевой команды для этого объекта.

![mrlearning-base](images/mrlearning-base/tutorial5-section3-step1-2.png)

### <a name="2-add-the-eye-tracking-tutorial-demo-script-component--to-all-target-objects"></a>2. Добавление компонента Eye Tracking Tutorial Demo (Script) (Демонстрация отслеживания взгляда для руководства — скрипт) в целевые объекты

Сохраняя выбранными все **дочерние объекты**, с помощью кнопки **Добавить компонент** добавьте компонент **Eye Tracking Tutorial Demo (Script)** (Демонстрация отслеживания взгляда для руководства — скрипт) во все дочерние объекты.

![mrlearning-base](images/mrlearning-base/tutorial5-section3-step2-1.png)

> [!NOTE]
> Компонент Eye Tracking Target (Script) (Целевой объект отслеживания взгляда — скрипт) не входит в состав MRTK. Он был предоставлен с активами для этого руководства.

### <a name="3-implement-the-while-looking-at-target-event"></a>3. Реализация события While Looking At Target

В окне "Иерархия" выберите объект **Cheese**. Затем создайте новое событие **While Looking At Target ()** (При взгляде на целевой объект)ю Настройте получение этого события в объекте **Cheese** и определите **EyeTrackingTutorialDemo.RotateTarget** в качестве запускаемого действия:

![mrlearning-base](images/mrlearning-base/tutorial5-section3-step3-1.png)

**Повторно выполните** процесс для каждого из дочерних объектов коллекции 3DObjectCollection.

> [!TIP]
> В разделе об [обработке жестов и нажатий активных кнопок с помощью средства отслеживания руки](mrlearning-base-ch2.md#hand-tracking-gestures-and-interactable-buttons) вы можете освежить свои знания о реализации событий.

### <a name="4-implement-the-on-selected-event"></a>4. Реализация события On Selected

В окне "Иерархия" выберите объект **Cheese**. Затем создайте событие **On Selected ()** (При выборе). Настройте получение этого события в объекте **Cheese** и определите **EyeTrackingTutorialDemo.BlipTarget** в качестве запускаемого действия:

![mrlearning-base](images/mrlearning-base/tutorial5-section3-step4-1.png)

**Повторно выполните** процесс для каждого из дочерних объектов коллекции 3DObjectCollection.

### <a name="5-enable-simulated-eye-tracking-for-in-editor-simulations"></a>5. Включение имитации отслеживания взгляда для имитации в редакторе

В окне "Иерархия" выберите объект **MixedRealityToolkit**. Затем в окне "Инспектор" выберите вкладку **Input** (Ввод). Разверните раздел **Input Data Providers** (Поставщики данных ввода) и раздел **Input Simulation Service** (Служба имитации ввода). Клонируйте объект **DefaultMixedRealityInputSimulationProfile**, чтобы заменить его собственным настраиваемым **профилем имитации ввода**:

![mrlearning-base](images/mrlearning-base/tutorial5-section3-step5-1.png)

> [!TIP]
> Чтобы вспомнить, как правильно клонировать профили MRTK, воспользуйтесь инструкциями из раздела о [настройке Набора средств для смешанной реальности](mrlearning-base-ch2.md#how-to-configure-the-mixed-reality-toolkit-profiles-change-spatial-awareness-display-option).

В разделе **Eye Simulation** (Имитация взгляда) установите флажок **Simulate Eye Position** (Имитировать положение глаз), чтобы включить имитацию отслеживания глаз:

![mrlearning-base](images/mrlearning-base/tutorial5-section3-step5-2.png)

Если теперь вы войдете в игровой режим, то сможете протестировать настроенные эффекты вращения и звукового сигнала, взглядом перемещая курсор к одному из объектов и используя взаимодействие рукой или речевую команду, чтобы выбрать объект:

![mrlearning-base](images/mrlearning-base/tutorial5-section3-step5-3.png)

> [!NOTE]
> Если вы не использовали DefaultHoloLens2ConfigurationProfile для клонирования настраиваемого профиля конфигурации МRТК, как описано в разделе о [настройке Набора средств для смешанной реальности](mrlearning-base-ch1.md#configure-the-mixed-reality-toolkit), отслеживание глаз может не работать в проекте и его придется включить. Дополнительные сведения см. в статье [о начале работы с отслеживанием взгляда в МRТК](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html).

### <a name="6-enable-gaze-input-in-the-visual-studio-projects-app-capabilities"></a>6. Включение ввода с помощью взгляда в возможностях приложения проекта Visual Studio

Прежде чем компилировать и развертывать приложение из Visual Studio на устройстве, необходимо включить в приложении проекта ввод с помощью взгляда. Дополнительные сведения см. в разделе о [тестировании приложения Unity на устройстве HoloLens 2](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#testing-your-unity-app-on-a-hololens-2).

## <a name="congratulations"></a>Поздравляем!

Вы успешно добавили в приложение базовые возможности отслеживания взгляда. Эти действия только открывают целый мир новых возможностей, которые предоставляет отслеживание взгляда. Кроме того, из этого руководстве вы узнали о других возможностях расширенного ввода, таких как голосовые команды и жесты сдвига.

[Следующий урок. 7. Создание примера приложения лунного модуля](mrlearning-base-ch6.md)
