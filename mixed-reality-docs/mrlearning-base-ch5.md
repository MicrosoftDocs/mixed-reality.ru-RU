---
title: Основной модуль обучения работе со смешанной реальностью. Расширенный ввод
description: В рамках этого курса вы узнаете, как реализовать функцию распознавания лиц Azure в приложении смешанной реальности.
author: jessemcculloch
ms.author: jemccull
ms.date: 02/26/2019
ms.topic: article
keywords: mixed reality, unity, tutorial, hololens
ms.openlocfilehash: f9da038fe917e9e45b386de54049d6aa312ecfba
ms.sourcegitcommit: b0b1b8e1182cce93929d409706cdaa99ff24fdee
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/23/2019
ms.locfileid: "68387775"
---
# <a name="6exploring-advanced-input-options"></a>6. Изучение дополнительных параметров ввода

В этом руководстве мы рассмотрим несколько дополнительных параметров ввода для HoloLens 2, включая использование речевых команд, жестов панорамирования и отслеживания глаз. 

## <a name="objectives"></a>Цели

- Активация событий с помощью голосовых команд и ключевых слов
- Использование отслеживаний руки для сдвига текстур и трехмерных объектов с помощью отслеживания руки
- Использование возможностей отслеживания взгляда HoloLens 2 для выбора объектов

## <a name="instructions"></a>Инструкция

### <a name="enabling-voice-commands"></a>Включение голосовых команд

В этом разделе мы будем реализовывать две команды Voice. Сначала мы предоставим возможность переключения панели диагностики частоты кадров, указав "переключить диагностику". Во-вторых, мы рассмотрим возможность воспроизведения звука с помощью команды Voice. Для начала мы рассмотрим профили и параметры МРТК, отвечающие за настройку команд Voice. 

1. В иерархии базовая сцена выберите Микседреалититулкит. На панели инспектора прокрутите вниз до пункта Параметры системы ввода. Дважды щелкните профиль системы ввода, чтобы открыть его. Клонировать входной профиль системы, чтобы сделать его доступным для изменения, как мы узнали на [занятии 1](mrlearning-base-ch1.md) 

В системном профиле входных данных существует множество параметров. Для голосовых команд выберите параметры голосовых команд. 

![Изображение "Урок 5, глава 1, шаг 2"](images/Lesson5_Chapter1_step2im.PNG)

2. Клонировать профиль голосовых команд, чтобы сделать его доступным для редактирования, как мы узнали на [занятии 1](mrlearning-base-ch1.md). Дважды щелкните профиль речевой команды, в котором можно увидеть ряд параметров. Полное описание этих параметров см. в [документации по мртк Speech](<https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Speech.html>). 

>Примечание. По умолчанию используется автоматический запуск. При необходимости это можно изменить на запуск вручную. Но в этом примере мы будем использовать его при автоматическом запуске. МРТК поставляется с несколькими голосовыми командами по умолчанию, такими как меню, переключение диагностики и переключить профилировщик. Мы будем использовать ключевое слово "переключить диагностику", чтобы включить и отключить счетчик частоты кадров диагностики. Также мы добавим новую голосовую команду, выполнив описанные ниже действия.
>
> ![Изображение "Урок 5, глава 1, примечание"](images/Lesson5_chapter1_noteim.PNG)

3. Добавьте новую голосовую команду. Чтобы добавить новую голосовую команду, нажмите кнопку + Добавить новую голосовую команду. Вы увидите новую строку, которая отображается под списком существующих голосовых команд. Введите здесь новую голосовую команду. В этом примере мы будем использовать команду "воспроизвести музыку".

>Совет. Можно также задать код клавиши для голосовой команды. Это позволяет голосовым командам активировать события при нажатии клавиши с клавиатуры.    

4. Добавьте возможность реагировать на голосовые команды. Выберите любой объект в иерархии базовых сцен, к которому не присоединены другие входные скрипты (например, без обработчика манипуляции). На панели инспектора нажмите кнопку Добавить компонент. Введите текст "обработчик речевого ввода".

   ![Lesson5 Chapter1 Step4im](images/Lesson5_chapter1_step4im.PNG)

   

По умолчанию вы увидите два флажка. Один из них — флажок является обязательным для фокуса. Это означает, что при указании объекта с помощью указателя--глаза-взгляда, головного взгляда, контроллера-взгляда или руки-взгляда будет активирована команда Voice. Снимите этот флажок, чтобы пользователю не нужно было просматривать объект, чтобы использовать команду Voice.

5. Добавьте возможность реагировать на голосовую команду. Для этого нажмите кнопку "+" в обработчике речевого ввода и выберите ключевое слово, на которое нужно ответить.

   > Примечание. Эти ключевые слова заполняются из профиля, который вы редактировали на предыдущем шаге.

![Изображение "Урок 5, глава 1, шаг 5"](images/Lesson5_chapter1_step5im.PNG)

6. Рядом с ключевым словом, вы увидите раскрывающееся меню. Выберите переключатель переключить диагностику, чтобы каждый раз, когда пользователь говорит о фразе "переключить диагностику", он активирует действие. Обратите внимание, что может потребоваться развернуть элемент 0, нажав стрелку рядом с ним.

![Изображение "Урок 5, глава 1, шаг 6"](images/Lesson5_chapter1_step6im.PNG)

7. Добавьте демонстрационный сценарий управления диагностикой, чтобы включить и отключить диагностику счетчика кадров. Для этого нажмите кнопку "добавить компонент" и выполните поиск скрипта "демонстрационные элементы управления диагностики" и добавьте его из меню. Этот скрипт можно добавить в любой объект. Но для простоты мы добавим его к тому же объекту, что и обработчик речевого ввода. 

   > Примечание. Этот сценарий включен только в эти модули и не включается в исходный МРТК.

![Изображение "Урок 5, глава 1, шаг 7"](images/Lesson5_chapter1_step7im.PNG)

8. Добавьте новый ответ в обработчик речевого ввода. Для этого нажмите кнопку +, расположенную под заметкой ответ () (отмечена зеленой стрелкой на рисунке выше).

![Изображение "Урок 5, глава 1, шаг 7"](images/Lesson5_chapter1_step8.PNG)

9. Перетащите объект, содержащий скрипт Diagnostics Controls, в новый ответ, созданный на шаге 8.
    ![Изображение "Урок 5, глава 1, шаг 9"](images/Lesson5_chapter1_step9im.PNG)

10. Теперь выберите раскрывающийся список "без функции" и выберите элемент управления "демонстрационный ролик". Затем выберите функцию "вкл. переключить диагностику ()", которая включает и выключает диагностику.  ![Изображение "Урок 5, глава 1, шаг 10"](images/Lesson5_chapter1_step10im.PNG)
    
> Обратите внимание на то, что перед сборкой приложения для устройства необходимо включить параметры микрофона. Для этого щелкните файл, перейдите в раздел параметры сборки, параметры проигрывателя и убедитесь, что включена возможность использования микрофона.

Далее мы добавим возможность воспроизведения звукового файла из голосовой команды с помощью объекта восьмиядерными. На [занятии 4](mrlearning-base-ch4.md) мы добавили возможность воспроизводить аудиоклип из объекта восьмиядерными. Теперь мы применим тот же аудиоисточник для голосовой команды воспроизведения музыки.

11. Выберите объект восьмиядерными в иерархии базовых сцен.

12. Добавьте еще один обработчик речевого ввода (повторите шаги 4 и 5), но с объектом восьмиядерными. 

13. Вместо добавления команды переключить диагностические голоса из шага 6 добавьте команду воспроизвести музыку, как показано на рисунке ниже.
    
     ![Изображение "Урок 5, глава 1, шаг 13"](images/Lesson5_chapter1_step13im.PNG)
    
    
    
14. Как и в случае с шагами 8 и 9, добавьте новый ответ и перетащите объект восьмиядерными в пустой слот отклика.

15. Выберите раскрывающееся меню без функции. Затем выберите источник аудио и выберите Плайонешот (аудиоклип).

![Изображение "Урок 5, глава 1, шаг 15"](images/Lesson5_chapter1_step15im.PNG)

16. В этом примере мы будем использовать один и тот же аудиоклип из [занятия 4](mrlearning-base-ch4.md). Перейдите на панель проекта, выполните поиск по слову "MRTK_Gem", а затем перетащите его в ячейку "источник звука", как показано на рисунке ниже. Теперь приложение будет отвечать на команды Voice "переключить диагностику", чтобы переключить панель счетчиков частоты кадров и воспроизвести музыку для воспроизведения песни MRTK_Gem.
     ![Изображение "Урок 5, глава 1, шаг 16"](images/Lesson5_chapter1_step16im.PNG)


### <a name="the-pan-gesture"></a>Жест сдвига 

В этом разделе будет показано, как использовать жест панорамирования. Это удобно для прокрутки с помощью пальца или руки для прокрутки содержимого. Кроме того, можно использовать жест панорамирования для поворота объектов, циклического перемещения по коллекции трехмерных объектов или даже для прокрутки двухмерного пользовательского интерфейса. Также будет рассмотрено использование жеста панорамирования для деформации текстуры и перемещения коллекции трехмерных объектов.

1. Создайте объект Quad. В иерархии базовых сцен щелкните правой кнопкой мыши, выберите "трехмерный объект" и выберите "четыре".

![Изображение "Урок 5, глава 2, шаг 2"](images/Lesson5_chapter2_step2im.PNG)

2. Поместите Quad в любое удобное место. В нашем примере мы устанавливаем x = 0, y = 0 и z = 1,5 за пределы камеры для удобного расположения из HoloLens 2.

   > Примечание. Если четыре блока или находятся в начале любого содержимого из предыдущих уроков, не забудьте переместить его так, чтобы он не блокировал другие объекты.

3. Примените материал к объекту Quad. Именно этот материал мы будет прокручивать жестом сдвига. 

![Изображение "Урок 5, глава 2, шаг 3"](images/Lesson5_chapter2_step3im.PNG)

4. На панели Проекты введите в поле поиска "панорамирование содержимого". Перетащите этот материал на объект Quad, размещенный в сцене. 

> Примечание. Материал для панорамного содержимого не включается в МРТК, но ресурс в пакете активов этого модуля, как он импортируется на предыдущих занятиях. 

> Примечание. Когда вы добавите элемент Pan content (Сдвиг содержимого), он может выглядеть растянутым. Это можно исправить, настроив для объекта Quad значения размера x, y и z так, чтобы его внешний вид вас устроил.

Чтобы использовать жест сдвига, для объекта нужно добавить коллайдер. Возможно, вы заметили, что объект Quad уже имеет сетчатый коллайдер. Но этот вариант нам подходит плохо, так как он очень тонкий и его трудно выделять. Мы рекомендуем заменить сетчатый коллайдер на прямоугольный.

5. Щелкните правой кнопкой мыши объект, расположенный на самом четыре, на панели инспектора. Затем удалите его, нажав кнопку удалить компонент.
    ![Изображение "Урок 5, глава 2, шаг 5"](images/Lesson5_chapter2_step5im.PNG)
6. Теперь добавьте поле "конфликты", нажав кнопку "добавить компонент" и выполнив поиск по слову "Box конфликтует". по умолчанию добавлено слишком тонкое окно "конфликты", поэтому нажмите кнопку "Изменить", чтобы изменить его. Пока эта кнопка остается в нажатом состоянии, вы можете изменять значения размера x, y и z для любых элементов в редакторе сцен. В нашем примере мы хотим расширить прямоугольный коллайдер, чтобы он немного выходил за пределы объекта Quad. В редакторе сцен перетащите прямоугольный коллайдер с обратной стороны наружу (как на рисунке ниже). Это позволяет пользователю не только использовать палец, но и прокручивать их все. 
    ![Изображение "Урок 5, глава 2, шаг 6"](images/Lesson5_chapter2_step6im.PNG)
7. Добавьте интерактивность. Так как мы хотим взаимодействовать с четырьмя прямыми, мы хотим использовать компонент, который мы использовали с помощью технологии близкого взаимодействия, которая использовалась на занятии 4 для воспроизведения музыки из объекта восьмиядерными. Нажмите кнопку Добавить компонент и выполните поиск по фразе "приближается к сенсорному взаимодействию" и выберите его, как показано на рисунке ниже. 

8. Добавьте возможность распознавания жеста сдвига. Нажмите кнопку Добавить компонент и введите "рука с руки". у вас будет возможность выбрать один луч (что позволит вам сдвигаться с расстояния) и указатель пальца. Для нашего примера давайте оставим указательный палец. 
    ![Изображение "Урок 5, глава 2, шаги 7 и 8"](images/Lesson5_chapter2_step7-8im.PNG)

![Изображение "Урок 5, глава 2, шаг 8"](images/Lesson5_chapter2_step8im.PNG)

9. В скрипте «рука руки» флажки заблокировать горизонтальный и зафиксировать вертикальные блокировки блокируют перемещения соответственно. Параметры текстуры для переноса позволяют текстуре (сопоставление текстур) следовать перемещениям панорамы пользователя. В этом примере вы установите флажок. Также имеется активная скорость, которая, если не установлен, жест панорамирования работать не будет. Установите этот флажок. Теперь у вас будет четыре типа с поддержкой PAN.

   

   Теперь мы изучим сдвиг трехмерных объектов. 

10. Щелкните правой кнопкой мыши объект Quad, выберите трехмерный объект и щелкните куб. Измените масштаб куба примерно до значений x=0,1, y=0,1 и z=0,1. Скопируйте этот куб три раза, щелкнув правой кнопкой мыши куб и нажав кнопку дублировать, либо нажав клавиши Ctrl/Command D. пропустить их равномерно. Сцена должна выглядеть примерно так, как показано на рисунке ниже.

![Изображение "Урок 5, глава 2, шаг 10"](images/Lesson5_chapter2_step10im.PNG)







11. Выделите их еще раз, а затем в скрипте панорамирования взаимодействия с рукой задайте действия Pan для каждого из кубов. В разделе приемники событий Pan необходимо указать число объектов, получающих событие. Так как имеется четыре Куба, введите "4" и нажмите клавишу ВВОД. Должны появиться четыре пустых поля.


![Изображение "Урок 5, глава 2, шаг 11"](images/Lesson5_chapter2_step11im.PNG)



12. Перетащите каждый из кубов в каждый из пустых слотов элементов.
     ![Изображение "Урок 5, глава 2, шаг 12"](images/Lesson5_chapter2_step12im.PNG)
    
13. Добавьте сценарий перемещения с помощью сценария Pan для всех кубов, нажав и удерживая клавишу Control/Command, и выбрав каждый объект. На панели инспектора щелкните Добавить компонент и выполните поиск по слову "переместить с помощью Pan". Щелкните скрипт, и он будет добавлен в каждый куб. Теперь трехмерные объекты будут перемещаться с помощью жеста сдвига. Если вы удалите отрисовку сетки для объекта Quad, он станет невидимым при прокручивании списка трехмерных объектов жестом сдвига.

### <a name="eye-tracking"></a>Отслеживание взгляда

В этом разделе мы рассмотрим, как включить отслеживание взглядов в нашем демонстрационном ролике. Мы будем медленно вращать элементы трехмерного меню, когда они газед с глазом глаза. Мы также будем активировать специальный эффект при выборе элемента, на который наведен взгляд.

1. Убедитесь, что профили МРТК настроены правильно. На момент написания этой статьи в конфигурации профиля набора средств для смешанной реальности по умолчанию не включается отслеживание взгляда. Чтобы добавить возможности отслеживания взгляда, следуйте инструкциям в разделе "Настройка профилей МРТК, необходимых для отслеживания взгляда", как описано в [документации по набору средств для смешанной реальности](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#setting-up-the-mrtk-profiles-required-for-eye-tracking  ). Убедитесь, что отслеживание отслеживания взгляда правильно настроено, выполнив все оставшиеся действия, описанные в приведенной выше ссылке на документацию, в том числе включение отслеживания взгляда в Газепровидер (компонент, присоединенный к камере) и включение имитации отслеживания взгляда в редакторе Unity. Обратите внимание, что будущие версии МРТК могут включать отслеживание глаз по умолчанию.

    По указанной выше ссылке вы найдете краткие инструкции по выполнению следующих действий:

    - Создание поставщика данных для глазного взгляда для использования в профиле МРТК
    - включение отслеживания взгляда в поставщике данных о направлении взгляда;
    - Настройка симуляции отслеживания взгляда в редакторе
    - редактирование возможностей решения Visual Studio, чтобы разрешить отслеживание взгляда в скомпилированном приложении.

2. Добавьте компонент отслеживания взгляда в целевые объекты. Чтобы объект мог реагировать на события взгляда на глаза, необходимо добавить компонент Эйетраккингтаржет для каждого объекта, с которым мы хотим взаимодействовать, с помощью взгляда глаз. Добавьте этот компонент в каждый из девяти трехмерных объектов, которые входят в коллекцию сетки. Совет. Выберите несколько элементов в иерархии, чтобы добавить компонент Эйетраккингтаржет.
    ![Урок 5, глава 3, шаг 2](images/Lesson5Chapter3Step2.JPG)

3. Теперь мы добавим скрипт EyeTrackingTutorialDemo, чтобы реализовать интересные возможности взаимодействия. Сценарий Эйетраккингтуториалдемо входит в состав этого репозитория серии руководств. Он не включен по умолчанию в набор средств Mixed Reality. Для каждого трехмерного объекта в коллекции сетки добавьте скрипт Эйетраккингтуториалдемо, выполнив поиск компонента в меню Добавление компонента.
   ![Урок 5, глава 3, шаг 3](images/Lesson5Chapter3Step3.JPG)

4. Поверните объект, удерживая взгляд на целевом объекте. Мы хотим настроить трехмерный объект для прокрутки, пока не просматриваете его. Для этого вставьте новое поле в раздел при просмотре целевого объекта () компонента Эйетраккингтаржет, как показано на рисунке ниже. 

![Урок 5, глава 3, шаг 4a](images/Lesson5Chapter3Step4a.JPG)
![Урок 5, глава 3, шаг 4b](images/Lesson5Chapter3Step4b.JPG)



В поле только что создано добавьте текущий объект Game в пустое поле и выберите Эйетраккингтуториалдемо > Ротатетаржет (), как показано на рисунке ниже. Теперь трехмерный объект будет вращаться, когда система отслеживания взгляда определит, что пользователь смотрит на него. 

5. Добавьте возможность "кратковременного сбоя Target", которая находится в газед при выборе воздушного касания или произнесения команды "Select". Как и на шаге 4, мы хотим активировать Эйетраккингтуториалдемо > Блиптаржет (), назначив его полю SELECT () объекта Game () в компоненте Эйетраккингтаржет, как показано на рисунке ниже. После этого вы заметите небольшое кратковременного сбоя в игровом объекте каждый раз, когда вы активируете действие SELECT, например воздушный разговор или голосовую команду "Select". 
    ![Урок 5, глава 3, шаг 5](images/Lesson5Chapter3Step5.JPG)
6. Убедитесь, что возможности отслеживания взгляда правильно настроены, прежде чем выполнять компиляцию в HoloLens 2. На момент написания этой статьи Unity еще не может установить входные данные взгляда для возможностей отслеживания взгляда. Установка этой возможности необходима для отслеживания взгляда в HoloLens 2. Выполните эти инструкции из документации по набору средств для смешанной реальности, чтобы включить возможность ввода взглядом: https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#testing-your-unity-app-on-a-hololens-2 


### <a name="congratulations"></a>Поздравляем! 
Вы успешно добавили базовые возможности отслеживания взгляда в приложение. Эти действия только открывают целый мир новых возможностей, которые предоставляет отслеживание взгляда. Эта глава также завершает занятие 5, где мы узнали о расширенных функциях ввода, таких как речевые команды, жесты панорамирования и отслеживание глаз. 

[Следующий урок. Пример сборки лунного модуля](mrlearning-base-ch6.md)

