---
title: Учебники по началу работы — 6. Просмотр дополнительных параметров ввода
description: В рамках этого курса вы узнаете, как реализовать функцию распознавания лиц Azure в приложении смешанной реальности.
author: jessemcculloch
ms.author: jemccull
ms.date: 02/26/2019
ms.topic: article
keywords: mixed reality, unity, tutorial, hololens
ms.openlocfilehash: 5599fe48f62a35d1dc02ce30fb7858fd74e87685
ms.sourcegitcommit: 2cf3f19146d6a7ba71bbc4697a59064b4822b539
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/12/2019
ms.locfileid: "73926538"
---
# <a name="6-exploring-advanced-input-options"></a>6. Изучение дополнительных параметров ввода

В этом руководстве рассматриваются несколько дополнительных параметров ввода для HoloLens 2, включая использование речевых команд, жестов панорамирования и отслеживания глаз. 

## <a name="objectives"></a>Задачи

- Активация событий с помощью голосовых команд и ключевых слов
- Использование отслеживаний руки для сдвига текстур и трехмерных объектов с помощью отслеживания руки
- Использование возможностей отслеживания взгляда HoloLens 2 для выбора объектов

## <a name="instructions"></a>Инструкция

### <a name="enabling-voice-commands"></a>Включение голосовых команд

В этом разделе реализуются две команды Voice. Во-первых, возможность включения и выключения панели диагностики частоты кадров появилась при произнесении "переключить диагностику". Во-вторых, просматривается возможность воспроизведения звука с голосовыми командами. Сначала просматриваются профили и параметры МРТК, отвечающие за настройку голосов.

1. В иерархии Басесцене выберите Микседреалититулкит. Затем на панели инспектора выберите входные данные и нажмите кнопку малый клон слева от Дефаултмикседреалитинпутсистемпрофиле, чтобы открыть всплывающее окно профиля клона. Во всплывающем окне щелкните клонировать, чтобы создать новый профиль Микседреалитинпутсистемпрофиле.

    ![mrlearning-Base-CH5-1-step1a. png](images/mrlearning-base-ch5-1-step1a.png)

    Это также приведет к автоматическому заполнению Микседреалититулкитконфигуратионпрофиле с помощью вновь созданного Микседреалитинпутсистемпрофиле.

    ![mrlearning-Base-CH5-1-step1b. png](images/mrlearning-base-ch5-1-step1b.png)

2. В системном профиле входных данных существует множество параметров. Для голосовых команд разверните раздел речь и выполните тот же процесс, что и на предыдущем шаге, чтобы клонировать Дефаултмикседреалитиспичкоммандспрофиле и заменить его собственной редактируемой копией.

    ![mrlearning-Base-CH5-1-step2. png](images/mrlearning-base-ch5-1-step2.png)

    В профиле голосовых команд можно заметить ряд параметров. Полное описание этих параметров см. в [документации по мртк Speech](<https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Speech.html>).

    По умолчанию используется автоматический запуск. При необходимости это можно изменить на запуск вручную. Но для этого примера не заключайте его на автоматический запуск. МРТК поставляется с несколькими голосовыми командами по умолчанию, такими как меню, переключение диагностики и переключение профилировщика. Мы будем использовать ключевое слово "переключить диагностику" для включения и отключения счетчика частоты кадров диагностики. Также мы добавим новую голосовую команду, выполнив описанные ниже действия.

3. Добавьте новую голосовую команду. Для этого нажмите кнопку + Добавить новую голосовую команду. Вы увидите новую строку, которая отображается под списком существующих команд Voice. Введите команду Voice, которую вы хотите использовать. В этом примере используйте команду "воспроизвести музыку".

    ![mrlearning-Base-CH5-1-step3. png](images/mrlearning-base-ch5-1-step3.png)

    >[!NOTE]
    >Можно также задать код клавиши для голосовой команды. Это позволяет голосовым командам активировать события при нажатии клавиши с клавиатуры.

4. Добавьте возможность реагировать на голосовые команды. Выберите любой объект в иерархии Басесцене, к которому не присоединены другие входные сценарии, например объект игры Микседреалитиплайспаце. На панели инспектора щелкните Добавить компонент, выполните поиск по слову "речь" и выберите Скрипт обработчика речевого ввода.

    ![mrlearning-Base-CH5-1-step4. png](images/mrlearning-base-ch5-1-step4.png)

    По умолчанию вы увидите два флажка. Один из них — флажок является обязательным для фокуса. Таким образом, при условии, что вы указываете на объект с помощью лучей-взгляда, Head-взгляда, Контролера или руки-взгляда, будет активирована команда Voice. Снимите этот флажок, чтобы пользователю не нужно было просматривать объект, чтобы использовать команду Voice.

5. Добавьте возможность реагировать на голосовую команду. Для этого нажмите кнопку "+" в обработчике речевого ввода.

    ![mrlearning-Base-CH5-1-step5. png](images/mrlearning-base-ch5-1-step5.png)

6. Рядом с ключевым словом, вы увидите раскрывающееся меню. Выберите переключатель переключить диагностику, чтобы каждый раз, когда пользователь говорит о нажатии фразы "переключить диагностику", он активирует действие. Обратите внимание, что может потребоваться развернуть элемент 0, нажав стрелку рядом с ним.

    ![mrlearning-Base-CH5-1-step6. png](images/mrlearning-base-ch5-1-step6.png)

    >[!NOTE]
    >Эти ключевые слова заполняются в зависимости от профиля, измененного на шаге 3.

7. Добавьте сценарий контроля системных голосов системы диагностики, чтобы включить и отключить диагностику счетчика кадров. Для этого нажмите кнопку "добавить компонент", выполните поиск скрипта "контрольные элементы системы диагностики" и добавьте его в меню. Его можно добавить к любому объекту, но для простоты мы применим тот же объект, где размещен обработчик голосового ввода.

    ![mrlearning-Base-CH5-1-Step7. png](images/mrlearning-base-ch5-1-step7.png)

8. Добавьте новый ответ в обработчик речевого ввода. Для этого щелкните значок "+", чтобы добавить новый ответ в список ответов.

    ![mrlearning-Base-CH5-1-Step8. png](images/mrlearning-base-ch5-1-step8.png)

9. Перетащите объект с помощью скрипта системы управления "Диагностика системных голосов" в новый ответ, созданный на предыдущем шаге.

    ![mrlearning-Base-CH5-1-step9. png](images/mrlearning-base-ch5-1-step9.png)

10. Щелкните раскрывающийся список функций (там, где нет функции), а затем щелкните элемент Диагностика системных голосов и выберите функцию Тоггледиагностикс (), которая включает и выключает диагностику.

    ![mrlearning-Base-CH5-1-step10. png](images/mrlearning-base-ch5-1-step10.png)

    >[!IMPORTANT]
    > Перед началом сборки на устройстве необходимо включить параметры MIC. Для этого щелкните файл и выберите параметры сборки, параметры проигрывателя и убедитесь, что включена возможность использования микрофона.

    Затем добавьте возможность воспроизведения звукового файла из голосовой команды с помощью объекта восьмиядерными. На [занятии 4 вы](mrlearning-base-ch4.md) уже добавили возможность воспроизводить аудиоклип из объекта восьмиядерными. Теперь мы применим тот же аудиоисточник для голосовой команды воспроизведения музыки.

11. Выберите объект восьмиядерными в иерархии Басесцене.

12. Добавьте еще один обработчик речевого ввода (повторите шаги 4 и 5), но с объектом восьмиядерными.

13. Вместо добавления команды переключить диагностические голоса из шага 6 добавьте команду воспроизвести музыку, как показано на рисунке ниже.

    ![mrlearning-Base-CH5-1-step13. png](images/mrlearning-base-ch5-1-step13.png)

14. Как и в случае с шагами 8 и 9, добавьте новый ответ и перетащите в него объект восьмиядерными, который содержит на нем сценарий управления системой диагностики, в пустой слот отклика.

15. Выберите раскрывающееся меню без функции. Затем выберите источник аудио, а затем — Плайонешот (аудиоклип).

    ![Изображение "Урок 5, глава 1, шаг 15"](images/Lesson5_chapter1_step15im.PNG)

16. В этом примере мы будем использовать один и тот же аудиоклип из [занятия 4](mrlearning-base-ch4.md). Перейдите на панель проекта, выполните поиск "MRTK_Gem" аудиоклипа и перетащите его в слот источника аудио, как показано на рисунке ниже. Теперь приложение будет отвечать на команды Voice "переключить диагностику", чтобы переключить панель счетчиков частоты кадров и воспроизвести музыку для воспроизведения MRTK_Gem песни.

    ![Lesson5 Chapter1 Step16im](images/Lesson5_chapter1_step16im.PNG)

### <a name="the-pan-gesture"></a>Жест сдвига

В этом разделе вы узнаете, как использовать жест панорамирования. Это удобно для прокрутки с помощью пальца или руки для прокрутки содержимого. Жест панорамирования также можно использовать для поворота объектов, перемещения по коллекции трехмерных объектов или даже для прокрутки двухмерного пользовательского интерфейса. <!--TMP You will also learn how to use the pan gesture to warp a texture, and how to move a collection of 3D objects.-->

1. Создайте объект Quad. В иерархии Басесцене щелкните правой кнопкой мыши и выберите «объемный объект», а затем «четыре».

    ![Изображение "Урок 5, глава 2, шаг 2"](images/Lesson5_chapter2_step2im.PNG)

2. Перемещайте четыре, если это необходимо. В нашем примере мы устанавливаем x = 0, y = 0 и z = 1,5 за пределы камеры для удобного расположения из HoloLens 2.

    >[!NOTE]
    >Если четыре блока или находятся в начале любого содержимого из предыдущих уроков, не забудьте переместить его так, чтобы он не блокировал другие объекты.

3. Примените материал к объекту Quad. Этот материал будет прокручиваться с помощью жеста панорамирования.

    ![Изображение "Урок 5, глава 2, шаг 3"](images/Lesson5_chapter2_step3im.PNG)

4. На панели проекты в поле поиска введите "панорамирование содержимого". Перетащите этот материал на четыре материала в сцене.

    >[!NOTE]
    >Материал для панорамного содержимого не включается в МРТК, но ресурс в пакете активов этого модуля, как он импортируется на предыдущих занятиях.

    >[!NOTE]
    >Когда вы добавите элемент Pan content (Сдвиг содержимого), он может выглядеть растянутым. Это можно исправить, настроив для объекта Quad значения размера x, y и z так, чтобы его внешний вид вас устроил.

    Чтобы использовать жест сдвига, для объекта нужно добавить коллайдер. Возможно, вы заметили, что объект Quad уже имеет сетчатый коллайдер. Но этот вариант нам подходит плохо, так как он очень тонкий и его трудно выделять. Мы рекомендуем заменить сетчатый коллайдер на прямоугольный.

5. Щелкните правой кнопкой мыши объект, расположенный на самом четыре, на панели инспектора. Затем удалите его, нажав кнопку удалить компонент.

    ![Lesson5 Chapter2 Step5im](images/Lesson5_chapter2_step5im.PNG)

6. Теперь добавьте поле "конфликты", нажав кнопку Добавить компонент и выполнив поиск по слову "Box конфликтует". Добавленное по умолчанию окно конфликтует по-прежнему является слишком узким, поэтому для изменения нажмите кнопку "Изменить". Пока эта кнопка остается в нажатом состоянии, вы можете изменять значения размера x, y и z для любых элементов в редакторе сцен. В нашем примере мы хотим расширить прямоугольный коллайдер, чтобы он немного выходил за пределы объекта Quad. В редакторе сцен перетащите прямоугольный коллайдер с обратной стороны наружу (как на рисунке ниже). Это позволяет пользователю не только использовать палец, но и прокручивать их все.

    ![Lesson5 Chapter2 Step6im](images/Lesson5_chapter2_step6im.PNG)

7. Добавьте интерактивность. Так как мы хотим взаимодействовать с четырьмя прямыми, мы хотим использовать компонент, который мы использовали с помощью технологии близкого взаимодействия, которая использовалась на занятии 4 для воспроизведения музыки из объекта восьмиядерными. Щелкните Добавить компонент, выполните поиск по фразе "приближается к сенсорному взаимодействию" и выберите его, как показано на рисунке ниже.

    ![mrlearning-Base-CH5-2-step7a. png](images/mrlearning-base-ch5-2-step7a.png)

    Если вы видите желтое предупреждение о границах и (или) центре, не соответствующих размеру и/или центру Боксколлидер, щелкните кнопки исправления и/или центр исправлений, чтобы обновить значения центров и границ.

    ![mrlearning-Base-CH5-2-step7b. png](images/mrlearning-base-ch5-2-step7b.png)

8. Добавьте возможность распознавания жеста сдвига. Нажмите кнопку Добавить компонент, введите "взаимодействие с руки" в поле поиска и добавьте компонент скрипта "действие" для действия "рука".

    ![mrlearning-Base-CH5-2-step8a. png](images/mrlearning-base-ch5-2-step8a.png)

    И с этим у вас есть четыре типа с поддержкой PAN.

    Как видите, компонент «рука» в области «взаимодействие» имеет различные настройки, как необязательное упражнение.

    ![mrlearning-Base-CH5-2-step8b. png](images/mrlearning-base-ch5-2-step8b.png)

<!--TMP
   Next, we will learn how to pan 3D objects. 

10. Right-click the quad object, select 3D object and click Cube. Scale the cube so that it’s roughly x = 0.1, y = 0.1 and z = 0.1. Copy that cube three times by right-clicking the cube and pressing duplicate, or by pressing control/command D. Space them out evenly. Your scene should look similar to the image below.

![Lesson5 Chapter2 Step10im](images/Lesson5_chapter2_step10im.PNG)

11. Select the quad again and under the hand interaction pan script, set the pan actions to each of the cubes. Under Pan Event Receivers, we want to specify the number of objects receiving the event. Since there are four cubes, type “4” and press Enter. Four empty fields should appear.

![Lesson5 Chapter2 Step11im](images/Lesson5_chapter2_step11im.PNG)

12. Drag each of the cubes into each of the empty element slots.
     ![Lesson5 Chapter2 Step12im](images/Lesson5_chapter2_step12im.PNG)
    
13. Add the Move with Pan script to all of the cubes by pressing and holding control/command and select each object. From the Inspector panel, click Add Component and search for “move with pan.” Click the script and it is added to each cube. Now the 3D objects will move with your pan gesture. If you remove the mesh render on your quad, you should now have an invisible quad where you can pan through a list of 3D objects.
-->

### <a name="eye-tracking"></a>Отслеживание взгляда

В этом разделе мы рассмотрим, как включить отслеживание взглядов в нашем демонстрационном ролике. Мы будем медленно вращать элементы трехмерного меню, когда они газед с глазом глаза. Мы также будем активировать специальный эффект при выборе элемента, на который наведен взгляд.

1. Убедитесь, что профили МРТК правильно настроены для отслеживания взгляда. Чтобы сделать это, перейдите к разделу [Приступая к работе с отслеживанием взглядов в](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html) инструкциях мртк и убедитесь, что отслеживание отслеживания взгляда правильно настроено, просмотрев шаги в разделе [Настройка отслеживания взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#setting-up-eye-tracking-step-by-step) . Выполните все оставшиеся действия в документации.

    >[!NOTE]
    >Если вы использовали DefaultHoloLens2InputSystemProfile, как описано в уроке [Настройка набора средств смешанной реальности](https://docs.microsoft.com/windows/mixed-reality/mrlearning-base-ch1#configure-the-mixed-reality-toolkit) , для клонирования настраиваемого профиля конфигурации мртк в проекте Unity по умолчанию включено отслеживание взгляда, но по-прежнему необходимо настроить симуляцию отслеживания взгляда для редактора Unity и настроить Visual Studio для разрешения отслеживания взгляда для сборки.

    По указанной выше ссылке вы найдете краткие инструкции по выполнению следующих действий:

    - Создание поставщика данных взгляда на Windows Mixed Reality для использования в профиле МРТК
    - Включение отслеживания взгляда в поставщике взгляда, присоединенном к камере
    - Настройка симуляции отслеживания взгляда в редакторе Unity
    - редактирование возможностей решения Visual Studio, чтобы разрешить отслеживание взгляда в скомпилированном приложении.

2. Добавьте компонент отслеживания взгляда в целевые объекты. Чтобы объект мог реагировать на события взгляда на глаза, необходимо добавить компонент Эйетраккингтаржет для каждого объекта, с которым мы хотим взаимодействовать, с помощью взгляда глаз. Добавьте этот компонент в каждый из девяти трехмерных объектов, которые входят в коллекцию сетки.

    >[!TIP]
    >Можно использовать клавиши Shift и CTRL, чтобы выбрать несколько элементов в иерархии сцены, а затем добавить компонент Эйетраккингтаржет.

    ![Lesson5 Chapter3 шаг 2](images/Lesson5Chapter3Step2.JPG)

3. Далее мы добавим сценарий Эйетраккингтуториалдемо для некоторых интересных взаимодействий. Сценарий Эйетраккингтуториалдемо входит в состав этого репозитория серии руководств. Он не включен по умолчанию в набор средств Mixed Reality. Для каждого трехмерного объекта в коллекции сетки добавьте скрипт Эйетраккингтуториалдемо, выполнив поиск компонента в меню Добавление компонента.

   ![Lesson5 Chapter3 шаг 3](images/Lesson5Chapter3Step3.JPG)

4. Поверните объект, удерживая взгляд на целевом объекте. Мы хотим настроить трехмерные объекты для прокрутки, пока не просматриваете их. Для этого вставьте новое поле в раздел при просмотре целевого объекта () компонента Эйетраккингтаржет, как показано на рисунке ниже.

    ![Lesson5 Chapter3 Step4a](images/Lesson5Chapter3Step4a.JPG)

    В созданном поле добавьте текущий объект Game в пустое поле и выберите Эйетраккингтуториалдемо > Ротатетаржет (), как показано на рисунке ниже. Теперь трехмерный объект будет вращаться, когда система отслеживания взгляда определит, что пользователь смотрит на него.

    ![Lesson5 Chapter3 Step4b](images/Lesson5Chapter3Step4b.JPG)

5. Добавьте возможность "кратковременного сбоя Target", которая находится в газед при выборе воздушного касания или произнесения команды "Select". Как и на шаге 4, мы хотим активировать Эйетраккингтуториалдемо > Блиптаржет (), назначив его полю SELECT () объекта Game () в компоненте Эйетраккингтаржет, как показано на рисунке ниже. После этого вы заметите небольшое кратковременного сбоя в игровом объекте каждый раз, когда вы активируете действие SELECT, например воздушный разговор или голосовую команду "Select".

    ![Lesson5 Chapter3 шаг 5](images/Lesson5Chapter3Step5.JPG)

6. Убедитесь, что возможности отслеживания взгляда правильно настроены, прежде чем выполнять компиляцию в HoloLens 2. На момент написания этой статьи Unity еще не может установить входные данные взгляда для возможностей отслеживания взгляда. Установка этой возможности необходима для отслеживания взгляда в HoloLens 2. Следуйте инструкциям по [тестированию приложения Unity на HoloLens 2](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#testing-your-unity-app-on-a-hololens-2) , чтобы включить входные возможности.

## <a name="congratulations"></a>Поздравляем!

Вы успешно добавили базовые возможности отслеживания взгляда в приложение. Эти действия только открывают целый мир новых возможностей, которые предоставляет отслеживание взгляда. Эта глава также завершает занятие 5, где мы узнали о расширенных функциях ввода, таких как речевые команды, жесты панорамирования и отслеживание глаз.

[Следующее занятие: 7. Создание примера приложения лунного модуля](mrlearning-base-ch6.md)
