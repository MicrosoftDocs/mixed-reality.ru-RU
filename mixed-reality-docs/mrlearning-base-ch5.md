---
title: Модуль MR обучения Base - дополнительные входные данные
description: Выполните этот курс, чтобы узнать, как реализовать распознавание лиц Azure в приложениях смешанной реальности.
author: jessemcculloch
ms.author: jemccull
ms.date: 02/26/2019
ms.topic: article
ms.localizationpriority: high
keywords: Смешанная реальность, unity, руководство, hololens
ms.openlocfilehash: 32141aafd43c5d729919673509c93bb2014edd37
ms.sourcegitcommit: 1c0fbee8fa887525af6ed92174edc42c05b25f90
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/16/2019
ms.locfileid: "65730924"
---
# <a name="mr-learning-base-module---advanced-input"></a>Модуль MR обучения Base - дополнительные входные данные

На этом занятии мы рассмотрим несколько дополнительных входных параметров для HoloLens 2, в том числе с помощью голосовых команд, панорамирования жестов и отслеживания. 

## <a name="objectives"></a>Цели

- Узнайте, как вызывать события с помощью голосовых команд и ключевые слова
- Используйте записанные руки для панорамирования, текстуры и трехмерные объекты
- Использовать глаз HoloLens 2, отслеживания возможностей для выбора объектов

## <a name="instructions"></a>Инструкция

### <a name="enabling-voice-commands"></a>Включение голосовые команды

В этом разделе мы будет реализовано два голосовых команд. Во-первых, возможность включить или выключить панель диагностики частоты кадров, о том, «toggle Диагностика». Во-вторых, воспроизведение звука с помощью голосовых команд. Во-первых, мы изучим MRTK профили и параметры, отвечает за настройку голосовых команд. 

1. В иерархии сцены Base выберите «MixedRealityToolkit.» На панели Инспектора прокрутите вниз до ввода системные параметры. Дважды щелкните, чтобы открыть свой профиль система ввода. Клонировать профиля система ввода, чтобы оно стало редактируемым, как мы узнали из [занятия 1](mrlearning-base-ch1.md) 

В профиле система ввода вы увидите различные параметры. Голосовые команды см. в статье где отображается надпись, «Параметры команды речи». 

![Lesson5 Chapter1 Step2im](images/Lesson5_Chapter1_step2im.PNG)

2. Клонировать профиль команды речи, чтобы оно стало редактируемым, как мы узнали из [занятия 1](mrlearning-base-ch1.md). Дважды щелкните профиль команды речи, где вы заметите ряд параметров. Полное описание этих параметров, см. в разделе [MRTK речи документации](<https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Speech.html>). 

>Примечание. По умолчанию общее поведение таково, автоматический запуск. Запуск вручную при необходимости, можно изменить, но в этом примере мы хотим хранить ее на автоматический запуск. MRTK поставляется с несколько голосовые команды по умолчанию (например, меню, переключить диагностики и переключить профилировщика). Мы будем использовать ключевое слово «переключить Диагностика» позволяет включать и отключать счетчика диагностики частоты кадров. Также мы добавим новую команду голоса в указанные ниже действия.
>
> ![Lesson5 Chapter1 Noteim](images/Lesson5_chapter1_noteim.PNG)

3. Добавьте новый голосовых команд. Чтобы добавить новый голосовых команд, нажмите кнопку «+ Добавить новую команду речи» и вы увидите новую строку, отображается под списком существующих голосовых команд. Введите в голосовых команд, которые вы хотите использовать. В этом ex musicample мы собираемся использовать команду «воспроизведение музыки».

>Совет. Можно также задать keycode для команд речи. Это позволяет голосовые команды для запуска при нажатии клавиши клавиатуры.   

4. Добавление возможности отвечать на голосовые команды. Выберите любой объект в иерархии базовых сцены, не поддерживает все другие входные скрипты, подключенные к ней (например, обработчик манипуляции.) На панели Инспектора нажмите кнопку «Добавить компонент». Введите «обработчика ввода речи». Выберите его.
   ![Lesson5 Chapter1 Step4im](images/Lesson5_chapter1_step4im.PNG)

   

По умолчанию вы увидите 2 флажки, он флажок «is требуется фокус». Это значит, что запускается до тех пор, пока вы указывают на объект с Рэй взглядом, (взглядом глаза, взглядом head, взглядом контроллера или наличии взглядом) голосовых команд. Снимите этот флажок, чтобы сделать так, чтобы пользователь не имеет рассмотрим объект для использования голосовых команд.

5. Добавление возможности отвечать на голосовые команды. Чтобы сделать это, нажмите кнопку «+», в обработчике ввода речи и выберите ключевое слово, которое вы хотите ответить.

   > Примечание. Эти ключевые слова будут заполнены на основе профиля, измененные на предыдущем шаге.

![Lesson5 Chapter1 Step5im](images/Lesson5_chapter1_step5im.PNG)

6. Рядом с «Ключевое слово» появится раскрывающееся меню. Выберите «Переключение диагностики». Это поможет вам таким образом, чтобы каждый раз, когда пользователь говорит фразу «переключить диагностики», он активирует действие. Обратите внимание на то, что может потребоваться развернуть «элемент 0», нажав стрелку рядом с ним.

![Lesson5 Chapter1 Step6im](images/Lesson5_chapter1_step6im.PNG)

7. Добавьте «Диагностика Демонстрация управления скрипт» для включения диагностики счетчиков частоты кадров или выключения. Чтобы сделать это, нажмите кнопку «Добавить компонент» и выполните поиск «Диагностика демонстрационный сценарий управления», затем добавьте его в меню. Этот сценарий можно добавить к любому объекту, но для простоты мы добавим его на тот же объект, как входной обработчик распознавания речи. 

   > Примечание: этот сценарий является только включенные в эти модули и не входит в состав исходного MRTK.

![Lesson5 Chapter1 Step7im](images/Lesson5_chapter1_step7im.PNG)

8. Добавьте новый ответ в обработчике ввода речи. Для этого щелкните кнопку «+» под надписью «ответа ()» (обозначен зеленая стрелка на рисунке выше).

![Lesson5 Chapter1 Step7im](images/Lesson5_chapter1_step8.PNG)

9. Перетащите объект, содержащий элементы управления Демонстрация диагностики скрипт в новый ответ, который вы только что создали на шаге 8.
    ![Lesson5 Chapter1 Step9im](images/Lesson5_chapter1_step9im.PNG)

10. Теперь выберите в раскрывающемся списке «нет функции», выберите диагностики Демонстрация элементов управления, а затем «на попробуйте переключиться (Диагностика)». Эта функция включает диагностику и выключает.  ![Lesson5 Chapter1 Step10im](images/Lesson5_chapter1_step10im.PNG)
    
> Обратите внимание на то, что перед сборкой на ваше устройство необходимо включить параметры mic. Чтобы сделать, щелкните файл, перейдите к параметры сборки, после этого параметры проигрывателя и убедитесь, что возможность "микрофон" задается.

Затем мы добавили возможность воспроизводить звуковой файл из голосовых команд, с помощью объекта «являются восьмеричным». Как следует из [урок 4](mrlearning-base-ch4.md), мы добавили Воспроизведение аудиоклипа упал являются восьмеричным объекта. Мы будем использовать этот же аудиоисточник для наших музыки голосовых команд.

11. Выберите объект являются восьмеричным в иерархии базовых сцены.

12. Добавьте еще один входной обработчик распознавания речи (повторите шаги 4 и 5), но с объектом являются восьмеричным. 

13. Вместо добавления команда «Переключить Диагностика» на шаге 6, добавьте голосовых команд «Воспроизведение музыки», как показано на рисунке ниже.
    
     ![Lesson5 Chapter1 Step13im](images/Lesson5_chapter1_step13im.PNG)
    
    
    
14. Как и в шагах 8 и 9, добавить новый ответ и перетащите являются восьмеричным пустой слот в ответе.

15. Выберите в раскрывающемся меню с текстом «нет функции» выберите «Audio источник», а затем выберите «PlayOneShot (AudioClip).»

![Lesson5 Chapter1 Step15im](images/Lesson5_chapter1_step15im.PNG)

16. Для аудиоклип, в этом примере мы собираемся использовать же звуковой клип из [занятия 4](mrlearning-base-ch4.md). Перейдите в панель проекта, найдите аудиоклипа «MRTK_Gem» и перетащите его в аудио исходного слота, как показано на рисунке ниже. Теперь ваше приложение должно быть отвечать на голосовые команды «Диагностика переключатель» для переключения панели счетчиков частоты кадров и «воспроизведение музыки» на воспроизведение в MRTK_Gem.
     ![Lesson5 Chapter1 Step16im](images/Lesson5_chapter1_step16im.PNG)


### <a name="the-pan-gesture"></a>Жест Pan 

В этой главе мы узнаете, как использовать жест сдвиг. Это полезно для прокрутки (с помощью пальца или наличии для прокрутки содержимого.) Также можно жест pan поворачивают объекты, чтобы пролистать коллекцию трехмерных объектов, или даже прокрутки двухмерных пользовательского интерфейса. Мы будет обучения как с помощью жестов pan warp текстуры. Мы также будет рассказано, как переместить коллекцию трехмерных объектов.

1. Создайте четыре. В иерархии базовых сцены щелкните правой кнопкой мыши, выберите «трехмерный объект», затем выберите «Четыре».

![Lesson5 Chapter2 Step2im](images/Lesson5_chapter2_step2im.PNG)

2. Изменить положение quad соответствующим образом. В нашем примере мы устанавливаем x = 0, y = 0 и z = 1,5 от камеры для удобном положении 2 HoloLens.

   > Примечание. Если четырех блоков (— компании infront из) любое содержимое из предыдущих занятий, убедитесь, что для перемещения его таким образом, чтобы она не блокировала любых других объектов.

3. Применение материала к квадрант. Этот материал будет материала, который мы будет прокрутке с жестом сдвиг. 

![Lesson5 Chapter2 Step3im](images/Lesson5_chapter2_step3im.PNG)

4. На панели «проекты», введите в поле поиска «Панорама content». Перетащите этот материал на четыре в сцене. 

> Примечание. Материал «Сдвиг содержимое» не включен в MRTK, но это ресурса в пакете средств этот модуль, как импортировать в предыдущих уроках. 

> Примечание. При добавлении содержимого pan, может выглядеть растянутым. Это можно исправить, настроив значения x, y и z значения от размера квадрант, пока не достигнете с тем, как это выглядит.

Чтобы использовать жест pan, вам потребуется collider объекта. Можно заметить, что четыре уже collider сетки. Тем не менее collider сетки не идеальное решение, так как это невероятно тонкой и точного выделения. Мы рекомендуем, заменив collider поле collider сетки.

5. Щелкните правой кнопкой мыши collider сетки на четырех (панели Инспектора), а затем удалите его, нажав кнопку «Удалить компонент». 
   ![Lesson5 Chapter2 Step5im](images/Lesson5_chapter2_step5im.PNG)

6. Теперь добавьте поле collider, выбрав «добавить компонент» Поиск «поле collider». Значение по умолчанию добавлено поле collider по-прежнему слишком тонким, нажмите кнопку «Изменить collider», чтобы изменить его. Когда он находится в нажатом состоянии, можно настроить размер с помощью x, y и z значений или элементов в редакторе сцены. В нашем примере мы хотим расширить collider поле немного за четыре. В редакторе сцены перетащите поле collider на обратной стороне к краям (см. на рисунке ниже). Что мы будем создавать отчеты — это разрешает пользователю использовать не только пальцев, но их всю руку для прокрутки. 
    ![Lesson5 Chapter2 Step6im](images/Lesson5_chapter2_step6im.PNG)
7. Сделайте интерактивными. Поскольку нам требуется напрямую взаимодействовать с квадрант, мы хотим использовать компонент «рядом с физические взаимодействия» (мы также использовали это на занятии 4 для воспроизведения музыки из являются восьмеричным). Нажмите кнопку «Добавить компонент» и найдите «рядом с физические взаимодействия» и выберите его, как показано на рисунке ниже. 

8. Добавление возможности распознавания жестов сдвиг. Нажмите кнопку «Добавить компонент» и введите «стрелки взаимодействия панорама». Имеется выбор между Рэй Рука (позволяя сдвиг на расстоянии) и вытянутым указательным пальцем. В этом примере оставьте вытянутым указательным пальцем. 
    ![Lesson5 Chapter2 8Im шаг 7](images/Lesson5_chapter2_step7-8im.PNG)

![Lesson5 Chapter2 Step8im](images/Lesson5_chapter2_step8im.PNG)

9. В скрипте pan взаимодействия вручную «блокировка по горизонтали» и «блокировка по вертикали» флажки заблокирует перемещений, соответственно. Параметры переноса текстуры сделает текстур (текстуры сопоставление) выполните перемещений pan пользователя. В этом примере мы собираемся установив этот флажок. Имеется также «velocity active» что, если этот флажок снят, pan жест не будет работать. Установите флажок, а также. Теперь необходимо иметь четыре pan с поддержкой.

   

   Далее будет рассказано как сдвиг трехмерные объекты. 

10. Четыре объекта щелкните правой кнопкой мыши, выберите трехмерный объект щелкните «куб». Масштабирование куба, так как это примерно x = 0,1, y = 0,1 и z = 0,1. Скопируйте этот куб 3 раза (, щелкнув правой кнопкой мыши куб и нажав клавишу повторяющиеся или командой нажатие элемента управления/D). Равномерного. Сцена должна выглядеть как показано на рисунке ниже.

![Lesson5 Chapter2 Step10im](images/Lesson5_chapter2_step10im.PNG)







11. Снова выберите квадрант, и в разделе скрипта сдвиг взаимодействия вручную, нам нужно выбрать pan действий к каждому из кубов. В разделе «Панорама приемников событий» необходимо задать число объектов, которые получают события. Поскольку имеются 4 кубы, типом «4» и нажмите клавишу ВВОД. должна появиться 4 пустые поля.


![Lesson5 Chapter2 Step11im](images/Lesson5_chapter2_step11im.PNG)



12. Перетащите каждый из кубов в каждой из слотов пустой элемент.
     ![Lesson5 Chapter2 Step12im](images/Lesson5_chapter2_step12im.PNG)
    
13. Добавьте скрипт «для перемещения Панорама» для кубов. Сделать это, нажмите и удерживайте элемент управления или команды и выберите каждый объект. Затем на панели инспектора, щелкните «Добавить компонент» и выполните поиск «перейти с панорама». Выберите сценарий и оно будет добавляться для каждого куба. Теперь трехмерные объекты будут перемещаться вместе с жеста Панорама! При удалении сетки отображаются на вашей квадрант, должна быть невидимой квадрант, где можно произвести сдвиг по списку трехмерные объекты.

### <a name="eye-tracking"></a>Отслеживания

В этой главе мы рассмотрим, как включить отслеживание глаза в нашей демоверсией. Мы медленно повернется наших 3D команды меню, когда они находятся gazed после с изображением глаза взглядом. Мы также вызывают интересную в силу при выборе элемента gazed после.

1. Убедитесь, что профили смешанной реальности Toolkit настроены правильно. На момент написания этой статьи, набор средств настройки профиля смешанной реальности не включает глаза, возможности отслеживания по умолчанию. Чтобы добавить возможности отслеживания, следуйте инструкциям в разделе «Настройка профилей MRTK, необходимые для отслеживания глаз», как описано в [документации Toolkit смешанной реальности](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#setting-up-the-mrtk-profiles-required-for-eye-tracking  ). Убедитесь, что этот глаз отслеживания настроен правильно, выполнив все оставшиеся действия, в документации по ссылке выше, в том числе Включение отслеживания глаза в GazeProvider (компонент, присоединенного к камере) и включение моделирование отслеживания в редакторе Unity. Обратите внимание, будущих версиях MRTK может включать глаз отслеживания по умолчанию.

    Вышеприведенная ссылка предоставляет краткие инструкции по:

    - Создание глаз помощи поставщик данных для использования в профиле MRTK
    - Включение отслеживания глаза в поставщике помощи
    - Настройка для имитации отслеживания в редакторе
    - Разрешить отслеживание глаза в созданное приложение решения Visual Studio возможности редактирования

2. Добавьте глаз отслеживания целевого компонента к целевым объектам. Чтобы разрешить объект реагировать на события взглядом глаза, необходимо добавить компонент EyeTrackingTarget для каждого объекта, который нужно взаимодействовать с изображением глаза взглядом. Добавьте этот компонент для каждого из девяти трехмерные объекты, которые являются частью коллекции сетки. Совет: выберите несколько элементов в иерархии для массового добавления компонента EyeTrackingTarget.
    ![Шаг 2 Chapter3 Lesson5](images/Lesson5Chapter3Step2.JPG)

3. Далее мы добавим EyeTrackingTutorialDemo скрипт для некоторые интересные возможности взаимодействия. Сценарий EyeTrackingTutorialDemo входит в состав этой серии руководств репозитории и не включается по умолчанию с набором средств смешанной реальности. Для каждого трехмерного объекта в коллекции сетки добавьте сценарий EyeTrackingTutorialDemo, выполнив поиск компонента в меню «Добавить компонент».
   ![Этап 3 Chapter3 Lesson5](images/Lesson5Chapter3Step3.JPG)

   4. Поверните объект при взгляде на целевом компьютере. Мы бы хотели настроить наших трехмерного объекта, чтобы запустить, пока мы рассматриваем его. Чтобы сделать это, вставьте новое поле в разделе «Во время поиска в Target» EyeTrackingTarget компонента, как показано на рисунке ниже. 

![Lesson5 Chapter3 Step4a](images/Lesson5Chapter3Step4a.JPG)
![Lesson5 Chapter3 Step4b](images/Lesson5Chapter3Step4b.JPG)



В созданное поле добавьте текущий объект игры в пустое поле и выберите EyeTrackingTutorialDemo > RotateTarget(), как показано на рисунке ниже. Теперь трехмерный объект настроен на вращение при является gazed при отслеживании глаз. 

5. Добавьте в способности «кратковременного сбоя target», является gazed в после select (жест касания, или о том, «выбрать»). Как и в шаге 4, нам нужно активировать EyeTrackingTutorialDemo > BlipTarget(), присвоив его поле «Select()» игровой объект компонента EyeTrackingTarget, как показано на рисунке ниже. Таким образом вы настроили можно заметить небольшие кратковременного сбоя в объекте игр, каждый раз, когда вы активировать действие выбора, например жест касания или голосовых команд «выберите». 
    ![Шаг 5 Chapter3 Lesson5](images/Lesson5Chapter3Step5.JPG)
6. Убедитесь, что возможности отслеживания глаз правильно настроены, перед сборкой для HoloLens 2. На момент написания этой статьи Unity еще не содержит возможность устанавливать взглядом возможность ввода (для отслеживания глаз). Установка этой возможности является обязательным для отслеживания глаза для работы в HoloLens 2. Выполните эти инструкции по документации toolkit смешанной реальности, чтобы включить возможность ввода взглядом. https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#testing-your-unity-app-on-a-hololens-2 


### <a name="congratulations"></a>Поздравляем! 
Вы успешно добавили основные глаза, возможности отслеживания для приложения. Эти действия являются только начало целый мир новых возможностей с помощью отслеживания. Также приводятся занятие 5, где мы узнали о расширенные функции ввода, например голосовые команды панорамирования жестов и отслеживания глаз. 

[Следующее занятие: Возможности образца лунного модуль сборки](mrlearning-base-ch6.md)

