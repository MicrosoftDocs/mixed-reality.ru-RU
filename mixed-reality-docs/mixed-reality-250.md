---
title: Совместное использование 250 - HoloLens и иммерсивную MR
description: Выполните кодирование Пошаговое руководство по использованию Unity, Visual Studio, HoloLens и Windows Mixed Reality гарнитуры совместного использования голограммы между устройствами смешанной реальности подробные сведения.
author: keveleigh
ms.author: kurtie
ms.date: 03/21/2018
ms.topic: article
keywords: holotoolkit mixedrealitytoolkit, mixedrealitytoolkit-unity, создающий эффект присутствия, движения контроллера, совместное использование, контроллер xbox, сетевые подключения между устройствами
ms.openlocfilehash: 9e1cb0d168b8bf830b4477190516cd19caef7972
ms.sourcegitcommit: 384b0087899cd835a3a965f75c6f6c607c9edd1b
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/12/2019
ms.locfileid: "59598046"
---
>[!NOTE]
>Учебники Academy реальности Mixed были разработаны с HoloLens (1-го поколения) и смешанной реальности Иммерсивную в виду.  Таким образом мы думаем, что это важно, чтобы эти учебники на месте для разработчиков, которые по-прежнему необходимы сведения при разработке приложений для этих устройств.  Эти руководства будут **_не_** дополняться последние наборы инструментов или взаимодействия, используемых для HoloLens 2.  Они будут сохранены, чтобы продолжить работу на поддерживаемых устройствах. Будет существовать новую серию учебников, которые будут опубликованы в будущем, демонстрируют способ разработки для HoloLens 2.  Это уведомление будет обновляться со ссылкой на эти руководства, когда они учитываются.

<br>

# <a name="mr-sharing-250-hololens-and-immersive-headsets"></a>Совместное использование 250 MR: HoloLens и иммерсивную

Благодаря гибкости для универсальной платформы Windows (UWP) можно легко создать приложение, которое охватывает несколько устройств. Благодаря этой гибкости мы можем создавать действия, которые необходимо использовать сильные стороны каждого устройства. Этом руководстве рассматриваются основные общий интерфейс, который выполняется на HoloLens и Windows Mixed Reality иммерсивную. Это содержимое было изначально доставлено на конференции Microsoft Build 2017 в Сиэтле, штат Вашингтон.

**В этом руководстве мы выполним следующее.**

* Настройка сети с помощью UNET.
* Совместное использование голограммы устройств смешанной реальности.
* Создайте другое представление приложения, в зависимости от используемого устройства смешанной реальности.
* Создайте общий интерфейс, где пользователи HoloLens помогает пользователям иммерсивную сделать несколько простых головоломок.

## <a name="device-support"></a>Поддержка устройств

<table>
<tr>
<th>Курс</th><th style="width:150px"> <a href="hololens-hardware-details.md">HoloLens</a></th><th style="width:150px"> <a href="immersive-headset-hardware-details.md">Иммерсивную</a></th>
</tr><tr>
<td>Совместное использование 250 MR: HoloLens и иммерсивную</td><td style="text-align: center;"> ✔️</td><td style="text-align: center;"> ✔️</td>
</tr>
</table>

## <a name="before-you-start"></a>Прежде чем начать

### <a name="prerequisites"></a>Предварительные требования

* ПК с Windows 10 с [средства разработки, необходимые](install-the-tools.md) и [настроен для поддержки Windows гарнитуры смешанной реальности иммерсивных](https://docs.microsoft.com/windows/mixed-reality/enthusiast-guide/windows-mixed-reality-minimum-pc-hardware-compatibility-guidelines).
* Контроллер Xbox, который работает с компьютера.
* Хотя бы одно устройство HoloLens и один иммерсивных гарнитуры.
* Сеть, которая позволяет рассылать UDP для обнаружения.

### <a name="project-files"></a>Файлы проекта

* Скачайте [файлы](https://github.com/Microsoft/MixedReality250/archive/master.zip) требуемые для проекта. Извлеките файлы в легко запоминающегося расположение.
* Для этого проекта требуется [рекомендуется версию Unity с поддержкой Windows Mixed Reality](install-the-tools.md).

>[!NOTE]
>Если вы хотите просмотреть исходный код перед загрузкой, он имеет [на сайте GitHub](https://github.com/Microsoft/MixedReality250).

## <a name="chapter-1---holo-world"></a>Глава 1 - Holo World

>[!VIDEO https://www.youtube.com/embed/IC0rp6rLiEc]

### <a name="objectives"></a>Цели

Убедитесь, что в среде разработки будет готова к работе с простого проекта.

### <a name="what-we-will-build"></a>Мы построим

Приложение, в которой отображается голограмма HoloLens или иммерсивных гарнитуры смешанной реальности Windows.

### <a name="steps"></a>Действия
* Откройте Unity.
    * Выберите **откройте**.
    * Перейдите к извлеченным файлам проекта.
    * Щелкните элемент **Выбор папки**.
    * *Займет немного хотя Unity для обработки в проект в первый раз.*
* Проверьте, что в Unity включено смешанной реальности.
    * Открыть диалоговое окно настройки сборки (**управления + Shift + B** или **файл > создать параметры** ).
    * Выберите **универсальной платформы Windows** щелкните **переключить платформу**.
    * Выберите **изменить > Параметры проигрывателя**.
    * В **инспектор** на правой панели, разверните узел **XR параметры**.
    * Проверьте **поддерживается виртуальной реальности** поле.
    * *Смешанная реальность Windows должен быть виртуальной реальности SDK.*
* Создание сцены.
    * В **иерархии** щелкните правой кнопкой мыши **Main Camera** выберите **удалить**.
    * Из **HoloToolkit > ввод > Prefabs** перетащите **MixedRealityCameraParent** для **иерархии**.
* Добавьте в сцену голограммы
    * Из **AppPrefabs** перетащите **Skybox** для **представлении сцены**.
    * Из **AppPrefabs** перетащите **диспетчеры** для **иерархии**.
    * Из **AppPrefabs** перетащите **остров** для **иерархии**.
* Сохранение и разработка
    * Сохранить (либо **управления + S** или **файл > Сохранить сцену**)
    * Так как это новую сцену, вам потребуется его назвать. Имя не имеет значения, но мы используем SharedMixedReality.
* Экспорт в Visual Studio
    * Откройте меню "сборка" (**управления + Shift + B** или **файл > Параметры сборки**)
    * Нажмите кнопку **Добавление открытых сцен.**
    * Проверьте **Unity C# проектов**
    * Щелкните **Сборка**.
    * В окне обозревателя файл, который отображается, создайте новую папку с именем **приложения**.
    * Одним щелчком мыши **приложения** папки.
    * Нажмите клавишу **выберите папку.**
    * **Дождитесь завершения сборки**
    * В окне обозревателя файл, который отображается, перейдите в **приложения** папки.
    * Дважды щелкните **SharedMixedReality.sln** для запуска Visual Studio
* Строится на основе Visual Studio
    * С помощью панели инструментов вверху изменить целевой объект для **выпуска** и **x86**.
    * Щелкните стрелку рядом с полем **локального компьютера** и выберите **устройства** для развертывания в HoloLens
    * Щелкните стрелку рядом с полем **устройства** и выберите **локального компьютера** развертывание для гарнитуры смешанной реальности.
    * Нажмите кнопку **Отладка -> Запуск без отладки** или **управления + F5** для запуска приложения.

### <a name="digging-into-the-code"></a>Подробно о коде

На панели «проект» перейдите к **Assets\HoloToolkit\Input\Scripts\Utilities** и дважды щелкните **MixedRealityCameraManager.cs** чтобы открыть его.

**Обзор:** MixedRealityCameraManager.cs является простой сценарий, который настраивает параметры качества уровень и фона в зависимости от устройства. Вот HolographicSettings.IsDisplayOpaque, что позволяет обнаружить, является ли устройство HoloLens сценарий ключа (IsDisplayOpaque возвращает значение false) или иммерсивных Гарнитура (IsDisplayOpaque возвращает значение true).

### <a name="enjoy-your-progress"></a>Наслаждайтесь хода выполнения

На этом этапе приложение просто визуализирует голограмма. Мы добавим взаимодействия для голограмма позже. Оба устройства голограмма одинаковой визуализации. Насыщенные гарнитура также сделает синим фоном небо и облаков.

## <a name="chapter-2---interaction"></a>Глава 2 - взаимодействия

>[!VIDEO https://www.youtube.com/embed/Lrb1y4sQRvI]

### <a name="objectives"></a>Цели

Показано, как обрабатывать входные данные для приложения Windows смешанной реальности.

### <a name="what-we-will-build"></a>Мы построим

Основываясь на приложение в главе 1, мы добавим возможность, позволяющая пользователю взять голограмма и поместите его на поверхность реального мира в HoloLens или на виртуальную таблицу в иммерсивных гарнитуры.

**Входной напоминание:** На HoloLens — выберите жест **жест касания**. На иммерсивную, мы будем использовать **A** кнопки контроллера Xbox. Дополнительные сведения о входных данных [начало](gestures.md).

### <a name="steps"></a>Действия
* Добавление диспетчера входных данных
    * Из **HoloToolkit > ввод > Prefabs** перетащите **InputManager** для **иерархии** как дочерний **диспетчеры**.
    * Из **HoloToolkit > ввод > Prefabs > курсор** перетащите **курсор** для **иерархии**.
* Добавление пространственное сопоставление
    * Из **HoloToolkit > SpatialMapping > Prefabs** перетащите **SpatialMapping** для **иерархии**.
* Добавление виртуального Playspace
    * В **иерархии** разверните **MixedRealityCameraParent** выберите **границ**
    * В **инспектор** панели установите флажок, чтобы включить **границ**
    * Из **AppPrefabs** перетащите **VRRoom** для **иерархии**.
* Добавить WorldAnchorManager
    * В **иерархии**выберите **диспетчеры**.
    * В **инспектор**, нажмите кнопку **добавить компонент**.
    * Тип **Manager привязки World**.
    * Выберите **Manager привязки World** Чтобы добавить его.
* Добавить TapToPlace острова
    * В **иерархии**, разверните **остров**.
    * Выберите **MixedRealityLand**.
    * В **инспектор**, нажмите кнопку **добавить компонент**.
    * Тип **коснитесь место** и выберите его.
    * Проверьте **снабдить родительского Tap**.
    * Задайте **смещение размещения** для **(0, 0.1, 0)**.
* Сохраните и выполните сборку как и раньше

### <a name="digging-into-the-code"></a>Подробно о коде

**Сценарий 1 - GamepadInput.cs**

На панели «проект» перейдите к **Assets\HoloToolkit\Input\Scripts\InputSources** и дважды щелкните **GamepadInput.cs** чтобы открыть его. В тот же путь «проект», также дважды щелкните **InteractionSourceInputSource.cs**.

Обратите внимание на то, что оба сценария имеют общий базовый класс BaseInputSource.

BaseInputSource хранит ссылки на InputManager, что позволяет скрипт для активации событий. В этом случае событие InputClicked относится. Это будет важно помнить, когда мы приступим к сценария 2, TapToPlace. В случае GamePadInput мы опроса на контроллере Нажимаемые кнопки A, а затем мы событие InputClicked. В случае InteractionSourceInputSource мы событие InputClicked в ответ на TappedEvent.

**Сценарий 2 - TapToPlace.cs**

На панели «проект» перейдите к **Assets\HoloToolkit\SpatialMapping\Scripts** и дважды щелкните **TapToPlace.cs** чтобы открыть его.

Первое, что многие разработчики желают реализовать при создании Holographic приложения — это перенос голограммы с входными данными жеста. Таким образом мы endeavored тщательно преобразовывать в комментарии этот сценарий. Несколько моментов заслуживают выделение для этого руководства.

Во-первых Обратите внимание на то, что TapToPlace реализует IInputClickHandler. IInputClickHandler предоставляет функции, которые обрабатывают InputClicked событие GamePadInput.cs или InteractionSourceInputSource.cs. OnInputClicked вызывается, когда BaseInputSource обнаруживает щелчок, пока объект с TapToPlace находится в фокусе. Либо совершающая жест касания в HoloLens, либо нажав кнопку A на контроллер Xbox будет активировать событие.

Во-вторых — код выполнен в обновлении см. в разделе, если поверхность разрабатывается в, мы может размещать объект игр на поверхности, таких как таблицы. Иммерсивных гарнитура нет понятие реальных рабочих областей, поэтому объект, представляющий верхней таблице (Vroom > TableThingy > куб) был помечен на уровне SpatialMapping физики, поэтому луч приведения в обновлении будет конфликтовать с верхней виртуальной таблицы.

### <a name="enjoy-your-progress"></a>Наслаждайтесь хода выполнения

Это время можно выбрать область, чтобы переместить его. На HoloLens острова, которая может перемещать реальных область. В иммерсивных гарнитура можно переместить область для виртуальную таблицу, который мы добавили.

## <a name="chapter-3---sharing"></a>Глава 3 - совместное использование

>[!VIDEO https://www.youtube.com/embed/1diycJvxfDc]

### <a name="objectives"></a>Цели

Убедитесь, что сеть настроена правильно и подробной информации о том, как пространственных привязки являются общими для устройств.

### <a name="what-we-will-build"></a>Мы построим

Мы преобразуем наш проект в проект многопользовательского режима. Мы добавим пользовательский Интерфейс и логика сеансов узла или соединения. HoloLens пользователи будут видеть друг с другом в сеансе с облаками над головой и иммерсивных гарнитура пользователи имеют облаков рядом которых привязка является. Пользователи в иммерсивную будут видеть пользователи HoloLens относительно начала координат сцены. Все HoloLens пользователи будут видеть голограмма острова в том же месте. Очень важно не будет на острове во время этой главе пользователей в иммерсивную, но будет работают почти так же HoloLens, представление глаз птиц острова.

### <a name="steps"></a>Действия
* Remove-Херд и VRRoom
    * В **иерархии** щелкните правой кнопкой мыши **остров** выберите **удалить**
    * В **иерархии** щелкните правой кнопкой мыши **VRRoom** выберите **удалить**
* Добавить Usland
    * Из **AppPrefabs** перетащите **Usland** для **иерархии**.
* Из **AppPrefabs** перетащите каждый из следующих действий, чтобы **иерархии**:
    * **UNETSharingStage**
    * **UNetAnchorRoot**
    * **UIContainer**
    * **DebugPanelButton**
* Сохраните и выполните сборку как и раньше

### <a name="digging-into-the-code"></a>Подробно о коде

На панели «проект» перейдите к **Assets\AppPrefabs\Support\SharingWithUnet\Scripts** и дважды щелкните **UnetAnchorManager.cs**. Возможность для одного HoloLens предоставить сведения об отслеживании другой HoloLens, таким образом, что оба устройства могут совместно использовать то же пространство расположено волшебное средство разрешения. Мощь смешанной реальности оживает, когда два или больше пользователей могут совместно работать с помощью тех же цифровых данных.

Необходимо отметить в этом сценарии несколько вещей:

В функции запуска, обратите внимание, что проверка **IsDisplayOpaque**. В этом случае мы представьте, что привязка устанавливается. Это обусловлено иммерсивную не предоставляют способ импорта или экспорта привязки. Если работа происходит в HoloLens, тем не менее, этот сценарий реализует доступом привязки между устройствами. Устройство, которое запускает сеанс будет создавать привязки для экспорта. Устройства, который присоединяется к сеансу запроса привязки с устройства, запустившего сеанс.

**Экспорт:**

Когда пользователь создает сеанс, NetworkDiscoveryWithAnchors будет вызывать функцию UNETAnchorManagers CreateAnchor. Рассмотрим CreateAnchor потока.

Мы начнем с выполнения действия по обслуживанию, очищая все данные, которые для предыдущих привязки мы собрали. Затем мы проверяем, существует ли кэшированный привязки для загрузки. Привязки данных, как правило, находиться в диапазоне от 5 до 20 МБ, поэтому повторное использование кэшированных привязки можно сэкономить на объем данных, которые необходимо передать по сети. Мы увидим, как это работает немного позже. Даже если мы повторно привязки, нам нужно получить данные готовы в случае, если присоединяется новый клиент, не имеет привязки к привязки.

Говоря о подготовке данных привязки, класс WorldAnchorTransferBatch предоставляет функциональные возможности для подготовки данных привязки для отправки на другое устройство или приложение и функциональные возможности для импорта данных привязки. Мы обеспечиваем для пути экспорта, мы добавим наши привязки к WorldAnchorTransferBatch и вызовите функцию ExportAsync. ExportAsync затем вызовет WriteBuffer обратный вызов, при формировании данных для экспорта. Когда все данные были экспортированы ExportComplete будет вызываться. В WriteBuffer мы добавим фрагмент данных в список, мы не для экспорта. В ExportComplete преобразование списка в массив. AnchorName переменной также задается, который будет активировать другие устройства для запроса привязки, если они не имеют.

В некоторых случаях привязка не экспортировать или создаст лишь небольшой объем данных, мы повторит попытку. Здесь мы вызываем CreateAnchor еще раз.

Конечная функция в исходном каталоге — AnchorFoundRemotely. Если другое устройство находит точку привязки, это устройство будет сообщить этому приложению и узел будет использовать его в качестве сигнала, что привязка является «хорошей привязки» и могут кэшироваться.

**Импорт:**

Когда HoloLens присоединяется к сеансу, ему необходимо импортировать привязку. В функции обновления в UNETAnchorManager опрашивается AnchorName. При изменении имени привязки, начинается процесс импорта. Во-первых мы попытаемся загрузить привязку с указанным именем из локального хранилища привязки. Если мы сделали, мы используем его без загрузки данных еще раз. Если у нас его нет, мы называем WaitForAnchor, которые будут инициировать загрузку.

По завершении загрузки называется NetworkTransmitter_dataReadyEvent. Это даст сигнал цикла обновления для вызова ImportAsync с загруженными данными. ImportAsync вызовет ImportComplete после завершения процесса импорта. Если импорт прошел успешно, привязка будет сохраняться в хранилище локального проигрывателя. PlayerController.cs фактически выполняется вызов AnchorFoundRemotely позволяет знать, что было установлено хороший привязки узла.

### <a name="enjoy-your-progress"></a>Наслаждайтесь хода выполнения

Это время пользователь с HoloLens будет размещаться сеанс с помощью **запуск сеанса** кнопку в пользовательском Интерфейсе. Другим пользователям, как на HoloLens или иммерсивных гарнитура, необходимо выберите сеанс и выберите пункт **веб-трансляции** кнопку в пользовательском Интерфейсе. Если у вас есть несколько пользователей с устройствами, HoloLens, они будут иметь красный облаков над головой. Также будет синее облако для каждого иммерсивных гарнитура, но синие облака не будут выше гарнитуры, как гарнитуры не удается найти же мировых координат как устройства HoloLens.

Эту точку в проекте является автономной приложение для управления доступом; очень ничего не делает она может работать в качестве базового плана. В следующей главах будет приступать к созданию взаимодействие для пользователей, чтобы воспользоваться. Чтобы получить дополнительные рекомендации по опытом разработки, перейдите сюда.

## <a name="chapter-4---immersion-and-teleporting"></a>Глава 4 – общения и teleporting

>[!VIDEO https://www.youtube.com/embed/kUHZ5tCOfvY]

### <a name="objectives"></a>Цели

Обслуживайте интерфейс для каждого типа устройств смешанной реальности.

### <a name="what-we-will-build"></a>Мы построим

Мы обновим приложение для размещения пользователей иммерсивных гарнитура на острове иммерсивных представление. HoloLens пользователи по-прежнему будут иметь вид с высоты птичьего полета острова. Пользователи каждого из типов устройств можно видеть других пользователей, как они указаны в мире. К примеру иммерсивных гарнитура пользователи могут видеть другие аватары на других путях на острове, и они видят пользователи HoloLens как giant облака выше блоке. Иммерсивных гарнитура пользователи будут видеть курсор пользователя HoloLens взглядом Рэй также в том случае, если HoloLens пользователь просматривает область. HoloLens пользователи будут видеть аватар на острове для представления каждого пользователя иммерсивных гарнитуры.

**Обновленные входные данные для Иммерсивных устройства:**
* Проигрывателя поворота левой кнопки прокладки и правом прокладки контроллера Xbox
* Удерживая кнопку Y контроллера Xbox позволит [teleport](navigating-the-windows-mixed-reality-home.md#getting-around-your-home) курсора. Если курсор будет отображаться вращающийся индикатор стрелки после отпускания кнопки Y, можно teleported в положении курсора.

### <a name="steps"></a>Действия
* Добавить MixedRealityTeleport MixedRealityCameraParent
    * В **иерархии**выберите **Usland**.
    * В **инспектор**, включить **уровень управления**.
    * В **иерархии**выберите **MixedRealityCameraParent**.
    * В **инспектор**, нажмите кнопку **добавить компонент**.
    * Тип **смешанной реальности Teleport** и выберите его.

### <a name="digging-into-the-code"></a>Подробно о коде

Иммерсивных гарнитура пользователей будет привязанным к их ПК с помощью кабеля, но наши остров больше, чем кабель имеет большую длину. Чтобы компенсировать, мы должны возможность перемещения камеры, независимо от пользователя движения. См. в разделе [страницы комфорта](comfort.md) Дополнительные сведения о создании собственного приложения смешанной реальности (в частности собственный движения и locomotion).

Для описания этого процесса будет полезно определить два термина. Во-первых, **наличия прицепа к арендованному** будет объектом, который перемещает камеры независимо от пользователя. Дочерний объект игр **наличия прицепа к арендованному** будет **главной камеры**. Главной камеры, присоединяется к head пользователя.

На панели «проект» перейдите к **Assets\AppPrefabs\Support\Scripts\GameLogic** и дважды щелкните **MixedRealityTeleport.cs**.

MixedRealityTeleport имеет два задания. Во-первых он обрабатывает поворота с помощью по нему. В функции обновления опроса для «ButtonUp» LeftBumper и RightBumper. GetButtonUp только возвращает значение true на первом кадре, кнопка не нажата была вниз. Если было вызвано одной из кнопок, затем мы знаем, что пользователю необходимо повернуть.

Когда мы повернуть мы исчезания и появление с помощью простой сценарий с именем «исчезания элемента управления». Это делается для предотвратить просмотр искусственных перемещения, что может привести к discomfort пользователя. Исчезания и уменьшения эффекта достаточно прост. У нас есть черные квадрант, выступающие в начале **главной камеры**. Когда исчезновение перехода альфа-значение от 0 до 1. Постепенно в результате области черных пикселей из четырех, чтобы отображать и скрывать все, за ними. Когда плавный переход обратно в перехода альфа-значение к нулю.

Когда мы вычисляем поворот, обратите внимание, что нам требуется сменить наших **наличия прицепа к арендованному** , но вычисление поворота вокруг **главной камеры**. Это важно, так как дальше **главной камеры** нахождение вдали 0,0,0, тем менее точным поворот вокруг наличия прицепа к арендованному стал бы с точки зрения пользователя. На самом деле, если вы не вращаются вокруг положение камеры, пользователь будет перемещен в дугу вокруг **наличия прицепа к арендованному** вместо того чтобы поворот.

Второе задание для MixedRealityTeleport — переключаются **наличия прицепа к арендованному**. Это делается в SetWorldPosition. SetWorldPosition занимает позицию нужного world позицию, где пользователь хочет percieve, они находятся. Нам нужно поместить наш **наличия прицепа к арендованному** в этой позиции минус локального положение **главной камеры**, поскольку этому смещению появляются в каждом кадре.

Второй сценарий вызывает SetWorldPosition. Давайте взглянем на этот скрипт. На панели «проект» перейдите к **Assets\AppPrefabs\Support\Scripts\GameLogic** и дважды щелкните **TeleportScript.cs**.

Этот сценарий немного сложнее, чем MixedRealityTeleport. Сценарий проверяет наличие Y кнопки контроллера Xbox пройдет. Во время удержания кнопки вниз teleport курсор отображается и скрипт приводит лучом, проведенным из положение взглядом пользователя. Если, Рэй конфликтует с поверхностью, больше или меньше указывающая вверх, рабочей области будет считаться хорошим область, чтобы teleport для, и анимации для курсора teleport будет включена. Если луч не пересекается с поверхность более или менее, указывающего, анимации на курсор будет недоступен. При отпускании кнопки Y и вычисляемые луча, она допустимую позицию, сценарий вызывает SetWorldPosition с позицией, пересеченной лучом.

### <a name="enjoy-your-progress"></a>Наслаждайтесь хода выполнения

Это время необходимо найти друга.

Опять же пользователь с HoloLens будет поддерживать сеанс. Другим пользователям будет подключиться к сеансу. Приложение будет помещен в первых трех пользователей, для присоединения из иммерсивных гарнитура на один из трех путей на острове. Вы можете просмотреть острова, которая в этом разделе.

Сведения о необходимо обратить внимание:
1. Вы увидите лиц в облаках, что позволяет пользователю immersed направление, в котором пользователь HoloLens см. в разделе.
2. Аватары на острове имеют necks, поворот. Они не соответствуют действия пользователя является реальной (мы не смогли их), но оно делает, неплохо работать.
3. Если пользователь HoloLens просматривает островом, immersed пользователи могут просматривать их курсора.
4. Облаках, которые представляют пользователей, HoloLens приведение теней.

## <a name="chapter-5---finale"></a>Глава 5 - некоторые

>[!VIDEO https://www.youtube.com/embed/n_HDWJbfpNg]

### <a name="objectives"></a>Цели

Создайте интерактивные возможности для совместной работы между типами двух устройств.

### <a name="what-we-will-build"></a>Мы построим

Пользователи HoloLens, основываясь на главе 4, когда пользователь с иммерсивных гарнитура получает практически головоломку на острове, получат всплывающей подсказкой с ключом к головоломки. После всех пользователей иммерсивных гарнитура получить прошлые головоломок и на «Готово pad» в комнате rocket, ракеты приведет к запуску.

### <a name="steps"></a>Действия
* В **иерархии**выберите **Usland**.
* В **инспектор**в **уровень управления**, проверьте **включить совместной работы**.

### <a name="digging-into-the-code"></a>Подробно о коде

Теперь давайте рассмотрим LevelControl.cs. Этот сценарий является основой логику игры и обслуживает состояния игры. Так как это игры с помощью UNET нам нужно понять, как данные перемещаются, по крайней мере достаточной для изменения в этом руководстве. Для более полного представления о UNET обратитесь к документации Unity.

На панели «проект» перейдите к **Assets\AppPrefabs\Support\Scripts\GameLogic** и дважды щелкните **LevelControl.cs**.

Сообщите нам понять, как иммерсивных гарнитура сообщает, что они готовы к запуску rocket. При установке одного из трех логические в список, соответствующие трем способам на острове логические сообщаются Rocket запуска готовности. Bool контура устанавливается при пользователя, присвоенный пути находится на вершине коричневая панель внутри rocket комнаты. Итак, теперь к деталям.

Мы начнем в функцию Update(). Обратите внимание, что имеется функция «по системам». Мы использовали это в разработке для тестирования rocket запуска и выполнить сброс последовательности. Это не сработает во взаимодействие с пользователем с несколькими. Будем надеяться, что к моменту усвоить следующие сведения можно сделать это в действии. После мы проверяем, см. в разделе, если следует схитрить, мы проверяем, если immersed локального проигрывателя. Мы хотим сосредоточиться на том, как мы находят, что мы находимся на цель. Внутри if (Immersed) Проверьте, имеется вызов CheckGoal скрытие за **EnableCollaboration** bool. Это соответствует флажок, извлеченного при помощью шагов, описанных в этой главе. Внутри EnableCollaboration мы видим, вызов CheckGoal().

CheckGoal выполняет некоторые расчеты, чтобы узнать, если мы более или менее положение на панели. Когда мы, мы Debug.Log «Прибыло в цель» и затем мы вызовите «SendAtGoalMessage()». В SendAtGoalMessage мы вызываем playerController.SendAtGoal. Чтобы сэкономить время, ниже приведен код:

```cs
private void CmdSendAtGoal(int GoalIndex)
       {
           levelState.SetGoalIndex(GoalIndex);
       }
```

```cs
public void SendAtGoal(int GoalIndex)
       {
           if (isLocalPlayer)
           {
               Debug.Log("sending at goal " + GoalIndex);
               CmdSendAtGoal(GoalIndex);
           }
       }
```

Обратите внимание на то, что SendAtGoalMessage вызывает CmdSendAtGoal, какие levelState.SetGoalIndex вызовы, обратно в LevelControl.cs. На первый взгляд это кажется странным. Почему просто не вызвать SetGoalIndex, а не это странное маршрутизации через контроллер проигрывателя? Причина в том, что мы удовлетворяющие модели данных, которые UNET использует для синхронизации данных. Чтобы избежать обмана и пробуксовка, UNET наличие у каждого объекта пользователя, имеющего позволяют изменять синхронизированные переменные. Кроме того только узла (пользователя, запустившего сеанс) могут изменять данные напрямую. Пользователей, которые не являются узла, но имеет полномочия, необходимые для отправки «команды» узлу, который будет изменить переменную. По умолчанию узел имеет полномочия на все объекты, за исключением объекта, сформированными для представления пользователю. В нашем случае этот объект имеет playercontroller скрипт. Есть способ запросить полномочия для объекта, а затем внесите изменения, но мы решили использовать факт, что контроллер проигрыватель имеет собственный центр и маршрута команды через контроллер проигрывателя.

Другими словами, при выяснилось, что сами в нашей цели, игроку необходимо сообщить этому приложению, и узел сообщит, все остальные.

В обзор LevelControl.cs SetGoalIndex. Здесь мы задав значение в synclist (AtGoal). Помните, мы находятся в контексте узла хотя мы это делать. Как и команды, RPC еще кое-узел может выдавать, вызовет все клиенты должны выполнять определенный код. Здесь мы называем «RpcCheckAllGoals». Каждый клиент отдельно проверьте, если заданы все три AtGoals и если да, запустить ракеты.

### <a name="enjoy-your-progress"></a>Наслаждайтесь хода выполнения

Основываясь на предыдущей главе, мы начнем сеанс как перед. Это время, как пользователи в иммерсивных гарнитура get на «дверца» пути к их появляется всплывающая подсказка, видно только те пользователи, HoloLens. HoloLens пользователи отвечают за связь этой информации пользователей в иммерсивных гарнитуры. Игра rocket приведет к запуску пространство после каждого аватар зашел в его соответствующий коричневая панель внутри вулкана. Сцены сбросит через 60 секунд, чтобы делать это снова.

## <a name="see-also"></a>См. также
* [Входные данные MR 213: Контроллеры движения](mixed-reality-213.md)
