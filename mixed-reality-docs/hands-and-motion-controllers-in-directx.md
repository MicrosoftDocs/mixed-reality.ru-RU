---
title: Руки и контроллеры движения в DirectX
description: Руководство разработчика по использованию отслеживания вручную и контроллеры движения в собственных приложениях DirectX.
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/30/2019
ms.topic: article
keywords: руки, контроллеры движения, directx, входные данные, голограммы
ms.openlocfilehash: 08666c8c26cd4851c0c003a96a9e96d7a90228ac
ms.sourcegitcommit: 45676da11ebe33a2aa3dccec0e8ad7d714420853
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/15/2019
ms.locfileid: "65629647"
---
# <a name="hands-and-motion-controllers-in-directx"></a><span data-ttu-id="40f6a-104">Руки и контроллеры движения в DirectX</span><span class="sxs-lookup"><span data-stu-id="40f6a-104">Hands and motion controllers in DirectX</span></span>

<span data-ttu-id="40f6a-105">В Windows Mixed Reality, обе стороны и [контроллера движения](motion-controllers.md) входных данных осуществляется через пространственных входные данные API, в [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) пространства имен.</span><span class="sxs-lookup"><span data-stu-id="40f6a-105">In Windows Mixed Reality, both hand and [motion controller](motion-controllers.md) input is handled through the spatial input APIs, found in the [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) namespace.</span></span> <span data-ttu-id="40f6a-106">Это позволяет с легкостью выполнить общие действия, такие как **выберите** нажимает так же, как в руки и контроллеры движения.</span><span class="sxs-lookup"><span data-stu-id="40f6a-106">This enables you to easily handle common actions like **Select** presses the same way across both hands and motion controllers.</span></span>

## <a name="getting-started"></a><span data-ttu-id="40f6a-107">Начало работы</span><span class="sxs-lookup"><span data-stu-id="40f6a-107">Getting started</span></span>

<span data-ttu-id="40f6a-108">Пространственные доступ ввода в Windows Mixed Reality начните с SpatialInteractionManager интерфейс.</span><span class="sxs-lookup"><span data-stu-id="40f6a-108">To access spatial input in Windows Mixed Reality, start with the SpatialInteractionManager interface.</span></span>  <span data-ttu-id="40f6a-109">Этот интерфейс может быть открыт, вызвав [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), обычно иногда во время запуска приложения.</span><span class="sxs-lookup"><span data-stu-id="40f6a-109">You can access this interface by calling  [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), typically sometime during app startup.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

SpatialInteractionManager interactionManager = SpatialInteractionManager::GetForCurrentView();
```

<span data-ttu-id="40f6a-110">Задание SpatialInteractionManager заключается в предоставлении доступа к [SpatialInteractionSources](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource), который представляет источник входных данных.</span><span class="sxs-lookup"><span data-stu-id="40f6a-110">The SpatialInteractionManager's job is to provide access to [SpatialInteractionSources](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource), which represent a source of input.</span></span>  <span data-ttu-id="40f6a-111">Существует три вида SpatialInteractionSources, доступных в системе.</span><span class="sxs-lookup"><span data-stu-id="40f6a-111">There are three kinds of SpatialInteractionSources available in the system.</span></span>
* <span data-ttu-id="40f6a-112">**Рука** представляет обнаруженных руку пользователя.</span><span class="sxs-lookup"><span data-stu-id="40f6a-112">**Hand** represents a user's detected hand.</span></span> <span data-ttu-id="40f6a-113">Рука источников, предлагают различные функции, на основе устройства, от простейших жестов на HoloLens полные руки, отслеживания на HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="40f6a-113">Hand sources offer different features based on the device, ranging from basic gestures on HoloLens to fully articulated hand tracking on HoloLens 2.</span></span> 
* <span data-ttu-id="40f6a-114">**Контроллер** представляет контроллер парных движения.</span><span class="sxs-lookup"><span data-stu-id="40f6a-114">**Controller** represents a paired motion controller.</span></span> <span data-ttu-id="40f6a-115">Контроллеры движения могут предлагать широкий набор возможностей.</span><span class="sxs-lookup"><span data-stu-id="40f6a-115">Motion controllers can offer a variety of capabilities.</span></span>  <span data-ttu-id="40f6a-116">Пример: Выберите триггеры, кнопки меню, кнопки коммерческих тайн, сенсорные панели и thumbsticks.</span><span class="sxs-lookup"><span data-stu-id="40f6a-116">For example: Select triggers, Menu buttons, Grasp buttons, touchpads and thumbsticks.</span></span>
* <span data-ttu-id="40f6a-117">**Голосовые** представляет голос пользователя, говоря система обнаружила ключевые слова.</span><span class="sxs-lookup"><span data-stu-id="40f6a-117">**Voice** represents the user's voice speaking system-detected keywords.</span></span> <span data-ttu-id="40f6a-118">Например этот источник будет внедрить выберите press и выпуска всякий раз, когда пользователь скажет: «Выбрать».</span><span class="sxs-lookup"><span data-stu-id="40f6a-118">For example, this source will inject a Select press and release whenever the user says "Select".</span></span>

<span data-ttu-id="40f6a-119">Кадров данных для представленного источника [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) интерфейс.</span><span class="sxs-lookup"><span data-stu-id="40f6a-119">Per-frame data for a source is represented by the  [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interface.</span></span> <span data-ttu-id="40f6a-120">Доступ к этим данным, в зависимости от того, требуется ли использовать модель управляемых событиями или на основе опроса в приложении двумя способами.</span><span class="sxs-lookup"><span data-stu-id="40f6a-120">There are two different ways to access this data, depending on whether you want to use an event-driven or polling-based model in your application.</span></span>

### <a name="event-driven-input"></a><span data-ttu-id="40f6a-121">Входные данные на основе событий</span><span class="sxs-lookup"><span data-stu-id="40f6a-121">Event-driven input</span></span>
<span data-ttu-id="40f6a-122">SpatialInteractionManager предоставляет ряд событий, которые приложение может прослушивать.</span><span class="sxs-lookup"><span data-stu-id="40f6a-122">The SpatialInteractionManager provides a number of events that your app can listen for.</span></span>  <span data-ttu-id="40f6a-123">Некоторые включают [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) и [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span><span class="sxs-lookup"><span data-stu-id="40f6a-123">A few examples include   [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span></span>

<span data-ttu-id="40f6a-124">Например следующий код подключает обработчик событий вызывается MyApp::OnSourcePressed SourcePressed событие.</span><span class="sxs-lookup"><span data-stu-id="40f6a-124">For example, the following code hooks up an event handler called MyApp::OnSourcePressed to the SourcePressed event.</span></span>  <span data-ttu-id="40f6a-125">Благодаря этому приложение для обнаружения нажатий на любой тип источника взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="40f6a-125">This allows your app to detect presses on any type of interaction source.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
interactionManager.SourcePressed({ this, &MyApp::OnSourcePressed });

```

<span data-ttu-id="40f6a-126">Это событие нажатия асинхронно, отправляется в приложение вместе с соответствующей SpatialInteractionSourceState во время произошло прессе.</span><span class="sxs-lookup"><span data-stu-id="40f6a-126">This pressed event is sent to your app asynchronously, along with the corresponding SpatialInteractionSourceState at the time the press happened.</span></span> <span data-ttu-id="40f6a-127">Ваше приложение или игровое ядро может потребоваться выполнить некоторые задачи обработки прямо сейчас или требуется поставить данные событий в подпрограмму обработки входных данных.</span><span class="sxs-lookup"><span data-stu-id="40f6a-127">Your app or game engine may want to perform some processing right away or you may want to queue up the event data in your input processing routine.</span></span> <span data-ttu-id="40f6a-128">Вот функцию обработчика событий для события SourcePressed, которое показывает, как проверить, была ли нажата кнопка "выбрать".</span><span class="sxs-lookup"><span data-stu-id="40f6a-128">Here is an event handler function for the SourcePressed event, which shows how to check whether the select button was pressed.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

void MyApp::OnSourcePressed(SpatialInteractionManager const& sender, SpatialInteractionSourceEventArgs const& args)
{
    if (args.PressKind() == SpatialInteractionPressKind::Select)
    {
        // Select button was pressed, update app state
    }
}
```

<span data-ttu-id="40f6a-129">Приведенный выше код проверяет только «Select» press, который соответствует основное действие на устройстве.</span><span class="sxs-lookup"><span data-stu-id="40f6a-129">The above code only checks for the 'Select' press, which corresponds to the primary action on the device.</span></span> <span data-ttu-id="40f6a-130">Примеры выполнения AirTap на HoloLens или извлечение триггер на контроллере движения.</span><span class="sxs-lookup"><span data-stu-id="40f6a-130">Examples include doing an AirTap on HoloLens or pulling the trigger on a motion controller.</span></span>  <span data-ttu-id="40f6a-131">При нажатии «Select» представляют намерение пользователя активировать голограмма, который их используете.</span><span class="sxs-lookup"><span data-stu-id="40f6a-131">'Select' presses represent the user's intention to activate the hologram they are targeting.</span></span>  <span data-ttu-id="40f6a-132">SourcePressed событие будет срабатывать по ряду кнопок и жестов, и вы можете проверить другие свойства SpatialInteractionSource для тестирования в тех случаях.</span><span class="sxs-lookup"><span data-stu-id="40f6a-132">The SourcePressed event will fire for a number of different buttons and gestures, and you can inspect other properties on the SpatialInteractionSource to test for those cases.</span></span>

### <a name="polling-based-input"></a><span data-ttu-id="40f6a-133">Ввод на основе опроса</span><span class="sxs-lookup"><span data-stu-id="40f6a-133">Polling-based input</span></span>
<span data-ttu-id="40f6a-134">Также можно SpatialInteractionManager для опроса текущее состояние ввода каждого кадра.</span><span class="sxs-lookup"><span data-stu-id="40f6a-134">You can also use SpatialInteractionManager to poll for the current state of input every frame.</span></span>  <span data-ttu-id="40f6a-135">Чтобы сделать это, просто вызовите [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) каждого кадра.</span><span class="sxs-lookup"><span data-stu-id="40f6a-135">To do this, simply call [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) every frame.</span></span>  <span data-ttu-id="40f6a-136">Эта функция возвращает массив, содержащий один [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) для каждого активного [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="40f6a-136">This function returns an array containing one [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) for every active [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span> <span data-ttu-id="40f6a-137">Это означает одна для каждого контроллера active движения, для каждой отслеживаемой стрелки и один для распознавания речи, если был недавно распространенная команду «select».</span><span class="sxs-lookup"><span data-stu-id="40f6a-137">This means one for each active motion controller, one for each tracked hand, and one for speech if a 'select' command was recently uttered.</span></span> <span data-ttu-id="40f6a-138">Это позволяет проверить свойства каждого SpatialInteractionSourceState для входных данных с диска в приложение.</span><span class="sxs-lookup"><span data-stu-id="40f6a-138">You can then inspect the properties on each SpatialInteractionSourceState to drive input into your application.</span></span> 

<span data-ttu-id="40f6a-139">Вот пример того, как для проверки для действия «выберите» использование метода опроса.</span><span class="sxs-lookup"><span data-stu-id="40f6a-139">Here is an example of how to check for the 'select' action using the polling method.</span></span> <span data-ttu-id="40f6a-140">Обратите внимание, что *прогноза* переменная представляет [HolographicFramePrediction](https://docs.microsoft.com/en-us/uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) объект, который может быть получен из [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="40f6a-140">Note that the *prediction* variable represents a [HolographicFramePrediction](https://docs.microsoft.com/en-us/uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) object, which can be obtained from the [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
auto sourceStates = m_spatialInteractionManager.GetDetectedSourcesAtTimestamp(prediction.Timestamp());

for (auto& sourceState : sourceStates)
{
    if (sourceState.IsSelectPressed())
    {
        // Select button is down, update app state
    }
}
```

<span data-ttu-id="40f6a-141">Каждый SpatialInteractionSource имеет идентификатор, который можно использовать для определения новых источников и сопоставить существующие источники из фрейма.</span><span class="sxs-lookup"><span data-stu-id="40f6a-141">Each SpatialInteractionSource has an ID, which you can use to identify new sources and correlate existing sources from frame to frame.</span></span>  <span data-ttu-id="40f6a-142">Руки присваивается новый идентификатор каждый раз, они оставьте и введите FOV, но идентификаторов оставаться статическим в течение сеанса.</span><span class="sxs-lookup"><span data-stu-id="40f6a-142">Hands are assigned a new ID every time they leave and enter the FOV, but controller IDs remain static for the duration of the session.</span></span>  <span data-ttu-id="40f6a-143">Можно использовать события на SpatialInteractionManager например [SourceDetected](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) и [SourceLost](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), представления реагировать руки введите или устройство, или при контроллеры движения включить и выключить или, в паре/непарный.</span><span class="sxs-lookup"><span data-stu-id="40f6a-143">You can use the events on SpatialInteractionManager such as [SourceDetected](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) and [SourceLost](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), to react when hands enter or leave the device's view, or when motion controllers are turned on/off or are paired/unpaired.</span></span>

### <a name="predicted-vs-historical-poses"></a><span data-ttu-id="40f6a-144">Прогнозируемые и ведением журнала создает</span><span class="sxs-lookup"><span data-stu-id="40f6a-144">Predicted vs. historical poses</span></span>
<span data-ttu-id="40f6a-145">Обратите внимание, что GetDetectedSourcesAtTimestamp параметра метки времени.</span><span class="sxs-lookup"><span data-stu-id="40f6a-145">Note that GetDetectedSourcesAtTimestamp has a timestamp parameter.</span></span> <span data-ttu-id="40f6a-146">Это позволяет состояние запроса и представлять данные, либо прогнозируемое или журнала, что вы сопоставлять пространственных взаимодействия с другими источниками входных данных.</span><span class="sxs-lookup"><span data-stu-id="40f6a-146">This enables you to request state and pose data that is either predicted or historical, letting you correlate spatial interactions with other sources of input.</span></span> <span data-ttu-id="40f6a-147">Например, при подготовке к просмотру наличии позицию в текущем кадре, можно передать прогнозируемое timestamp, предоставляемые [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="40f6a-147">For example, when rendering the hand's position in the current frame, you can pass in the predicted timestamp provided by the [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span></span> <span data-ttu-id="40f6a-148">Это позволяет системе прогнозировать вперед положение руки для приведения их с выходными данными Отрисованный кадр, сводя к минимуму наблюдаемой задержки.</span><span class="sxs-lookup"><span data-stu-id="40f6a-148">This enables the system to forward-predict the hand position to closely align with the rendered frame output, minimizing perceived latency.</span></span>

<span data-ttu-id="40f6a-149">Тем не менее прогнозируемое поза не создает идеальный указывающего Рэй для нацеливания с источником взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="40f6a-149">However, such a predicted pose does not produce an ideal pointing ray for targeting with an interaction source.</span></span> <span data-ttu-id="40f6a-150">Например при нажатии кнопки контроллера движения, может занять до 20 мс для этого события всплывать через Bluetooth в операционную систему.</span><span class="sxs-lookup"><span data-stu-id="40f6a-150">For example, when a motion controller button is pressed, it can take up to 20ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="40f6a-151">Аналогичным образом после выполнении пользователем жеста руки, некоторое время может понадобиться система обнаруживает жест и приложения, а затем выполняет опрос для него.</span><span class="sxs-lookup"><span data-stu-id="40f6a-151">Similarly, after a user performs a hand gesture, some amount of time may pass before the system detects the gesture and your app then polls for it.</span></span> <span data-ttu-id="40f6a-152">Когда приложение выполняет опрос для изменения состояния создает head и наличии используется для целевой объект, который взаимодействия фактически произошло в прошлом.</span><span class="sxs-lookup"><span data-stu-id="40f6a-152">By the time your app polls for a state change, the head and hand poses used to target that interaction actually happened in the past.</span></span> <span data-ttu-id="40f6a-153">Если вы устанавливаете путем передачи timestamp вашей текущей HolographicFrame GetDetectedSourcesAtTimestamp, позу вместо вперед прогнозируемой для нацеливания луч во время кадра отображается, в которой может быть более чем 20 мс, в будущем.</span><span class="sxs-lookup"><span data-stu-id="40f6a-153">If you target by passing your current HolographicFrame's timestamp to GetDetectedSourcesAtTimestamp, the pose will instead be forward predicted to the targeting ray at the time the frame will be displayed, which could be more than 20ms in the future.</span></span> <span data-ttu-id="40f6a-154">Этот будущих поза хорошо подходит для *отрисовки* источника взаимодействия, но приводит к увеличению наша проблема времени для *нацеливания* взаимодействия, как пользователь предназначенных для произошло в прошлом.</span><span class="sxs-lookup"><span data-stu-id="40f6a-154">This future pose is good for *rendering* the interaction source, but compounds our time problem for *targeting* the interaction, as the user's targeting occurred in the past.</span></span>

<span data-ttu-id="40f6a-155">К счастью [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) и [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) события предоставляют исторических [состояние](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) связанные с Каждое событие ввода.</span><span class="sxs-lookup"><span data-stu-id="40f6a-155">Fortunately, the [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) events provide the historical [State](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associated with each input event.</span></span>  <span data-ttu-id="40f6a-156">Это напрямую включает в себя исторические head и наличии создает, доступных через [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), вместе с ведением журнала [Timestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) , можно передать в другие API-интерфейсы для корреляции с этим событием.</span><span class="sxs-lookup"><span data-stu-id="40f6a-156">This directly includes the historical head and hand poses available through [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), along with a historical [Timestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) that you can pass to other APIs to correlate with this event.</span></span>

<span data-ttu-id="40f6a-157">Это ведет к следующие рекомендации при визуализации и определение целевых объектов с руки и контроллеры каждого кадра:</span><span class="sxs-lookup"><span data-stu-id="40f6a-157">That leads to the following best practices when rendering and targeting with hands and controllers each frame:</span></span>
* <span data-ttu-id="40f6a-158">Для **наличии/контроллер отрисовки** каждого кадра, приложение должно **опроса** для **прогнозируемые вперед** представлять каждого источника взаимодействия во время photon текущего кадра.</span><span class="sxs-lookup"><span data-stu-id="40f6a-158">For **hand/controller rendering** each frame, your app should **poll** for the **forward-predicted** pose of each interaction source at the current frame’s photon time.</span></span>  <span data-ttu-id="40f6a-159">Можно выполнить опрос для всех источников взаимодействия, вызвав [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) каждого кадра, передавая прогнозируемые метки времени, предоставляемые [HolographicFrame::CurrentPrediction](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span><span class="sxs-lookup"><span data-stu-id="40f6a-159">You can poll for all interaction sources by calling [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) each frame, passing in the predicted timestamp provided by [HolographicFrame::CurrentPrediction](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span></span>
* <span data-ttu-id="40f6a-160">Для **нацеливание стороны/контроллер** по press или выпуска, приложения должны обрабатывать нажата и отпущена **события**, точные точки для отслеживания на основе **исторических** поза head или вручную для Это событие.</span><span class="sxs-lookup"><span data-stu-id="40f6a-160">For **hand/controller targeting** upon a press or release, your app should handle pressed/released **events**, raycasting based on the **historical** head or hand pose for that event.</span></span> <span data-ttu-id="40f6a-161">Вы получаете этот нацеливания Рэй путем обработки [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) или [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) событий, начало [состояние](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) свойства из аргументов события и последующего вызова его [ TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) метод.</span><span class="sxs-lookup"><span data-stu-id="40f6a-161">You get this targeting ray by handling the [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) or [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) event, getting the [State](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) property from the event arguments, and then calling its [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) method.</span></span>

## <a name="cross-device-input-properties"></a><span data-ttu-id="40f6a-162">Входные свойства между устройствами</span><span class="sxs-lookup"><span data-stu-id="40f6a-162">Cross-device input properties</span></span>
<span data-ttu-id="40f6a-163">Этот API SpatialInteractionSource поддерживает контроллеры и наличии отслеживания системах с широким диапазоном возможностей.</span><span class="sxs-lookup"><span data-stu-id="40f6a-163">The SpatialInteractionSource API supports controllers and hand tracking systems with a wide range of capabilities.</span></span> <span data-ttu-id="40f6a-164">Несколько эти возможности, общие для различных типов устройств.</span><span class="sxs-lookup"><span data-stu-id="40f6a-164">A number of these capabilities are common between device types.</span></span> <span data-ttu-id="40f6a-165">К примеру вручную отслеживания движения контроллеры и оба предоставляют действием «select», а также трехмерного положения.</span><span class="sxs-lookup"><span data-stu-id="40f6a-165">For example, hand tracking and motion controllers both provide a 'select' action and a 3D position.</span></span> <span data-ttu-id="40f6a-166">По возможности API сопоставляется те же свойства на SpatialInteractionSource эти общие возможности.</span><span class="sxs-lookup"><span data-stu-id="40f6a-166">Wherever possible, the API maps these common capabilities to the same properties on the SpatialInteractionSource.</span></span>  <span data-ttu-id="40f6a-167">Это позволяет приложениям более просто поддерживать широкий спектр типов входных данных.</span><span class="sxs-lookup"><span data-stu-id="40f6a-167">This enables applications to more easily support a wide range of input types.</span></span> <span data-ttu-id="40f6a-168">В следующей таблице описаны свойства, которые поддерживаются, и об отличиях между типов входных данных.</span><span class="sxs-lookup"><span data-stu-id="40f6a-168">The following table describes the properties that are supported, and how they compare across input types.</span></span>

| <span data-ttu-id="40f6a-169">Свойство</span><span class="sxs-lookup"><span data-stu-id="40f6a-169">Property</span></span> | <span data-ttu-id="40f6a-170">Описание</span><span class="sxs-lookup"><span data-stu-id="40f6a-170">Description</span></span> | <span data-ttu-id="40f6a-171">Жесты HoloLens</span><span class="sxs-lookup"><span data-stu-id="40f6a-171">HoloLens Gestures</span></span> | <span data-ttu-id="40f6a-172">Контроллеры движения</span><span class="sxs-lookup"><span data-stu-id="40f6a-172">Motion Controllers</span></span> | <span data-ttu-id="40f6a-173">Ясно сформулированные руки</span><span class="sxs-lookup"><span data-stu-id="40f6a-173">Articulated Hands</span></span>|
|--- |--- |--- |--- |--- |
| [<span data-ttu-id="40f6a-174">SpatialInteractionSource::**рабочей руки пользователя**</span><span class="sxs-lookup"><span data-stu-id="40f6a-174">SpatialInteractionSource::**Handedness**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.handedness) | <span data-ttu-id="40f6a-175">Справа или слева / контроллера.</span><span class="sxs-lookup"><span data-stu-id="40f6a-175">Right or left hand / controller.</span></span> | <span data-ttu-id="40f6a-176">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-176">Not Supported</span></span> | <span data-ttu-id="40f6a-177">Поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-177">Supported</span></span> | <span data-ttu-id="40f6a-178">Поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-178">Supported</span></span> |
| [<span data-ttu-id="40f6a-179">SpatialInteractionSourceState::**IsSelectPressed**</span><span class="sxs-lookup"><span data-stu-id="40f6a-179">SpatialInteractionSourceState::**IsSelectPressed**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isselectpressed) | <span data-ttu-id="40f6a-180">Текущее состояние основную кнопку.</span><span class="sxs-lookup"><span data-stu-id="40f6a-180">Current state of the primary button.</span></span> | <span data-ttu-id="40f6a-181">Жест касания</span><span class="sxs-lookup"><span data-stu-id="40f6a-181">Air Tap</span></span> | <span data-ttu-id="40f6a-182">триггер</span><span class="sxs-lookup"><span data-stu-id="40f6a-182">Trigger</span></span> | <span data-ttu-id="40f6a-183">Нестрогой Air коснитесь (вертикальное сжатие)</span><span class="sxs-lookup"><span data-stu-id="40f6a-183">Relaxed Air Tap (upright pinch)</span></span> |
| [<span data-ttu-id="40f6a-184">SpatialInteractionSourceState::**IsGrasped**</span><span class="sxs-lookup"><span data-stu-id="40f6a-184">SpatialInteractionSourceState::**IsGrasped**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isgrasped) | <span data-ttu-id="40f6a-185">Текущее состояние кнопки захвата.</span><span class="sxs-lookup"><span data-stu-id="40f6a-185">Current state of the grab button.</span></span> | <span data-ttu-id="40f6a-186">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-186">Not Supported</span></span> | <span data-ttu-id="40f6a-187">Кнопки захвата</span><span class="sxs-lookup"><span data-stu-id="40f6a-187">Grab button</span></span> | <span data-ttu-id="40f6a-188">Жест сжатия или закрытое вручную</span><span class="sxs-lookup"><span data-stu-id="40f6a-188">Pinch or Closed Hand</span></span> |
| [<span data-ttu-id="40f6a-189">SpatialInteractionSourceState::**IsMenuPressed**</span><span class="sxs-lookup"><span data-stu-id="40f6a-189">SpatialInteractionSourceState::**IsMenuPressed**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.ismenupressed) | <span data-ttu-id="40f6a-190">Текущее состояние кнопки меню.</span><span class="sxs-lookup"><span data-stu-id="40f6a-190">Current state of the menu button.</span></span>    | <span data-ttu-id="40f6a-191">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-191">Not Supported</span></span> | <span data-ttu-id="40f6a-192">Кнопки меню</span><span class="sxs-lookup"><span data-stu-id="40f6a-192">Menu Button</span></span> | <span data-ttu-id="40f6a-193">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-193">Not Supported</span></span> |
| [<span data-ttu-id="40f6a-194">SpatialInteractionSourceLocation::**позиции**</span><span class="sxs-lookup"><span data-stu-id="40f6a-194">SpatialInteractionSourceLocation::**Position**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.position) | <span data-ttu-id="40f6a-195">Местоположение XYZ вручную или захвата для изменения позиции на контроллере.</span><span class="sxs-lookup"><span data-stu-id="40f6a-195">XYZ location of the hand or grip position on the controller.</span></span> | <span data-ttu-id="40f6a-196">Расположение Palm</span><span class="sxs-lookup"><span data-stu-id="40f6a-196">Palm location</span></span> | <span data-ttu-id="40f6a-197">Позиция поза захвата для изменения</span><span class="sxs-lookup"><span data-stu-id="40f6a-197">Grip pose position</span></span> | <span data-ttu-id="40f6a-198">Расположение Palm</span><span class="sxs-lookup"><span data-stu-id="40f6a-198">Palm location</span></span> |
| [<span data-ttu-id="40f6a-199">SpatialInteractionSourceLocation::**ориентации**</span><span class="sxs-lookup"><span data-stu-id="40f6a-199">SpatialInteractionSourceLocation::**Orientation**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.orientation) | <span data-ttu-id="40f6a-200">Кватернион, представляющий ориентацию позу вручную или захвата для изменения на контроллере.</span><span class="sxs-lookup"><span data-stu-id="40f6a-200">Quaternion representing the orientation of the hand or grip pose on the controller.</span></span> | <span data-ttu-id="40f6a-201">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-201">Not Supported</span></span> | <span data-ttu-id="40f6a-202">Ориентация поза захвата для изменения</span><span class="sxs-lookup"><span data-stu-id="40f6a-202">Grip pose orientation</span></span> | <span data-ttu-id="40f6a-203">Ориентация Palm</span><span class="sxs-lookup"><span data-stu-id="40f6a-203">Palm orientation</span></span> |
| [<span data-ttu-id="40f6a-204">SpatialPointerInteractionSourcePose::**позиции**</span><span class="sxs-lookup"><span data-stu-id="40f6a-204">SpatialPointerInteractionSourcePose::**Position**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.position#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_Position) | <span data-ttu-id="40f6a-205">Начало координат луча, указывающего.</span><span class="sxs-lookup"><span data-stu-id="40f6a-205">Origin of the pointing ray.</span></span> | <span data-ttu-id="40f6a-206">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-206">Not Supported</span></span> | <span data-ttu-id="40f6a-207">Поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-207">Supported</span></span> | <span data-ttu-id="40f6a-208">Поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-208">Supported</span></span> |
| [<span data-ttu-id="40f6a-209">SpatialPointerInteractionSourcePose::**ForwardDirection**</span><span class="sxs-lookup"><span data-stu-id="40f6a-209">SpatialPointerInteractionSourcePose::**ForwardDirection**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.forwarddirection#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_ForwardDirection) | <span data-ttu-id="40f6a-210">Направление луча, указывающего.</span><span class="sxs-lookup"><span data-stu-id="40f6a-210">Direction of the pointing ray.</span></span> | <span data-ttu-id="40f6a-211">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-211">Not Supported</span></span> | <span data-ttu-id="40f6a-212">Поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-212">Supported</span></span> | <span data-ttu-id="40f6a-213">Поддерживается</span><span class="sxs-lookup"><span data-stu-id="40f6a-213">Supported</span></span> |

<span data-ttu-id="40f6a-214">Некоторые из указанных выше свойств доступны не на всех устройствах, и API-Интерфейс позволяет проверить это.</span><span class="sxs-lookup"><span data-stu-id="40f6a-214">Some of the above properties are not available on all devices, and the API provides a means to test for this.</span></span> <span data-ttu-id="40f6a-215">Например, вы можете проверить [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) свойства, чтобы определить, предоставляет ли источник действия может воспользоваться.</span><span class="sxs-lookup"><span data-stu-id="40f6a-215">For example, you can inspect the [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) property to determine whether the source provides a grasp action.</span></span>

### <a name="grip-pose-vs-pointing-pose"></a><span data-ttu-id="40f6a-216">Поза захвата для изменения и указывающего поза</span><span class="sxs-lookup"><span data-stu-id="40f6a-216">Grip pose vs. pointing pose</span></span>

<span data-ttu-id="40f6a-217">Смешанная реальность Windows поддерживает движения контроллеров в различных форм-факторов.</span><span class="sxs-lookup"><span data-stu-id="40f6a-217">Windows Mixed Reality supports motion controllers in a variety of form factors.</span></span>  <span data-ttu-id="40f6a-218">Она также поддерживает ясно сформулированные наличии системы по отслеживанию.</span><span class="sxs-lookup"><span data-stu-id="40f6a-218">It also supports articulated hand tracking systems.</span></span>  <span data-ttu-id="40f6a-219">Все эти системы обладают разным связям между положением руки и естественным «вперед», приложения должны использовать для команды или rendreing объектов в руки пользователя.</span><span class="sxs-lookup"><span data-stu-id="40f6a-219">All of these systems have different relationships between the hand position and the natural "forward" direction that apps should use for pointing or rendreing objects in the user's hand.</span></span>  <span data-ttu-id="40f6a-220">Для поддержки все это, существует два вида 3D создает для обоих контроллеров отслеживания и перемещения вручную.</span><span class="sxs-lookup"><span data-stu-id="40f6a-220">To support all of this, there are two types of 3D poses provided for both hand tracking and motion controllers.</span></span>  <span data-ttu-id="40f6a-221">Во-первых, поза захвата для изменения, который представляет положение руки пользователя.</span><span class="sxs-lookup"><span data-stu-id="40f6a-221">The first is grip pose, which represents the user's hand position.</span></span>  <span data-ttu-id="40f6a-222">Вторая указывает поза, который представляет указывающего луча, исходящие от руки пользователя или контроллера.</span><span class="sxs-lookup"><span data-stu-id="40f6a-222">The second is pointing pose, which represents a pointing ray originating from the user's hand or controller.</span></span> <span data-ttu-id="40f6a-223">Таким образом, если нужно отобразить **руку пользователя** или **объект содержится в руки пользователя**, такие как помехой или оружия, используйте поза захвата для изменения.</span><span class="sxs-lookup"><span data-stu-id="40f6a-223">So, if you want to render **the user's hand** or **an object held in the user's hand**, such as a sword or gun, use the grip pose.</span></span> <span data-ttu-id="40f6a-224">Если вы хотите raycast от контроллера или вручную, например, если пользователь является **обращены пользовательского интерфейса** , указывающего поза использовать.</span><span class="sxs-lookup"><span data-stu-id="40f6a-224">If you want to raycast from the controller or hand, for example when the user is **pointing at UI** , use the pointing pose.</span></span>

<span data-ttu-id="40f6a-225">Вы можете получить доступ к **поза захвата для изменения** через [SpatialInteractionSourceState::Properties::TryGetLocation(...) ](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  Определяется следующим образом:</span><span class="sxs-lookup"><span data-stu-id="40f6a-225">You can access the **grip pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  It is defined as follows:</span></span>
* <span data-ttu-id="40f6a-226">**Возьмитесь за позиции**: Palm центроида при удержании контроллер, естественно, корректируется, влево или вправо, чтобы центрировать позиция в пределах захвата.</span><span class="sxs-lookup"><span data-stu-id="40f6a-226">The **grip position**: The palm centroid when holding the controller naturally, adjusted left or right to center the position within the grip.</span></span>
* <span data-ttu-id="40f6a-227">**Возьмитесь за правой оси в ориентации**: При открытии полностью свои силы для формирования позу плоских 5 палец, луч, является нормальным для вашей palm (вперед от левой palm назад от правой palm)</span><span class="sxs-lookup"><span data-stu-id="40f6a-227">The **grip orientation's Right axis**: When you completely open your hand to form a flat 5-finger pose, the ray that is normal to your palm (forward from left palm, backward from right palm)</span></span>
* <span data-ttu-id="40f6a-228">**Возьмитесь за ориентации на ось, направленная вперед**: При закрытии вашей руке частично (как будто держа контроллеру), луч, указывающий «forward» трубку, образованное пальцы отличных от бегунка.</span><span class="sxs-lookup"><span data-stu-id="40f6a-228">The **grip orientation's Forward axis**: When you close your hand partially (as if holding the controller), the ray that points "forward" through the tube formed by your non-thumb fingers.</span></span>
* <span data-ttu-id="40f6a-229">**Возьмитесь за ориентации элемента вверх оси**: Ось вверх, право и прямого определения содержится в разрешении.</span><span class="sxs-lookup"><span data-stu-id="40f6a-229">The **grip orientation's Up axis**: The Up axis implied by the Right and Forward definitions.</span></span>

<span data-ttu-id="40f6a-230">Вы можете получить доступ к **поза указатель** через [SpatialInteractionSourceState::Properties::TryGetLocation (...):: SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) или [SpatialInteractionSourceState:: TryGetPointerPose (...):: TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span><span class="sxs-lookup"><span data-stu-id="40f6a-230">You can access the **pointer pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)::SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) or [SpatialInteractionSourceState::TryGetPointerPose(...)::TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span></span>

## <a name="controller-specific-input-properties"></a><span data-ttu-id="40f6a-231">Входные свойства конкретного контроллера</span><span class="sxs-lookup"><span data-stu-id="40f6a-231">Controller-specific input properties</span></span>
<span data-ttu-id="40f6a-232">Для контроллеров SpatialInteractionSource имеет свойство контроллера с помощью дополнительных возможностей.</span><span class="sxs-lookup"><span data-stu-id="40f6a-232">For controllers, the SpatialInteractionSource has a Controller property with additional capabilities.</span></span>
* <span data-ttu-id="40f6a-233">**HasThumbstick:** Если значение равно true, контроллер может джойстик.</span><span class="sxs-lookup"><span data-stu-id="40f6a-233">**HasThumbstick:** If true, the controller has a thumbstick.</span></span> <span data-ttu-id="40f6a-234">Проверьте [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) свойство SpatialInteractionSourceState получения джойстик x и y значения (ThumbstickX и ThumbstickY), а также его нажаты (IsThumbstickPressed).</span><span class="sxs-lookup"><span data-stu-id="40f6a-234">Inspect the [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) property of the SpatialInteractionSourceState to acquire the thumbstick x and y values (ThumbstickX and ThumbstickY), as well as its pressed state (IsThumbstickPressed).</span></span>
* <span data-ttu-id="40f6a-235">**HasTouchpad:** Если значение равно true, контроллер может сенсорной панели.</span><span class="sxs-lookup"><span data-stu-id="40f6a-235">**HasTouchpad:** If true, the controller has a touchpad.</span></span> <span data-ttu-id="40f6a-236">Проверьте свойство ControllerProperties SpatialInteractionSourceState получения сенсорной панели x и y значений (TouchpadX и TouchpadY) и знать, если пользователь касается планшета (IsTouchpadTouched) и если они нажав сенсорной вниз () IsTouchpadPressed).</span><span class="sxs-lookup"><span data-stu-id="40f6a-236">Inspect the ControllerProperties property of the SpatialInteractionSourceState to acquire the touchpad x and y values (TouchpadX and TouchpadY), and to know if the user is touching the pad (IsTouchpadTouched) and if they are pressing the touchpad down (IsTouchpadPressed).</span></span>
* <span data-ttu-id="40f6a-237">**SimpleHapticsController:** Интерфейс API SimpleHapticsController для контроллера, позволяет исследовать возможности haptics контроллера, а также позволяет управлять обратной связи haptic.</span><span class="sxs-lookup"><span data-stu-id="40f6a-237">**SimpleHapticsController:** The SimpleHapticsController API for the controller allows you to inspect the haptics capabilities of the controller, and it also allows you to control haptic feedback.</span></span>

<span data-ttu-id="40f6a-238">Обратите внимание, что диапазон для сенсорной панели и джойстик -1 до 1 для обеих осей (снизу вверх и слева направо).</span><span class="sxs-lookup"><span data-stu-id="40f6a-238">Note that the range for touchpad and thumbstick is -1 to 1 for both axes (from bottom to top, and from left to right).</span></span> <span data-ttu-id="40f6a-239">Диапазон для аналоговой триггера, к которому можно получить с помощью свойства SpatialInteractionSourceState::SelectPressedValue, имеет диапазон от 0 до 1.</span><span class="sxs-lookup"><span data-stu-id="40f6a-239">The range for the analog trigger, which is accessed using the SpatialInteractionSourceState::SelectPressedValue property, has a range of 0 to 1.</span></span> <span data-ttu-id="40f6a-240">Значение 1 соответствует с IsSelectPressed равен true; любое другое значение связано с IsSelectPressed равен false.</span><span class="sxs-lookup"><span data-stu-id="40f6a-240">A value of 1 correlates with IsSelectPressed being equal to true; any other value correlates with IsSelectPressed being equal to false.</span></span>

## <a name="articulated-hand-tracking"></a><span data-ttu-id="40f6a-241">Ясно сформулированные вручную отслеживания</span><span class="sxs-lookup"><span data-stu-id="40f6a-241">Articulated hand tracking</span></span>
<span data-ttu-id="40f6a-242">API смешанной реальностью Windows обеспечивает полную поддержку для ясно сформулированные руки, отслеживания, к примеру HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="40f6a-242">The Windows Mixed Reality API provides full support for articulated hand tracking, for example on HoloLens 2.</span></span> <span data-ttu-id="40f6a-243">Ясно сформулированные вручную отслеживания можно использовать для реализации прямой манипуляцией и моделями входных данных для точки и фиксации в ваших приложениях.</span><span class="sxs-lookup"><span data-stu-id="40f6a-243">Articulated hand tracking can be used to implement direct manipulation and point-and-commit input models in your applications.</span></span> <span data-ttu-id="40f6a-244">Его также можно создавать полностью настраиваемые взаимодействий.</span><span class="sxs-lookup"><span data-stu-id="40f6a-244">It can also be used to author fully custom interactions.</span></span>

### <a name="hand-skeleton"></a><span data-ttu-id="40f6a-245">Каркас вручную</span><span class="sxs-lookup"><span data-stu-id="40f6a-245">Hand skeleton</span></span>
<span data-ttu-id="40f6a-246">Ясно сформулированные вручную отслеживания предоставляет 25 совместные каркас, позволяющий множество различных типов взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="40f6a-246">Articulated hand tracking provides a 25 joint skeleton that enables many different types of interactions.</span></span>  <span data-ttu-id="40f6a-247">Скелет предоставляет 5 соединений для индекса или среднего/кольцо/мало пальцы, 4 соединений для бегунка и 1 запястья соединения.</span><span class="sxs-lookup"><span data-stu-id="40f6a-247">The skeleton provides 5 joints for the index/middle/ring/little fingers, 4 joints for the thumb, and 1 wrist joint.</span></span>  <span data-ttu-id="40f6a-248">Совместные запястья служит основой иерархии.</span><span class="sxs-lookup"><span data-stu-id="40f6a-248">The wrist joint serves as the base of the hierarchy.</span></span> <span data-ttu-id="40f6a-249">На следующем рисунке показана Макет схемы.</span><span class="sxs-lookup"><span data-stu-id="40f6a-249">The following picture illustrates the layout of the skeleton.</span></span>

![Каркас вручную](images/hand-skeleton.png)

<span data-ttu-id="40f6a-251">В большинстве случаев каждый соединение называется основании костей, который он представляет.</span><span class="sxs-lookup"><span data-stu-id="40f6a-251">In most cases, each joint is named based on the bone that it represents.</span></span>  <span data-ttu-id="40f6a-252">Так как существуют две кости на каждого соединения, мы используем соглашению именования каждого соединения, исходя кости дочерний в этом расположении.</span><span class="sxs-lookup"><span data-stu-id="40f6a-252">Since there are two bones at every joint, we use a convention of naming each joint based on the child bone at that location.</span></span>  <span data-ttu-id="40f6a-253">Дочерние кости определяется как кости максимально далеко от кисти.</span><span class="sxs-lookup"><span data-stu-id="40f6a-253">The child bone is defined as the bone further from the wrist.</span></span>  <span data-ttu-id="40f6a-254">Например «индекс Proximal» совместные содержит начальное положение proximal кости индекса и ориентацию, кости.</span><span class="sxs-lookup"><span data-stu-id="40f6a-254">For example, the "Index Proximal" joint contains the beginning position of the index proximal bone, and the orientation of that bone.</span></span>  <span data-ttu-id="40f6a-255">Он не содержит конечную позицию костей.</span><span class="sxs-lookup"><span data-stu-id="40f6a-255">It does not contain the ending position of the bone.</span></span>  <span data-ttu-id="40f6a-256">Если требуется, получится его от следующего соединения в иерархии «индекса средний уровень» соединения.</span><span class="sxs-lookup"><span data-stu-id="40f6a-256">If you need that, you'd get it from the next joint in the hierarchy, the "Index Intermediate" joint.</span></span>

<span data-ttu-id="40f6a-257">В дополнение к 25 иерархических соединений система предоставляет palm соединением.</span><span class="sxs-lookup"><span data-stu-id="40f6a-257">In addition to the 25 hierarchical joints, the system provides a palm joint.</span></span>  <span data-ttu-id="40f6a-258">Palm обычно не считается частью базовой структуры.</span><span class="sxs-lookup"><span data-stu-id="40f6a-258">The palm is not typically considered part of the skeletal structure.</span></span>  <span data-ttu-id="40f6a-259">Он предоставляется только в качестве удобного способа получить общую положение и ориентацию вручную.</span><span class="sxs-lookup"><span data-stu-id="40f6a-259">It is provided only as a convenient way to get the hand's overall position and orientation.</span></span>

<span data-ttu-id="40f6a-260">Для каждого соединения, предоставляется следующая информация:</span><span class="sxs-lookup"><span data-stu-id="40f6a-260">The following information is provided for each joint:</span></span>

| <span data-ttu-id="40f6a-261">Имя</span><span class="sxs-lookup"><span data-stu-id="40f6a-261">Name</span></span> | <span data-ttu-id="40f6a-262">Описание</span><span class="sxs-lookup"><span data-stu-id="40f6a-262">Description</span></span> |
|--- |--- |
|<span data-ttu-id="40f6a-263">Положение</span><span class="sxs-lookup"><span data-stu-id="40f6a-263">Position</span></span> | <span data-ttu-id="40f6a-264">Трехмерного положения соединения, доступен в любом запросе системы координат.</span><span class="sxs-lookup"><span data-stu-id="40f6a-264">3D position of the joint, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="40f6a-265">Orientation</span><span class="sxs-lookup"><span data-stu-id="40f6a-265">Orientation</span></span> | <span data-ttu-id="40f6a-266">3D ориентацию кости, доступен в любом запросе системы координат.</span><span class="sxs-lookup"><span data-stu-id="40f6a-266">3D orientation of the bone, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="40f6a-267">Радиус</span><span class="sxs-lookup"><span data-stu-id="40f6a-267">Radius</span></span> | <span data-ttu-id="40f6a-268">Расстояние область обложки совместные позиции.</span><span class="sxs-lookup"><span data-stu-id="40f6a-268">Distance to surface of the skin at the joint position.</span></span> <span data-ttu-id="40f6a-269">Это удобно для настройки непосредственного взаимодействия или визуализаций, которые зависят от ширина палец.</span><span class="sxs-lookup"><span data-stu-id="40f6a-269">Useful for tuning direct interactions or visualizations that rely on finger width.</span></span> |
|<span data-ttu-id="40f6a-270">Точность</span><span class="sxs-lookup"><span data-stu-id="40f6a-270">Accuracy</span></span> | <span data-ttu-id="40f6a-271">Содержит указание на уверены, как система, в том числе о программе этого соединения.</span><span class="sxs-lookup"><span data-stu-id="40f6a-271">Provides a hint on how confident the system feels about this joint's information.</span></span> |

<span data-ttu-id="40f6a-272">Доступ к данным скелет вручную с помощью функции на [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="40f6a-272">You can access the hand skeleton data through a function on the [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>  <span data-ttu-id="40f6a-273">Эта функция вызывается [TryGetHandPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), и возвращает объект с именем [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose).</span><span class="sxs-lookup"><span data-stu-id="40f6a-273">The function is called [TryGetHandPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), and it returns an object called [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose).</span></span>  <span data-ttu-id="40f6a-274">Если источник не поддерживает ясно сформулированные руки, эта функция вернет значение null.</span><span class="sxs-lookup"><span data-stu-id="40f6a-274">If the source does not support articulated hands, then this function will return null.</span></span>  <span data-ttu-id="40f6a-275">Получив HandPose, можно получить текущие данные соединения, вызвав [TryGetJoint](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), с именем соединения, которые вас интересуют.</span><span class="sxs-lookup"><span data-stu-id="40f6a-275">Once you have a HandPose, you can get current joint data by calling [TryGetJoint](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), with the name of the joint you are interested in.</span></span>  <span data-ttu-id="40f6a-276">Данные возвращаются в виде [JointPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.jointpose) структуры.</span><span class="sxs-lookup"><span data-stu-id="40f6a-276">The data is returned as a [JointPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.jointpose) structure.</span></span>  <span data-ttu-id="40f6a-277">Следующий код получает положение подсказки вытянутым указательным пальцем.</span><span class="sxs-lookup"><span data-stu-id="40f6a-277">The following code gets the position of the index finger tip.</span></span> <span data-ttu-id="40f6a-278">Переменная *currentState* представляет экземпляр [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="40f6a-278">The variable *currentState* represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;
using namespace winrt::Windows::Foundation::Numerics;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    JointPose joint;
    if (handPose.TryGetJoint(desiredCoordinateSystem, HandJointKind::IndexTip, joint))
    {
        float3 indexTipPosition = joint.Position;

        // Do something with the index tip position
    }
}
```

### <a name="hand-mesh"></a><span data-ttu-id="40f6a-279">Стороны сетки</span><span class="sxs-lookup"><span data-stu-id="40f6a-279">Hand mesh</span></span>

<span data-ttu-id="40f6a-280">Ясно сформулированные Рука отслеживания API позволяет полностью deformable сетку вручную.</span><span class="sxs-lookup"><span data-stu-id="40f6a-280">The articulated hand tracking API allows for a fully deformable triangle hand mesh.</span></span>  <span data-ttu-id="40f6a-281">Этой сетчатой структурой можно deform в режиме реального времени наряду с ее вручную и используется для визуализации, а также методы расширенной физики.</span><span class="sxs-lookup"><span data-stu-id="40f6a-281">This mesh can deform in real time along with the hand skeleton, and is useful for visualization as well as advanced physics techniques.</span></span>  <span data-ttu-id="40f6a-282">Чтобы получить доступ к сети вручную, необходимо сначала создать [HandMeshObserver](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver) путем вызова метода [TryCreateHandMeshObserverAsync](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) на [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="40f6a-282">To access the hand mesh, you need to first create a [HandMeshObserver](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver) object by calling [TryCreateHandMeshObserverAsync](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) on the [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span>  <span data-ttu-id="40f6a-283">Это действие необходимо выполнить один раз для одного источника, обычно в первый раз, он отображается.</span><span class="sxs-lookup"><span data-stu-id="40f6a-283">This only needs to be done once per source, typically the first time you see it.</span></span>  <span data-ttu-id="40f6a-284">Это означает, что Вы вызовите эту функцию для создания объекта HandMeshObserver всякий раз, когда FOV переходит в руки.</span><span class="sxs-lookup"><span data-stu-id="40f6a-284">That means you'll call this function to create a HandMeshObserver object whenever a hand enters the FOV.</span></span>  <span data-ttu-id="40f6a-285">Обратите внимание на то, что это функцию с модификатором async, поэтому вам придется иметь дело с немного здесь параллелизма.</span><span class="sxs-lookup"><span data-stu-id="40f6a-285">Note that this is an async function, so you'll have to deal with a bit of concurrency here.</span></span>  <span data-ttu-id="40f6a-286">Когда она станет доступна, вы можете запросить объект HandMeshObserver буфера индекса треугольника путем вызова [GetTriangleIndices](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span><span class="sxs-lookup"><span data-stu-id="40f6a-286">Once available, you can ask the HandMeshObserver object for the triangle index buffer by calling [GetTriangleIndices](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span></span>  <span data-ttu-id="40f6a-287">Индексы не изменяйте кадра на рамку, чтобы можно было получить их один раз и кэшировать их в течение времени существования источника.</span><span class="sxs-lookup"><span data-stu-id="40f6a-287">Indices don't change frame over frame, so you can get those once and cache them for the lifetime of the source.</span></span>  <span data-ttu-id="40f6a-288">Индексы, указанные в порядке, поворота по часовой стрелке.</span><span class="sxs-lookup"><span data-stu-id="40f6a-288">Indices are provided in clockwise winding order.</span></span>

<span data-ttu-id="40f6a-289">Следующий код запускает отсоединенных std::thread, чтобы создать Наблюдатель сети и извлекает буфера индекса, когда доступен сетке наблюдатель.</span><span class="sxs-lookup"><span data-stu-id="40f6a-289">The following code spins up a detached std::thread to create the mesh observer and extracts the index buffer once the mesh observer is available.</span></span>  <span data-ttu-id="40f6a-290">Он запускается из переменной с именем *currentState*, который является экземпляром [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) представляющий отслеживаемые руки.</span><span class="sxs-lookup"><span data-stu-id="40f6a-290">It starts from a variable called *currentState*, which is an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) representing a tracked hand.</span></span>

```cpp
using namespace Windows::Perception::People;

std::thread createObserverThread([this, currentState]()
{
    HandMeshObserver newHandMeshObserver = currentState.Source().TryCreateHandMeshObserverAsync().get();
    if (newHandMeshObserver)
    {
        unsigned indexCount = newHandMeshObserver.TriangleIndexCount();
        vector<unsigned short> indices(indexCount);
        newHandMeshObserver.GetTriangleIndices(indices);

        // Save the indices and handMeshObserver for later use - and use a mutex to synchronize access if needed!
     }
});
createObserverThread.detach();
```
<span data-ttu-id="40f6a-291">Запуск отсоединенных поток является только один из вариантов для обработки асинхронных вызовов.</span><span class="sxs-lookup"><span data-stu-id="40f6a-291">Starting a detached thread is just one option for handling async calls.</span></span>  <span data-ttu-id="40f6a-292">Кроме того, можно использовать новый [co_await](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/concurrency) функциональные возможности, поддерживаемые C++/WinRT.</span><span class="sxs-lookup"><span data-stu-id="40f6a-292">Alternatively, you could use the new [co_await](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/concurrency) functionality supported by C++/WinRT.</span></span>

<span data-ttu-id="40f6a-293">Получив объект HandMeshObserver, должен удерживать в течение его соответствующий SpatialInteractionSource активен.</span><span class="sxs-lookup"><span data-stu-id="40f6a-293">Once you have a HandMeshObserver object, you should hold onto it for the duration that its corresponding SpatialInteractionSource is active.</span></span>  <span data-ttu-id="40f6a-294">Затем каждый кадр, вы можете запросить ее последней буфера вершин, представляющий Рука путем вызова [GetVertexStateForPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) и передавая [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose) экземпляр, представляющий поза, возникает необходимость вершины для.</span><span class="sxs-lookup"><span data-stu-id="40f6a-294">Then each frame, you can ask it for the latest vertex buffer that represents the hand by calling [GetVertexStateForPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) and passing in a [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose) instance that represents the pose that you want vertices for.</span></span>  <span data-ttu-id="40f6a-295">Каждая вершина в буфере, имеющую положение и обычной.</span><span class="sxs-lookup"><span data-stu-id="40f6a-295">Each vertex in the buffer has a position and a normal.</span></span>  <span data-ttu-id="40f6a-296">Ниже приведен пример, иллюстрирующий получение текущего набора вершин сетки вручную.</span><span class="sxs-lookup"><span data-stu-id="40f6a-296">Here's an example of how to get the current set of vertices for a hand mesh.</span></span>  <span data-ttu-id="40f6a-297">Как и раньше *currentState* переменная представляет экземпляр [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="40f6a-297">Just as before, the *currentState* variable represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    std::vector<HandMeshVertex> vertices(handMeshObserver.VertexCount());
    auto vertexState = handMeshObserver.GetVertexStateForPose(handPose);
    vertexState.GetVertices(vertices);

    auto meshTransform = vertexState.CoordinateSystem().TryGetTransformTo(desiredCoordinateSystem);
    if (meshTransform != nullptr)
    {
        // Do something with the vertices and mesh transform, along with the indices that you saved earlier
    }
}
```

<span data-ttu-id="40f6a-298">В отличие от соединений, которая скелет сетки в наличии API не позволяют укажите систему координат для вершины.</span><span class="sxs-lookup"><span data-stu-id="40f6a-298">In contrast to skeleton joints, the hand mesh API does not allow you to specify a coordinate system for the vertices.</span></span>  <span data-ttu-id="40f6a-299">Вместо этого [HandMeshVertexState](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshvertexstate) задает систему координат, вершин, предусмотренных в.</span><span class="sxs-lookup"><span data-stu-id="40f6a-299">Instead, the [HandMeshVertexState](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshvertexstate) specifies the coordinate system that the vertices are provided in.</span></span>  <span data-ttu-id="40f6a-300">Преобразование сетки можно получить, вызвав [TryGetTransformTo](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) и указав требуемый координат.</span><span class="sxs-lookup"><span data-stu-id="40f6a-300">You can then get a mesh transform by calling [TryGetTransformTo](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) and specifying your desired coordinate system.</span></span>  <span data-ttu-id="40f6a-301">Необходимо использовать это преобразование сетки при работе с вершины.</span><span class="sxs-lookup"><span data-stu-id="40f6a-301">You'll need to use this mesh transform whenever you work with the vertices.</span></span>  <span data-ttu-id="40f6a-302">Этот подход уменьшает нагрузку на ЦП, особенно в том случае, если вы используете только сетки для отрисовки.</span><span class="sxs-lookup"><span data-stu-id="40f6a-302">This approach reduces CPU overhead, especially if you are only using the mesh for rendering purposes.</span></span>

## <a name="gaze-and-commit-composite-gestures"></a><span data-ttu-id="40f6a-303">Помощи и зафиксируйте составные жесты</span><span class="sxs-lookup"><span data-stu-id="40f6a-303">Gaze and Commit composite gestures</span></span>
<span data-ttu-id="40f6a-304">Для приложений, использующих модель ввода взглядом и фиксации, особенно на HoloLens (первого поколения), пространственных входной API поддерживает необязательный [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) , может использоваться для включить составные жесты, создаются на основе «Выберите» событие.</span><span class="sxs-lookup"><span data-stu-id="40f6a-304">For applications using the gaze-and-commit input model, particularly on HoloLens (first gen), the Spatial Input API provides an optional [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) that can be used to to enable composite gestures built on top of the 'select' event.</span></span>  <span data-ttu-id="40f6a-305">Маршрутизации взаимодействий из SpatialInteractionManager для SpatialGestureRecognizer голограмма приложений может обнаруживать события касания, удержание, манипуляции и навигации равномерно в руки, голоса и пространственных устройств ввода, без необходимости обрабатывать нажатия и освобождает вручную.</span><span class="sxs-lookup"><span data-stu-id="40f6a-305">By routing interactions from the SpatialInteractionManager to a hologram's SpatialGestureRecognizer, apps can detect Tap, Hold, Manipulation, and Navigation events uniformly across hands, voice, and spatial input devices, without having to handle presses and releases manually.</span></span>

<span data-ttu-id="40f6a-306">SpatialGestureRecognizer выполняет только минимальный устранения неоднозначности между набор жестов, которые можно запросить.</span><span class="sxs-lookup"><span data-stu-id="40f6a-306">SpatialGestureRecognizer performs only the minimal disambiguation between the set of gestures that you request.</span></span> <span data-ttu-id="40f6a-307">К примеру Если вы запрашивали только Tap, пользователь может удерживать пальцев, пока они любят и отвод по-прежнему будет выполняться.</span><span class="sxs-lookup"><span data-stu-id="40f6a-307">For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur.</span></span> <span data-ttu-id="40f6a-308">При запросе коснитесь и хранения, после того как об одной секунды удерживая пальцев, жест переведет в удержание и Tap не будет происходить.</span><span class="sxs-lookup"><span data-stu-id="40f6a-308">If you request both Tap and Hold, after about a second of holding down their finger, the gesture will promote to a Hold and a Tap will no longer occur.</span></span>

<span data-ttu-id="40f6a-309">Чтобы использовать SpatialGestureRecognizer, обрабатывать SpatialInteractionManager [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) событий и захвата SpatialPointerPose предоставляются существует.</span><span class="sxs-lookup"><span data-stu-id="40f6a-309">To use SpatialGestureRecognizer, handle the SpatialInteractionManager's [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) event and grab the SpatialPointerPose exposed there.</span></span> <span data-ttu-id="40f6a-310">Используйте Рэй головной взглядом пользователя из этого поза для пересечения с голограммы и поверхности сетки в окружения пользователя, чтобы определить, что пользователь собирается для взаимодействия с.</span><span class="sxs-lookup"><span data-stu-id="40f6a-310">Use the user's head gaze ray from this pose to intersect with the holograms and surface meshes in the user's surroundings, in order to determine what the user is intending to interact with.</span></span> <span data-ttu-id="40f6a-311">Затем направлять SpatialInteraction в аргументах событий для целевой голограмма SpatialGestureRecognizer, с помощью его [CaptureInteraction](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) метод.</span><span class="sxs-lookup"><span data-stu-id="40f6a-311">Then, route the SpatialInteraction in the event arguments to the target hologram's SpatialGestureRecognizer, using its [CaptureInteraction](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) method.</span></span> <span data-ttu-id="40f6a-312">Запустится интерпретации, реализуемый в соответствии с [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) задать на этот распознаватель, во время создания - или с [TrySetGestureSettings](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span><span class="sxs-lookup"><span data-stu-id="40f6a-312">This starts interpreting that interaction according to the [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) set on that recognizer at creation time - or by [TrySetGestureSettings](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span></span>

<span data-ttu-id="40f6a-313">На HoloLens (сначала gen), взаимодействия и жесты следует обычно являются их выбора целевой платформы из головного взглядом пользователя, а не при визуализации или напрямую взаимодействовать в расположении вручную.</span><span class="sxs-lookup"><span data-stu-id="40f6a-313">On HoloLens (first gen), interactions and gestures should generally derive their targeting from the user's head gaze, rather than trying to render or interact at the hand's location directly.</span></span> <span data-ttu-id="40f6a-314">После запуска взаимодействия относительный движения вручную может использоваться для управления жест, как и в случае с жестом манипуляции или навигации.</span><span class="sxs-lookup"><span data-stu-id="40f6a-314">Once an interaction has started, relative motions of the hand may be used to control the gesture, as with the Manipulation or Navigation gesture.</span></span>

## <a name="see-also"></a><span data-ttu-id="40f6a-315">См. также</span><span class="sxs-lookup"><span data-stu-id="40f6a-315">See also</span></span>
* [<span data-ttu-id="40f6a-316">HEAD и глаз взглядом в DirectX</span><span class="sxs-lookup"><span data-stu-id="40f6a-316">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="40f6a-317">Модель ввода непосредственной работы со</span><span class="sxs-lookup"><span data-stu-id="40f6a-317">Direct manipulation input model</span></span>](direct-manipulation.md)
* [<span data-ttu-id="40f6a-318">Модель ввода точки и фиксации</span><span class="sxs-lookup"><span data-stu-id="40f6a-318">Point-and-commit input model</span></span>](point-and-commit.md)
* [<span data-ttu-id="40f6a-319">Модель ввода взглядом и фиксации</span><span class="sxs-lookup"><span data-stu-id="40f6a-319">Gaze and commit input model</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="40f6a-320">Контроллеры движения</span><span class="sxs-lookup"><span data-stu-id="40f6a-320">Motion controllers</span></span>](motion-controllers.md)
