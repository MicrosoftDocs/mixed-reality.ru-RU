---
title: Взгляд — взгляд
description: HoloLens 2 предоставляет разработчикам возможность использовать информацию о том, что видят пользователи, для нового уровня контекста и человеческого понимания в Holographic.
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: Отслеживание глаз, Смешанная реальность, ввод, глаз-взгляд
ms.openlocfilehash: 51779b7b210522aa4d19b5a32d7df6ccb2cb3a35
ms.sourcegitcommit: ff330a7e36e5ff7ae0e9a08c0e99eb7f3f81361f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/28/2019
ms.locfileid: "70122067"
---
# <a name="eye-gaze-on-hololens-2"></a>Глаз — Взгляните на HoloLens 2
HoloLens 2 предоставляет разработчикам возможность использовать информацию о том, что видят пользователи, для нового уровня контекста и человеческого понимания в Holographic. Эта страница указывает разработчикам, как они могут воспользоваться преимуществами отслеживания взгляда для различных вариантов использования, а также то, что следует искать при проектировании пользовательских интерфейсов на основе взгляда. 


## <a name="device-support"></a>Поддержка устройств

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><strong>Возможность</strong></td>
     <td><a href="hololens-hardware-details.md"><strong>HoloLens (1-го поколения)</strong></a></td>
     <td><strong>HoloLens 2</strong></td>
     <td><a href="immersive-headset-hardware-details.md"><strong>Иммерсивные гарнитуры</strong></a></td>
</tr>
<tr>
     <td>Взгляд — взгляд</td>
     <td>❌</td>
     <td>✔️</td>
     <td>❌</td>
</tr>
</table>

## <a name="use-cases"></a>Варианты использования
Функция отслеживание взгляда предоставляет приложениям сведения о том, куда смотрит пользователь в реальном времени. В следующих сценариях использования описаны некоторые взаимодействия, которые можно реализовать с помощью отслеживания взгляда в смешанной реальности.
Следует помнить, что [набор средств Mixed Reality](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) полезен для предоставления нескольких интересных и удобных примеров использования отслеживания взгляда, таких как быстрый и простой способ выбора целевого объекта, а также автоматическая прокрутка текста на основе вид пользователя. 

### <a name="user-intent"></a>Намерения пользователя    
Сведения о том, где и как выглядит пользователь, предоставляет мощный **контекст для других входных данных**, таких как Voice, руки и контроллеры.
Эти данные можно применять в разных задачах.
Например, это может варьироваться от быстрого и легко нацеливания на сцену, просто взглянув на голограмму и выполнив команду "Select" (см. также « [head-взгляд» и «Commit](gaze-and-commit.md)») или *«поместить это...»* , а затем взглянуть на место, где пользователь хочет поместить голограмму и сказать *: «... Здесь "* . Подобные примеры доступны в наборах средств для смешанной реальности для [выбора целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) и [позиционирования целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).

Кроме того, пример намерения пользователя может включать в себя сведения о том, что видят пользователи, чтобы улучшить работу с помощью применяющихся виртуальных агентов и интерактивных голограмм. Например, виртуальные агенты могут адаптировать доступные параметры и их поведение на основе текущего просматриваемого содержимого. 

### <a name="implicit-actions"></a>Неявные действия
Категория неявных действий тесно связана с намерениями пользователя.
Идея состоит в том, что голограммы или элементы пользовательского интерфейса реагируют на инстинктуале, что может даже не показаться, что пользователь взаимодействует с системой вообще, а сам система и пользователь синхронизированы. Одним из примеров является **Автоматическая прокрутка на основе взгляда на глаза** , когда пользователь может прочитать длинный текст, который автоматически начинает прокручиваться после того, как пользователь получит доступ к нижней части текстового поля, чтобы пользователь оставался в потоке чтения без отрыва пальца.  
Ключевым аспектом этого процесса является то, что скорость прокрутки адаптируется к скорости чтения пользователя.
В качестве другого примера можно возместить **масштаб и панораму** , в котором пользователь может точно соответствовать тем, на что он направлен. Для управления скоростью масштабирования и управления ею можно управлять с помощью голоса или ввода-вывода, что важно для предоставления пользователю прав на управление и предотвращения переполнения. Мы рассмотрим эти рекомендации по проектированию более подробно. После масштабирования пользователь может плавно проследить за тем, что, например, разообразить свое окружение, просто воспользовавшись знаком взгляда.
Эти типы взаимодействия демонстрируются в примере набора средств для смешанной реальности для [навигации с поддержкой взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).

Дополнительные варианты использования неявных _действий_ могут включать:
- **Интеллектуальные уведомления**. Вас раздражают уведомления, которые всплывают ровно в том месте, на которое вы смотрите? Принимая во внимание то, к какому пользователю относится пользователь, вы можете сделать этот процесс более эффективным, потратив уведомления от того, где пользователь в настоящее время облаками. Это ограничивает число обращений и автоматически закрывает их после того, как пользователь закончит чтение. 
- **"Вежливые" голограммы**. Голограммы, которые слегка реагируют на газед. Это может варьироваться от слегка свечения элементов пользовательского интерфейса до медленного цветутного цветок до виртуального животного, начинающегося с пользователя, или пытаясь избежать глаза пользователя после длительной звездочки. Это взаимодействие может предоставить интересное представление о подключении и удовлетворенности приложения.

### <a name="attention-tracking"></a>Отслеживание внимания   
Сведения о том, где или как видят пользователи, — это чрезвычайно мощный инструмент для оценки удобства использования дизайнов и выявления проблем в эффективных рабочих процессах. Визуализация и аналитика отслеживания взгляда являются распространенной практикой в различных областях приложений. С помощью HoloLens 2 мы предоставляем новое измерение для понимания того, как трехмерные голограммы могут быть помещены в реальные контексты и оцениваться соответствующим образом. [Набор средств Mixed Reality](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) предоставляет основные примеры ведения журнала и загрузки данных отслеживания взгляда, а также способы их визуализации.

Другие приложения в этой области могут включать: 
-   **Удаленный взгляд — визуализация взгляда:** Визуализируйте, что просматривает удаленные участники совместной работы, чтобы убедиться, что инструкции правильно понятны и следуют.
-   **Исследование пользователей.** Отслеживание внимания можно использовать для изучения того, как новички и пользователи с экспертами визуально анализируют содержимое или способ координации сложных задач, например для анализа медицинских данных или при работе с операционным механизмом.
-   **Обучающее моделирование и мониторинг производительности.** Тренировка и оптимизация выполнения задач, которые позволят более эффективно выявлять узкие места в потоке выполнения.
-   **Оценка проекта, реклама и маркетинговые исследования.** Отслеживание взгляда — это распространенный инструмент для исследования рынка при оценке моделей веб-сайтов и продуктов.

### <a name="additional-use-cases"></a>Другие варианты использования
- **Игры.** Вам нужны суперспособности? Вам сюда! Вы можете левитате голограммы на них. Стреляйте лазерными лучами из глаз. Превратите противников в камень или закрепите их. Примените рентгеновское зрение, чтобы исследовать здания. Вы ограничены только пределами своего воображения!  

- **Выразительные аватары.** Отслеживание взгляда помогает в более выразительных трехмерных аватарах, используя данные отслеживания взгляда, чтобы анимировать глаза аватара, указывающие, что именно видят пользователи. 

- **Ввод текста.** Отслеживание взгляда можно использовать в качестве альтернативы для ввода текста с низкой наработкой, особенно если речь или руки неудобны для использования. 


## <a name="available-eye-tracking-data"></a>Доступные данные отслеживания взгляда
Прежде чем приступить к подробному рассмотрению конкретных руководств по проектированию для взаимодействия с взглядом, мы хотим вкратце описать возможности, предоставляемые [API отслеживания взгляда](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) HoloLens 2. Разработчики получают доступ к одному лучау глаза (источнику и направлению взгляда) приблизительно в _30 кадров/с (60 Гц)_ .
Более подробные сведения о том, как получить доступ к данным отслеживания взгляда, см. в руководствах для разработчиков, посвященных использованию [глаз-взгляда в DirectX](gaze-in-directx.md) и [глаза-взгляде в Unity](https://aka.ms/mrtk-eyes).

Прогнозируемый глаз — это приблизительно в 1,5 градусов визуального угла вокруг фактического целевого объекта (см. рисунок ниже). Как и в случае с небольшим количеством неточностей, разработчики должны запланировать некоторое поле вокруг этого нижнего значения (например, 2.0-3.0 градусов может привести к более удобному интерфейсу). Мы обсудим, как более подробно решать выбор мелких целевых объектов. Чтобы отслеживание взгляда работало точно, каждому пользователю нужно пройти калибровку отслеживания взгляда. 

![Оптимальный размер целевого объекта на расстоянии 2 метра](images/gazetargeting-size-1000px.jpg)<br>
*Оптимальный размер целевого объекта на расстоянии в 2 метра*

## <a name="calibration"></a>Монитора 
Чтобы отслеживание взгляда работало правильно, каждый пользователь должен пройти по [калибровке пользователя](calibration.md) с отслеживанием взгляда, для которого пользователь должен взглянуть на набор holographic мишеней. Это позволяет устройству настроить систему для более удобного и качественного просмотра для пользователя, а также для обеспечения точного отслеживания в то же время. Отслеживание взгляда должно работать для большинства пользователей, но бывают случаи, когда пользователь не может успешно выполнить калибровку.
Дополнительные сведения о калибровке см. в статье [калибровка](calibration.md).

## <a name="eye-gaze-input-design-guidelines"></a>Рекомендации по проектированию ввода взгляда
Создание взаимодействия, которое использует преимущества быстрого перемещения глаз, может оказаться сложной задачей. В этом разделе мы обобщены основные преимущества и проблемы, которые следует учитывать при проектировании приложения. 

### <a name="benefits-of-eye-gaze-input"></a>Преимущества входных данных взгляда
- **Высокая скорость нацеливания**. Человеческий глаз — это самая быстрая передействующая мощность в кадре человека. 

- **Низкий уровень усилий**. Физическое перемещение почти не требуется. 

- **Ненавязчивость**. Сведения о перемещении глаз, часто описываемые пользователями, позволяют системе узнать, какую цель планирует пользователь придерживаться. 

- **Альтернативный канал ввода.** Взгляд на глаза — это мощный вспомогательный ввод, позволяющий создавать руки и речевые входные данные в течение многих лет работы пользователей, основанных на координации глаз.

- **Визуальное внимание.** Еще одним важным преимуществом является возможность определить, к чему пользователь оплачивает внимание. Это может помочь в различных областях приложений, от более эффективного оценки различных проектов до упрощения работы с более интеллектуальными пользовательскими интерфейсами и расширенными социальными подсказками для удаленного взаимодействия.

В двух словах, использование глаз-взгляда в качестве входных данных обеспечивает быстрый и простой контекстный сигнал. Это особенно удобно в сочетании с другими входными данными, например с голосовыми и *ручными* вводами, для подтверждения намерений пользователя.


### <a name="challenges-of-eye-gaze-as-an-input"></a>Проблемы с глазом. Взгляните на входные данные
Благодаря большому энергопотреблению приходится отвечать за множество обязанностей.
В то время как взгляд на глаза можно использовать для создания соответствия пользовательским интерфейсам, которые делают вас похожим на супергерой, важно также понять, что это не подходит для соответствующей учетной записи. Ниже рассматриваются некоторые *проблемы* , которые следует учитывать, а также способы их устранения при работе с входными данными взгляда на глаза: 

- **Взгляд на глаза — "Always On"** Когда вы откроете Лидс глаз, ваши глаза начнут фиксатинг на вещи в среде. При каждом взгляде вы выполняете и случайно выдаете действия, так как вы просматриваете что-то слишком длинное, что привело бы к неудовлетворенности.
Поэтому мы рекомендуем объединять глаза с помощью *команды Voice*, *жеста руки*, нажатия *кнопки* или расширенного вдаваясь, чтобы активировать выбор цели.
Это решение также обеспечивает режим, в котором пользователь может просмотреться без лишних пошагового запуска чего-либо. Эта проблема также должна учитываться при проектировании визуальных элементов и отзывов аудита при простом просмотре целевого объекта.
Не перегружайте каналы взаимодействия с пользователем навязчивыми звуками всплывающих элементов или фокусировки. Тонкость — это ключ. Некоторые рекомендации по этому аспекту мы рассмотрим ниже, когда речь пойдет о проектировании.

- **Наблюдение и управление** Представьте себе, что вы хотите точно выгадать фотографию на стене. Вы внимательно смотрите на рамку и окружающие объекты, чтобы оценить горизонтальность линий. Теперь представьте себе, как это сделать, если вы хотите использовать глаз в качестве входных данных для перемещения изображения. Сложно, правда? В этом описана двойная роль глаза — Взгляните, когда требуется как для ввода, так и для управления. 

- **Изменение фокуса перед щелчком**. Для быстрого выбора целевых объектов исследование показало, что перед завершением ручного щелчка (например, аиртап) можно перейти на глаза. Следовательно, особое внимание должно быть оплачено для синхронизации сигнала с быстрым глазом взгляда с медленным входом (например, с помощью голоса, руки, контроллера).

- **Маленькие целевые объекты**. Вам известно, что при попытке чтения текста, который слишком мал для удобства чтения? Это может привести к тому, что вы захотите и надеты, так как вы попытаетесь перенастроить глаза, чтобы лучше сосредоточиться на них.
Это незначительное время, которое может быть вызвано пользователями при принудительном выборе целевых объектов, которые слишком малы в приложении, с помощью нацеленности на глаз.
Чтобы поддерживать приятное и уверенное взаимодействие с пользователем, мы рекомендуем учесть при разработке, что минимальный размер целевых объектов должен быть не менее 2°, а желательно еще больше.

- **Неоднородный взгляд — перемещения Взгляните** Наши глаза выполняют быстрые перемещения от с фиксацией к с фиксацией. Изучая записанный путь перемещения глаз, вы быстро заметите его неравномерность. Ваши глаза быстро переходят и в некачественном переходе по сравнению с движением в *голову* или в *руки*.  

- **Надежность отслеживания**. Точность отслеживания взгляда может немного ухудшаться при изменении освещенности, пока глаза привыкают к новым условиям.
Хотя это не должно повлиять на структуру приложения, так как точность должна быть в пределах 2 °, может потребоваться выполнить калибровку пользователя снова. 


## <a name="design-recommendations"></a>Рекомендации по проектированию
Ниже приведен список конкретных рекомендаций по проектированию, основанных на указанных преимуществах и проблемах для ввода взгляда на глаза:

1. **Глаз — Взгляните не так, как Head-взгляд:**
    - **Обдумайте, подходит ли быстрое и неровное перемещение глаз для вашей задачи ввода данных.** Несмотря на то, что наши быстрые и неоднородные движения глаз отлично подходят для быстрого выбора целевых объектов в нашем поле зрения, оно менее применимо для задач, требующих гладкого ввода траекторий (например, для рисования или енЦирклингных заметок). Для таких задач лучше использовать движения рук или головы.
  
    - **Старайтесь не прикреплять что-либо непосредственно к глазу пользователя (например, к ползунку или курсору).**
В случае с курсором это может привести к эффекту "флиинг Cursor" из-за небольших смещений в прогнозируемом сигнале взгляда. В случае с ползунком он может конфликтовать с двойной ролью управления ползунком с глазами, а также проверить, находится ли объект в нужном месте. В двух словах, пользователи могут стать перегруженными и нечеткими, особенно если сигнал неточен для этого пользователя. 
  
2. **Объединение глаз-взгляда с другими входными данными:** Интеграция отслеживания взгляда с другими входными данными, такими как жесты, речевые команды или нажатие кнопки, обеспечивает ряд преимуществ.
    - **Свободное наблюдение.** Учитывая, что основная роль наших глаз заключается в том, чтобы наблюдать за нашей средой, важно, чтобы пользователи могли выполнять поиск без запуска отзывов или действий (визуальных, аудитов и т. д.). 
    Объединение отслеживания взгляда с другим элементом управления вводом позволяет плавно переходить между наблюдения за отслеживанием взгляда и режимами управления вводом.
  
    - **Мощный источник информации о контексте**. С помощью сведений о месте и том, что видят пользователи, в то время как уттеринг голосовое действие или выполнение жеста руки позволяет легко передавать входные данные по полю представления. Пример: Команда Put that there позволяет быстро и без усилий выбрать голограмму и поместить ее в другую область сцены, просто просмотрев на объект и место назначения. 

    - **Потребность в синхронизации между несколькими источниками входных данных (проблема изменения фокуса перед щелчком).** Сочетание быстрых движений с более сложными дополнительными входами, например длинными голосовыми командами или жестами руки, несет ответственность за продолжение глаза перед завершением дополнительной команды ввода. Следовательно, если вы создаете собственные элементы управления вводом (например, пользовательские жесты), обязательно запишите SES этой входной или приблизительной длительности, чтобы сопоставить его с тем, что пользователь просмотрел в прошлом.
    
3. **Ненавязчивый отклик на действия, полученные с помощью отслеживания взгляда**. При рассмотрении целевого объекта полезно предоставить отзыв, чтобы указать, что система работает как намеченная, но должна быть незаметной. Это может включать в себя медленное смешивание, включение и отображение визуальных элементов или выполнение других тонких целевых объектов, таких как медленное движение, например небольшое увеличение целевого размера, чтобы указать, что система правильно определила, что пользователь просматривает целевой объект без Необязательное прерывание текущего рабочего процесса пользователя. 

4. **Старайтесь не использовать нетипичные перемещения глаз для ввода данных.** Не вынуждайте пользователей выполнять определенные движения глаз (жесты вздействия) для запуска действий в приложении.

5. **Оставьте запас на неточность.** Мы расразличимы два типа неточностей, которые заметны для пользователей: смещение и нарушение. Самый простой способ устранить это смещение — предоставить достаточно большие целевые объекты для взаимодействия. Рекомендуется использовать визуальный угол больше 2 ° в качестве ссылки. Например, размер эскиза составляет примерно 2 ° в визуальном элементе при растяжении ARM. На этом основана следующая рекомендация.
    - Не вынуждайте пользователей выбирать крошечные целевые объекты. Исследование показало, что если целевые объекты достаточно велики и система спроектирована правильно, пользователи описывают взаимодействие как простые и Magical. Если же целевые объекты становятся слишком маленькими, взаимодействие вызывает у пользователей усталость и раздражение.
  
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a>Руководство разработчика: Что делать, если отслеживание взгляда недоступно?
Возможны ситуации, когда приложение не будет получать данные отслеживания взгляда по различным причинам, включая, помимо прочего, следующие:
* Пользователь пропустил калибровку отслеживания взгляда.
* Пользователь откалиброван, но решил не предоставлять приложению разрешение на использование данных отслеживания взгляда.
* Пользователь имеет уникальные очков или некоторые условия для глаз, которые система пока не поддерживает.
* Внешние факторы отслеживают надежность отслеживания взгляда, например палец на делителе HoloLens или очков, интенсивность прямого солнечного света и окклусионс из-за перекрестных глаз.

Разработчикам приложений это означает, что необходимо учитывать, как поддерживать пользователей, для которых данные отслеживания взгляда могут быть недоступны. Ниже мы сначала объясним, как определить, доступно ли отслеживание взгляда, и как решить, когда оно недоступно для различных приложений.

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a>1. Как определить доступность отслеживания взгляда
Существует несколько проверок, позволяющих определить, доступны ли данные отслеживания взгляда. Проверьте, нет ли...
* ... система поддерживает отслеживание взгляда. Вызовите следующий *метод*: [Windows. восприятие. People. Эйеспосе. не поддерживается ()](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)

* ... пользователь откалиброван. Вызовите следующее *свойство*: [Windows. восприятие. People. Эйеспосе. Искалибратионвалид](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)

* ... пользователь предоставил приложению разрешение на использование данных отслеживания взгляда: Получение текущего _"газеинпутакцессстатус"_ . Пример того, как это сделать, объясняется в [запросе доступа к вводу с](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input)помощью взгляда.

Кроме того, может потребоваться проверить, что данные отслеживания взгляда не устарели, добавив время ожидания между полученными обновлениями данных отслеживания взгляда и иным способом откатом к заголовку, как описано ниже. 

Как описано выше, существует несколько причин, по которым данные отслеживания взгляда могут быть недоступны. Хотя некоторые пользователи, возможно, решили отменять доступ к данным отслеживания взгляда, и, в некоторых случаях, не предоставить доступ к данным отслеживания взгляда, это может быть непреднамеренно. Таким образом, если приложение использует отслеживание взгляда, и это важная часть работы, мы рекомендуем четко взаимодействовать с пользователем. Пользователь должен знать, почему отслеживание взгляда является критически важным для вашего приложения (возможно, даже перечисление некоторых улучшенных функций), чтобы помочь пользователю лучше понять, что они предоставляют. Помогите пользователю определить, почему отслеживание взгляда может не работать (на основе описанных выше проверок) и предложить некоторые рекомендации для быстрого устранения потенциальных проблем. Например, если вы обнаружите, что система поддерживает отслеживание взгляда, пользователь откалиброван и даже имеет соответствующее разрешение, но данные отслеживания взгляда не принимаются, это может указывать на некоторые другие проблемы, такие как Растушевка или перекрыто глаза. Обратите внимание, что в редких случаях пользователи, для которых отслеживание взгляда может просто не работать. Таким образом, будьте Уважайте, чтобы отклонять или даже отключать напоминания о включении отслеживания взгляда в приложении.

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a>2. Откат для приложений с помощью взгляда на первичный входной указатель
Если приложение использует указатель мыши в качестве входных указателей, чтобы быстро выбирать голограммы в сцене, но данные отслеживания взгляда недоступны, мы рекомендуем вернуться к Head-взгляду и начать отображение курсора Head-взгляда. Мы рекомендуем использовать время ожидания (например, 500 – 1500 мс) для определения необходимости переключения. Это позволяет избежать выталкивания курсора при каждой ошибке, когда система может ненадолго потерять отслеживание из-за движения с высокой продолженностью или мультиков и мерцаний. Если вы являетесь разработчиком Unity, автоматическое переключение на Heading-взгляд уже обработано в наборе средств Mixed Reality. Если вы являетесь разработчиком DirectX, вам нужно самостоятельно справиться с этим параметром.

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a>3. Откат для других приложений, зависящих от отслеживания взгляда
Ваше приложение может использовать глаза в уникальном виде, специально предназначенном для глаз, например, для анимации глаза аватара или для внимания на глаза, тепловые карты с точной информацией о визуальном внимание. В этом случае нет четких резервных. Если отслеживание взгляда недоступно, эти возможности могут просто быть отключены. 

<br>

На этой странице мы надеемся, что вы получите хорошее представление о роли отслеживания взгляда и взгляда на глаза для HoloLens 2. Чтобы приступить к разработке, ознакомьтесь со сведениями об [глаза в Unity](https://aka.ms/mrtk-eyes) и [глаза-взгляде в DirectX](gaze-in-directx.md).


## <a name="see-also"></a>См. также
* [Глаза. Взгляните на DirectX](gaze-in-directx.md)
* [Взгляд — Взгляните на Unity (набор средств Mixed Reality)](https://aka.ms/mrtk-eyes)
* [Калибровка](calibration.md)
* [Направление головы и фиксация](gaze-and-commit.md)
* [Жесты руками](gestures.md)
* [Голосовой ввод](voice-design.md)
* [Контроллеры движения](motion-controllers.md)
* [Комфорт](comfort.md)
