---
title: Отслеживания
description: Отслеживания
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Отслеживание глаза, смешанный реальность, входные данные, взглядом глаз
ms.openlocfilehash: 948d6ad36bfa3f7b179268a8e6241c9a2ce8e732
ms.sourcegitcommit: c20563b8195c0c374a927b96708d958b127ffc8f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/21/2019
ms.locfileid: "65974765"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="4996a-104">Отслеживания на HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="4996a-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="4996a-105">HoloLens 2 позволяет совершенно новый уровень контекста и человека пониманию Holographic качества, предоставляя разработчикам невероятные возможности с помощью сведений о новые пользователи рассматривают.</span><span class="sxs-lookup"><span data-stu-id="4996a-105">HoloLens 2 allows for a whole new level of context and human understanding within the Holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="4996a-106">На этой странице приведены общие сведения о как разработчики могут использовать преимущества глаз отслеживания различных сценариев использования, и что нужно обратить внимание при проектировании глаз взглядом на основе пользовательских интерфейсов.</span><span class="sxs-lookup"><span data-stu-id="4996a-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="4996a-107">Варианты использования</span><span class="sxs-lookup"><span data-stu-id="4996a-107">Use cases</span></span>
<span data-ttu-id="4996a-108">Отслеживания позволяет приложения отслеживать, где пользователь смотрит в режиме реального времени.</span><span class="sxs-lookup"><span data-stu-id="4996a-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="4996a-109">В этом разделе описываются некоторые возможные варианты использования и novel взаимодействия, которые становятся возможными с помощью отслеживания в смешанной реальности.</span><span class="sxs-lookup"><span data-stu-id="4996a-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="4996a-110">Перед началом работы, ниже мы будем рассказывать о [смешанной реальности Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) несколько раз, так как она предоставляет несколько примеров мощный для использования отслеживания глаза, например быстро и легко поддерживается глаз целевой Выбранные параметры и автоматически прокрутки текста, на которых пользователь взглянет на основе.</span><span class="sxs-lookup"><span data-stu-id="4996a-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="4996a-111">Намерения пользователя</span><span class="sxs-lookup"><span data-stu-id="4996a-111">User intent</span></span>    
<span data-ttu-id="4996a-112">Сведения о которых пользователь взглянет на предоставляет мощный **контекст для других входных данных**, например голосовой связи, руки и контроллеры.</span><span class="sxs-lookup"><span data-stu-id="4996a-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="4996a-113">Это может использоваться для различных задач.</span><span class="sxs-lookup"><span data-stu-id="4996a-113">This can be used for various tasks.</span></span>
<span data-ttu-id="4996a-114">Например, это может быть в диапазоне от быстро и легко **нацеливания** на сцене, просто просмотрев голограмма и о том, «select» (также см. в разделе [взглядом Head, чтобы зафиксировать](gaze-and-commit.md)) или произнести «put это...», затем заглядывающий через место размещения голограмма и сказать «... there».</span><span class="sxs-lookup"><span data-stu-id="4996a-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="4996a-115">Примеры для этого можно найти в [смешанной реальности Toolkit — поддерживается глаз Выбор целевой](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) и [смешанной реальности Toolkit — поддерживается глаз позиционирования целевой](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="4996a-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="4996a-116">Дополнительный пример для намерения пользователя может включать с помощью сведений о выглядеть на пользователей, для улучшения взаимодействия с embodied агентами виртуальные и интерактивные голограммы.</span><span class="sxs-lookup"><span data-stu-id="4996a-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="4996a-117">Для этого виртуального агенты могут адаптировать доступные параметры и их поведение на основе в настоящее время просматривать содержимое.</span><span class="sxs-lookup"><span data-stu-id="4996a-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="4996a-118">Неявные действия</span><span class="sxs-lookup"><span data-stu-id="4996a-118">Implicit actions</span></span>
<span data-ttu-id="4996a-119">Категория неявное действия тесно связана с намерения пользователя.</span><span class="sxs-lookup"><span data-stu-id="4996a-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="4996a-120">Идея в том, что голограммы или элементы пользовательского интерфейса реагировать немного instinctual способом, который может не даже показаться, что выполняется взаимодействие с системой вообще, а скорее находятся в синхронизированном системы и пользователя. Например, является одним из примеров чрезвычайно успешно **глаз взглядом на базе Автопрокрутка**.</span><span class="sxs-lookup"><span data-stu-id="4996a-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="4996a-121">Идея проста, как: Он считывает текст и можно просто продолжить чтение.</span><span class="sxs-lookup"><span data-stu-id="4996a-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="4996a-122">Текст плавно перемещается вверх держать пользователей в их чтения потока.</span><span class="sxs-lookup"><span data-stu-id="4996a-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="4996a-123">Ключевой аспект является то, что скорость прокрутки адаптируется к скорость чтения из него.</span><span class="sxs-lookup"><span data-stu-id="4996a-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="4996a-124">Другой пример — **поддерживается глаз масштабирования и панорамирования** для которого пользователь может воспринимается в качестве углубляться точно, на что он или она основным акцентом на.</span><span class="sxs-lookup"><span data-stu-id="4996a-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="4996a-125">Активации масштабирования и управления скоростью масштабирования можно управлять с помощью голоса или передать входные данные, что важно о предоставлении чувство элемента управления и избежать перегрузки пользователь (мы поговорим о этим рекомендациям по проектированию более подробно ниже).</span><span class="sxs-lookup"><span data-stu-id="4996a-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="4996a-126">После увеличения пользователя можно плавно следуйте, к примеру, в ходе улицу для изучения свой окружение просто для того, с помощью их взглядом глаз.</span><span class="sxs-lookup"><span data-stu-id="4996a-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="4996a-127">Демонстрация примеры для эти типы взаимодействия можно найти в [смешанной реальности Toolkit — поддерживается глаз навигации](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) образца.</span><span class="sxs-lookup"><span data-stu-id="4996a-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="4996a-128">Варианты для использования дополнительных _неявное действия_ могут включать:</span><span class="sxs-lookup"><span data-stu-id="4996a-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="4996a-129">**Смарт-уведомления:** Когда-либо получить самым с помощью уведомлений, всплывающее окно справа, где сосредоточившись?</span><span class="sxs-lookup"><span data-stu-id="4996a-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="4996a-130">Принимая во внимание, где пользователь в данный момент основное внимание уделяется вопросам, вы можете улучшить ее!</span><span class="sxs-lookup"><span data-stu-id="4996a-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="4996a-131">Показать смещение от где пользователь административным ограничить отвлекающих факторов и автоматически закрыть их один раз уведомлений завершения чтения.</span><span class="sxs-lookup"><span data-stu-id="4996a-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="4996a-132">**Внимательный голограммы:** Голограммы, может привести к некоторой реагировать при проверяемый.</span><span class="sxs-lookup"><span data-stu-id="4996a-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="4996a-133">Это может включать несколько свечение элементы пользовательского интерфейса, медленно blooming цветок с виртуального pet запуском для ретроспективного взгляда на вы или лишние ваши глаза взглядом после длительного последовательно.</span><span class="sxs-lookup"><span data-stu-id="4996a-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="4996a-134">Это может обеспечить интересных чувство связи и удовлетворения в вашем приложении.</span><span class="sxs-lookup"><span data-stu-id="4996a-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="4996a-135">Отслеживание внимания</span><span class="sxs-lookup"><span data-stu-id="4996a-135">Attention tracking</span></span>   
<span data-ttu-id="4996a-136">Сведения о которых пользователи рассмотрим можно чрезвычайно мощное средство для оценки удобство использования модели и выявить проблемы в эффективный рабочие потоки.</span><span class="sxs-lookup"><span data-stu-id="4996a-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="4996a-137">К этому моменту, отслеживания, визуализации и аналитики уже чаще всего выполняются в различных областях приложения.</span><span class="sxs-lookup"><span data-stu-id="4996a-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="4996a-138">С 2 HoloLens мы предоставляем новое измерение и понимание этого 3D голограммы можно поместить в реальном контексте и оцениваться вместе с.</span><span class="sxs-lookup"><span data-stu-id="4996a-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="4996a-139">[Смешанной реальности Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) предоставляет простые примеры, для ведения журнала и загрузки данных отслеживания и визуализировать их.</span><span class="sxs-lookup"><span data-stu-id="4996a-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="4996a-140">Другие приложения, в этой области могут включать:</span><span class="sxs-lookup"><span data-stu-id="4996a-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="4996a-141">**Визуализация взглядом удаленного глаза:** Визуализировать то, что удаленных участников совместной работы требуется в, например, обеспечьте ли инструкции понятны и соблюдение правильно.</span><span class="sxs-lookup"><span data-stu-id="4996a-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="4996a-142">**Примеры research пользователей:** Внимание отслеживания можно использовать для изучения того, начинающих программистов и экспертов пользователям визуально анализировать содержимое или их наличии глаз coordination в решении сложных задач (например, для анализа медицинских данных или в работе оборудования).</span><span class="sxs-lookup"><span data-stu-id="4996a-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="4996a-143">**Обучающие программы и мониторинг производительности:** Практики и оптимизировать выполнение задач, выявление узких мест, более эффективно в ходе выполнения.</span><span class="sxs-lookup"><span data-stu-id="4996a-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="4996a-144">**Разработка оценок, объявления и маркетинговых исследований.** Отслеживания — Это распространенный инструмент для исследования рынка для оценки веб-сайта и проектирование продукта.</span><span class="sxs-lookup"><span data-stu-id="4996a-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="4996a-145">Дополнительные варианты использования</span><span class="sxs-lookup"><span data-stu-id="4996a-145">Additional use cases</span></span>
- <span data-ttu-id="4996a-146">**Игры:** Иногда возникает необходимость иметь специалистами.</span><span class="sxs-lookup"><span data-stu-id="4996a-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="4996a-147">Есть шанс!</span><span class="sxs-lookup"><span data-stu-id="4996a-147">Here's your chance!</span></span> <span data-ttu-id="4996a-148">Levitate голограммы, глядя на них.</span><span class="sxs-lookup"><span data-stu-id="4996a-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="4996a-149">Устранение неисправностей образные лазерный ваши глаза.</span><span class="sxs-lookup"><span data-stu-id="4996a-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="4996a-150">Превратите противников в камне, или Фиксируйте их!</span><span class="sxs-lookup"><span data-stu-id="4996a-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="4996a-151">Используйте ваши рентгеновское зрение зданий.</span><span class="sxs-lookup"><span data-stu-id="4996a-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="4996a-152">Ваше воображение, ограничено!</span><span class="sxs-lookup"><span data-stu-id="4996a-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="4996a-153">**Выразительный аватары:** Глаз отслеживания помогает в более выразительный 3D аватары с помощью динамической глаз отслеживания даты для анимации аватар глаза, чтобы указать, что пользователь момент рассматривал.</span><span class="sxs-lookup"><span data-stu-id="4996a-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="4996a-154">Он также добавляет дополнительные выразительности, добавив мультики и каждое.</span><span class="sxs-lookup"><span data-stu-id="4996a-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="4996a-155">**Ввод текста:** Отслеживания используется в качестве альтернативы интересных для ввода текста низким усилий особенно в том случае, когда речь или руки неудобны для использования.</span><span class="sxs-lookup"><span data-stu-id="4996a-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="4996a-156">API отслеживания глаз</span><span class="sxs-lookup"><span data-stu-id="4996a-156">Eye tracking API</span></span>
<span data-ttu-id="4996a-157">Прежде чем углубляться в подробные сведения о рекомендации по разработке для взаимодействия с изображением глаза взглядом, мы хотим кратко пункты возможности, которые предоставляет средство отслеживания глаз 2 HoloLens.</span><span class="sxs-lookup"><span data-stu-id="4996a-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="4996a-158">[API отслеживания глаз](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) можно получить с помощью: `Windows.Perception.People.EyesPose`.</span><span class="sxs-lookup"><span data-stu-id="4996a-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="4996a-159">Он предоставляет луча взглядом единый eye (origin взглядом и направления) для разработчиков.</span><span class="sxs-lookup"><span data-stu-id="4996a-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="4996a-160">Средство отслеживания глаз предоставляет данные в о _30 кадров/с_.</span><span class="sxs-lookup"><span data-stu-id="4996a-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="4996a-161">Прогнозируемое глаз взглядом находится внутри ЦС.</span><span class="sxs-lookup"><span data-stu-id="4996a-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="4996a-162">1.0 — 1,5 градусов в visual угол вокруг фактический рассмотрели целевой объект.</span><span class="sxs-lookup"><span data-stu-id="4996a-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="4996a-163">Небольшая неточности надлежащим образом, следует учитывать некоторые поля вокруг этого значение нижней границы.</span><span class="sxs-lookup"><span data-stu-id="4996a-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="4996a-164">Мы обсудим это более ниже.</span><span class="sxs-lookup"><span data-stu-id="4996a-164">We will discuss this more below.</span></span> <span data-ttu-id="4996a-165">Для отслеживания работы точно глаза каждому пользователю требуется пройти за отслеживание калибровки пользователя.</span><span class="sxs-lookup"><span data-stu-id="4996a-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="4996a-166">![Размер оптимальной цели на расстоянии 2 средства измерения](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="4996a-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="4996a-167">*Размер оптимальной цели на расстоянии 2 средства измерения*</span><span class="sxs-lookup"><span data-stu-id="4996a-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="4996a-168">Рекомендации по проектированию взглядом глаз</span><span class="sxs-lookup"><span data-stu-id="4996a-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="4996a-169">Создание взаимодействие, которое использует преимущества быстрого перемещения глаз нацеливания может быть сложной задачей.</span><span class="sxs-lookup"><span data-stu-id="4996a-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="4996a-170">В этом разделе собраны ключевые преимущества и проблемы, которые необходимо учитывать при разработке приложения.</span><span class="sxs-lookup"><span data-stu-id="4996a-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="4996a-171">Преимущества глаз отслеживание взгляда</span><span class="sxs-lookup"><span data-stu-id="4996a-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="4996a-172">**Указывающий высокой скорости.**</span><span class="sxs-lookup"><span data-stu-id="4996a-172">**High speed pointing.**</span></span> <span data-ttu-id="4996a-173">Конфигурировать глаз — это самая быстрая reacting конфигурировать в наш текст.</span><span class="sxs-lookup"><span data-stu-id="4996a-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="4996a-174">**Незначительные трудозатраты.**</span><span class="sxs-lookup"><span data-stu-id="4996a-174">**Low effort.**</span></span> <span data-ttu-id="4996a-175">Необходимы едва любой физического перемещения.</span><span class="sxs-lookup"><span data-stu-id="4996a-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="4996a-176">**Implicitness.**</span><span class="sxs-lookup"><span data-stu-id="4996a-176">**Implicitness.**</span></span> <span data-ttu-id="4996a-177">Часто называются пользователями «виду материалы», информацию о движении глаз пользователя позволяет системе знать, цели пользовательские планы, чтобы привлечь.</span><span class="sxs-lookup"><span data-stu-id="4996a-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="4996a-178">**Альтернативный канал входных данных.**</span><span class="sxs-lookup"><span data-stu-id="4996a-178">**Alternative input channel.**</span></span> <span data-ttu-id="4996a-179">Взглядом глаз могут предоставить мощный вспомогательных входных данных вручную и голоса входной построение лежит многолетний опыт из пользователей, исходя их наличии глаза координации.</span><span class="sxs-lookup"><span data-stu-id="4996a-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="4996a-180">**Visual внимания.**</span><span class="sxs-lookup"><span data-stu-id="4996a-180">**Visual attention.**</span></span> <span data-ttu-id="4996a-181">Другим важным преимуществом является возможность определить, что пользователя основное внимание уделяется вопросам.</span><span class="sxs-lookup"><span data-stu-id="4996a-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="4996a-182">Это может помочь в различные аспекты приложения, начиная от более эффективно оценке различных схемы и помощь в эффективнее пользовательских интерфейсов и улучшенной социальной подсказки для удаленного обмена данными.</span><span class="sxs-lookup"><span data-stu-id="4996a-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="4996a-183">По сути, с помощью взглядом глаза, так как входные данные потенциально позволяет быстро и легко контекстные сигнал - эта возможность особенно эффективна в сочетании с другими входными данными например *голосовой* и *вручную* входных данных подтверждение намерения пользователя.</span><span class="sxs-lookup"><span data-stu-id="4996a-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="4996a-184">Проблемы глаз помощи в качестве входных данных</span><span class="sxs-lookup"><span data-stu-id="4996a-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="4996a-185">С большим количеством power поставляется множество ответственности: Хотя взглядом глаз можно использовать для создания походили главный супермен волшебное средство разрешения с пользователями, это также важно знать, что это не хорошо учетную запись для этого соответствующим образом.</span><span class="sxs-lookup"><span data-stu-id="4996a-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="4996a-186">Далее мы рассмотрим некоторые *проблемы* с весовым коэффициентом учетной записи и способы их устранения при работе с изображением глаза взгляда:</span><span class="sxs-lookup"><span data-stu-id="4996a-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="4996a-187">**Ваши глаза взглядом «always on»** некоторое время, откройте ваш lids глаз глаза начать fixating разговор в вашей среде.</span><span class="sxs-lookup"><span data-stu-id="4996a-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="4996a-188">Реагирование в каждый выглядеть марки и потенциально случайно выдачи действия, так как в него какие-либо слишком долго приведет к более ужасно возможности!</span><span class="sxs-lookup"><span data-stu-id="4996a-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="4996a-189">Именно поэтому мы рекомендуем объединение взглядом глаз с *голосовые команды*, *передать жест*, *нажатие кнопки* или расширенных простоя, чтобы активировать Выбор целевого объекта.</span><span class="sxs-lookup"><span data-stu-id="4996a-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="4996a-190">Это решение также позволяет в режиме, в котором пользователь может свободно оглядитесь без огромное чувство involuntarily активации что-то.</span><span class="sxs-lookup"><span data-stu-id="4996a-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="4996a-191">Эту проблему также следует принимать во внимание при проектировании наглядных и звуковых обратной связи, рассматривая просто целевого объекта.</span><span class="sxs-lookup"><span data-stu-id="4996a-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="4996a-192">Не перегрузить пользователя с помощью исчезающего влияние и наведите указатель мыши звуков.</span><span class="sxs-lookup"><span data-stu-id="4996a-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="4996a-193">Тонкость является ключом!</span><span class="sxs-lookup"><span data-stu-id="4996a-193">Subtlety is key!</span></span> <span data-ttu-id="4996a-194">Мы рассмотрим некоторые практические рекомендации для данного дальнейшей ниже при работе с этими рекомендации по проектированию.</span><span class="sxs-lookup"><span data-stu-id="4996a-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="4996a-195">**Наблюдения и управления** Imagine, вам нужно точно выровнять фотографии на стене.</span><span class="sxs-lookup"><span data-stu-id="4996a-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="4996a-196">Взглянуть на границах и окружающим его элементам, чтобы увидеть, если он выравнивает хорошо.</span><span class="sxs-lookup"><span data-stu-id="4996a-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="4996a-197">Теперь представьте, что бы вы делали, когда в то же время вы хотите использовать ваши глаза взглядом в качестве входных данных для перемещения на рисунке.</span><span class="sxs-lookup"><span data-stu-id="4996a-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="4996a-198">Сложно, правда?</span><span class="sxs-lookup"><span data-stu-id="4996a-198">Difficult, isn't it?</span></span> <span data-ttu-id="4996a-199">Это описание double роли взглядом глаза, при необходимости, как для входных данных и управления.</span><span class="sxs-lookup"><span data-stu-id="4996a-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="4996a-200">**Оставьте перед щелкните:** Для быстрого целевой выделений, исследования показали, что взглядом глаз пользователя могут быть перемещены прежде чем закончить щелчок вручную (например, airtap).</span><span class="sxs-lookup"><span data-stu-id="4996a-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="4996a-201">Таким образом особое внимание нужно уделить синхронизации сигнала взглядом быстрый глаз с медленнее входные данные элемента управления (например, голоса, руки, контроллер).</span><span class="sxs-lookup"><span data-stu-id="4996a-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="4996a-202">**Небольшой цели:** Знаете ли вы знакомы с предчувствием при попытке прочитать текст, который просто немного слишком мал для удобства чтения?</span><span class="sxs-lookup"><span data-stu-id="4996a-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="4996a-203">Этот straining чувство для глаз, вы доверяете устали и новым out, так как при попытке перенастроить глаза лучше сосредоточиться?</span><span class="sxs-lookup"><span data-stu-id="4996a-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="4996a-204">Это кажется, вы можете вызывать пользователей при их для выбора слишком мало целевых объектов в приложении при помощи нацеливания на глаза.</span><span class="sxs-lookup"><span data-stu-id="4996a-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="4996a-205">Для проектирования для создания более приятной и уверенно возможности для пользователей, мы рекомендуем что целевые объекты должны быть по крайней мере 2° visual угол, предпочтительно большего размера.</span><span class="sxs-lookup"><span data-stu-id="4996a-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="4996a-206">**Неоднородные перемещений взглядом глаз** этот момент выполнять быстрое перемещение из с фиксацией для с фиксацией.</span><span class="sxs-lookup"><span data-stu-id="4996a-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="4996a-207">Если взглянуть на проверку пути перемещений записанные глаза, вы увидите, что они выглядят выравнивания.</span><span class="sxs-lookup"><span data-stu-id="4996a-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="4996a-208">Переместить глаза, быстро и в свободной форме перемещается по сравнению с *головного взглядом* или *передать движения*.</span><span class="sxs-lookup"><span data-stu-id="4996a-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="4996a-209">**Отслеживание надежности.** Точность отслеживания может привести к снижению немного в изменении свет, внимание к настройке для новых условий.</span><span class="sxs-lookup"><span data-stu-id="4996a-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="4996a-210">Хотя это не должна влиять на обязательно своего проекта приложения, как точность не может превышать ограничение в упомянутое выше 2°.</span><span class="sxs-lookup"><span data-stu-id="4996a-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="4996a-211">Это может означать, что пользователь имеет для запуска другой калибровки.</span><span class="sxs-lookup"><span data-stu-id="4996a-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="4996a-212">Рекомендации по проектированию</span><span class="sxs-lookup"><span data-stu-id="4996a-212">Design recommendations</span></span>
<span data-ttu-id="4996a-213">Ниже перечислены рекомендации по разработке на основании описаны преимущества и трудности для глаз помощи входные данные:</span><span class="sxs-lookup"><span data-stu-id="4996a-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="4996a-214">**Взглядом глаз! = взглядом Head:**</span><span class="sxs-lookup"><span data-stu-id="4996a-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="4996a-215">**Рассмотрим ли быстрое перемещений неоднородные глаз соответствия входной задаче:** Хотя наши глаза быстрого и менее совершенных перемещений удобны для быстрого выбора целевых объектов по нашей поле зрения, это понижает его применимость для задач, требующих smooth траекторий ввода (например, при рисовании или encircling заметки).</span><span class="sxs-lookup"><span data-stu-id="4996a-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="4996a-216">В этом случае вручную или head указывает лучше использовать.</span><span class="sxs-lookup"><span data-stu-id="4996a-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="4996a-217">**Избегайте присоединении что-то непосредственно к взглядом глаз пользователя (например, "ползунок" или курсора).**</span><span class="sxs-lookup"><span data-stu-id="4996a-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="4996a-218">В случае курсора это может привести эффект «fleeing курсора» из-за небольшое смещения в сигнале взглядом проецируемых глаз.</span><span class="sxs-lookup"><span data-stu-id="4996a-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="4996a-219">В случае ползунка она конфликтует с двойной роль управления "ползунок" с закрытыми глазами при также хочет проверить, является ли объект на правильное расположение.</span><span class="sxs-lookup"><span data-stu-id="4996a-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="4996a-220">По сути пользователи могут быстро вы перегружен и отвлекают, особенно, соответствует ли сигнал неточный для этого пользователя.</span><span class="sxs-lookup"><span data-stu-id="4996a-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="4996a-221">**Взглядом глаз объединить с другими входными данными:** Интеграция глаз отслеживания других входных данных, например жестами руками, голосовые команды или при нажатии кнопки, выполняет несколько преимуществ:</span><span class="sxs-lookup"><span data-stu-id="4996a-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="4996a-222">**Разрешить бесплатное наблюдения:** Основную роль этот момент представляет для наблюдения за нашей среде, важно позволяют пользователям просматривать без активации любой (визуальном элементе аудитории,...) обратной связи или действия.</span><span class="sxs-lookup"><span data-stu-id="4996a-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="4996a-223">Объединение ET с другим элементом позволяет плавно переход между ET наблюдения и режимов управления вводом.</span><span class="sxs-lookup"><span data-stu-id="4996a-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="4996a-224">**Поставщик мощные контекста:** Используя сведения о, где пользователь просматривает при uttering голосовых команд или выполнении жеста вручную позволяет без труда сразу передавать входные данные в поле зрения.</span><span class="sxs-lookup"><span data-stu-id="4996a-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="4996a-225">Ниже перечислены примеры таких данных. «Put, существует» быстро и согласованно взаимодействуют выберите и поместите голограмма через сцены, просто просмотрев целевой объект и целевой.</span><span class="sxs-lookup"><span data-stu-id="4996a-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="4996a-226">**Потребность в синхронизации Многорежимные входные данные («оставьте перед нажмите кнопку» проблема):** Объединение перемещений глаз частых более сложных дополнительных входных данных (например, длинные голосовые команды или жестами руками) есть риск перехода с ваши глаза взглядом перед завершением работы дополнительных входных команд.</span><span class="sxs-lookup"><span data-stu-id="4996a-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="4996a-227">Таким образом Если вы создаете свои собственные элементы управления для ввода (например, настраиваемых вручную жестов), убедитесь, что журнала с момента этого периода ввода или приблизительного, его необходимо согласовать с что пользователя fixated на в прошлом.</span><span class="sxs-lookup"><span data-stu-id="4996a-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="4996a-228">**Слабая отзыв для отслеживания входных данных:** Это полезно для предоставления отзывов в том случае, если целевой объект рассмотрели (для указания, что система работает должным образом), но следует хранить небольшие.</span><span class="sxs-lookup"><span data-stu-id="4996a-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="4996a-229">Это может включать медленно смешение ввода-вывода основные особенности visual или выполнять другие незначительные целевой поведения, такие как медленное движения (например, немного увеличить целевой объект) для указания, что система правильно обнаружила, что пользователь просматривает целевой объект, однако без без необходимости прерывания рабочего процесса для текущего пользователя.</span><span class="sxs-lookup"><span data-stu-id="4996a-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="4996a-230">**Избегайте применения перемещений понятном и естественном глаз как входные данные:** Не выполнять принудительное пользователям выполнять определенные глаз перемещений (взглядом жестов) для запуска действий в приложении.</span><span class="sxs-lookup"><span data-stu-id="4996a-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="4996a-231">**Учтите место для неточности.** Имеется два типа неточности которой заметны пользователям: Смещение и нарушение синхронизации.</span><span class="sxs-lookup"><span data-stu-id="4996a-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="4996a-232">Самый простой способ адрес смещения, — для обеспечения достаточно большой целевых объектов для взаимодействия с (> 2° visual угол — как ссылка: эскиз — около 2° visual угол при многократном out arm (1)).</span><span class="sxs-lookup"><span data-stu-id="4996a-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="4996a-233">Это приводит к инструкциям ниже:</span><span class="sxs-lookup"><span data-stu-id="4996a-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="4996a-234">Не выполнять принудительное пользователям выбирать Крошечные объекты: Исследования показали, что если целевые объекты не обладает достаточным размером (система тщательно продумана), пользователи описываются взаимодействия как простые и создавать Волшебный.</span><span class="sxs-lookup"><span data-stu-id="4996a-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="4996a-235">Если целевые объекты становятся слишком мал, пользователи описываются практические принципы как fatiguing и нервов.</span><span class="sxs-lookup"><span data-stu-id="4996a-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
    
# <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="4996a-236">Рекомендации по проектированию взглядом глаз</span><span class="sxs-lookup"><span data-stu-id="4996a-236">Eye gaze design guidelines</span></span>

<span data-ttu-id="4996a-237">С 2 HoloLens у нас есть отличная возможность улучшить взглядом & фиксации быстрее и удобнее, используя вместо головного взглядом взглядом глаз.</span><span class="sxs-lookup"><span data-stu-id="4996a-237">With HoloLens 2, we have the great opportunity to make gaze & commit faster and more comfortable by using eye gaze instead of head gaze.</span></span> <span data-ttu-id="4996a-238">Тем не менее взглядом глаз ведет себя по-разному очень головной взглядом определенными способами, а также таким образом поставляется несколько уникальных задач.</span><span class="sxs-lookup"><span data-stu-id="4996a-238">However, eye gaze behaves very differently to head gaze in certain ways and hence comes with a number of unique challenges.</span></span> <span data-ttu-id="4996a-239">В глаза помощи рекомендации по проектированию собраны общие преимущества и проблемы, которые необходимо учитывать при использовании отслеживания глаза в качестве входного средний в приложении holographic.</span><span class="sxs-lookup"><span data-stu-id="4996a-239">In Eye Gaze Design Guidelines, we summarize general advantages and challenges to take into account when using eye tracking as an input medium in your holographic app.</span></span> <span data-ttu-id="4996a-240">В этом разделе рассматриваются вопросы по разработке для глаз взглядом & фиксации.</span><span class="sxs-lookup"><span data-stu-id="4996a-240">In this section, we focus on the specific design considerations for eye gaze & commit.</span></span> <span data-ttu-id="4996a-241">Во-первых этот момент ориентированы на невероятно быструю работу и таким образом удобно быстро единообразие в представлении.</span><span class="sxs-lookup"><span data-stu-id="4996a-241">First, our eyes move incredibly fast and thus are great at quickly targeting across the view.</span></span> <span data-ttu-id="4996a-242">Это делает глаз помощи идеально подходят для быстрого взглядом & фиксации действия, особенно в сочетании с быстрой фиксации, например press жест касания или кнопки.</span><span class="sxs-lookup"><span data-stu-id="4996a-242">This makes eye gaze ideal for quick gaze & commit actions especially when combined with fast commits such as an air-tap or button press.</span></span>

<span data-ttu-id="4996a-243">Больше не показывать курсора: Хотя почти невозможно взаимодействие без курсора, при использовании head помощи, указатель примет вид быстро мешает работе и раздражающих при использовании взглядом глаз.</span><span class="sxs-lookup"><span data-stu-id="4996a-243">Do not show a cursor: While it is nearly impossible to interact without a cursor when using head gaze, the cursor becomes quickly distracting and annoying when using eye gaze.</span></span> <span data-ttu-id="4996a-244">Вместо того чтобы курсор, чтобы информировать пользователей ли отслеживания работает и имеет правильно, обнаруженных в настоящее время поиск на целевом объекте, используйте небольшие visual выделяет (более подробное описание ниже).</span><span class="sxs-lookup"><span data-stu-id="4996a-244">Instead of relying on a cursor to inform the user whether eye tracking is working and has correctly detected the currently looked at target, use subtle visual highlights (more details below).</span></span>

<span data-ttu-id="4996a-245">Стремитесь к обратной связи слабая переходом при наведении указателя мыши: Что кажется отличным визуальную обратную связь для головного взглядом может привести к появлению ужасно, непреодолимой сред, с помощью взглядом глаз.</span><span class="sxs-lookup"><span data-stu-id="4996a-245">Strive for subtle blended hover feedback: What seems great visual feedback for head gaze can result in terrible, overwhelming experiences using eye gaze.</span></span> <span data-ttu-id="4996a-246">Помните, что глаза являются невероятно быстро, быстро darting между точками в вашего поля зрения.</span><span class="sxs-lookup"><span data-stu-id="4996a-246">Remember that your eyes are enormously fast, quickly darting across points in your field-of-view.</span></span> <span data-ttu-id="4996a-247">Быстрое выделение внезапные изменения (вкл. / выкл.) может привести flickery обратной связи при всматриваться.</span><span class="sxs-lookup"><span data-stu-id="4996a-247">Quick sudden highlight changes (on/off) may result in flickery feedback when looking around.</span></span> <span data-ttu-id="4996a-248">Таким образом при обратной связи при наведении указателя мыши, мы рекомендуем использовать выделение плавно смешением в (и смешением масштабирование при поиске сейчас).</span><span class="sxs-lookup"><span data-stu-id="4996a-248">So, when providing hover feedback, we recommend using a smoothly blended-in highlight (and blended-out when looking away).</span></span> <span data-ttu-id="4996a-249">Это означает, что сначала вы едва заметите обратной связи при просмотре целевого объекта.</span><span class="sxs-lookup"><span data-stu-id="4996a-249">This means that at first you would barely notice the feedback when looking at a target.</span></span> <span data-ttu-id="4996a-250">В ходе 500 – 1000 мс выделение будет увеличение интенсивности.</span><span class="sxs-lookup"><span data-stu-id="4996a-250">Over the course of 500-1000 ms the highlight would increase in intensity.</span></span> <span data-ttu-id="4996a-251">Хотя начинающие пользователи могут продолжить поиск на целевом компьютере, чтобы убедиться, что система правильно определила фокусом целевой объект, опытных пользователей может быстро помощи & фиксируются без ожидания завершения до его полная насыщенность обратной связи.</span><span class="sxs-lookup"><span data-stu-id="4996a-251">While novice users could keep looking at the target to ensure that the system has correctly determined the focused target, expert users could quickly gaze & commit without waiting until the feedback is at its full intensity.</span></span> <span data-ttu-id="4996a-252">Кроме того также рекомендуется использовать горизонтального blend при исчезновение обратной связи при наведении курсора мыши.</span><span class="sxs-lookup"><span data-stu-id="4996a-252">In addition, we also recommend using a blend-out when fading out the hover feedback.</span></span> <span data-ttu-id="4996a-253">Исследования показали, что быстрые изменения методологии motion и контрастности очень заметны в вашей периферийное зрение (то есть область поля visual, где не требуется).</span><span class="sxs-lookup"><span data-stu-id="4996a-253">Research has shown that quick motion and contrast changes are very noticeable in your peripheral vision (so, the area of your visual field where you are not looking).</span></span> <span data-ttu-id="4996a-254">Затухания не должен быть же медленно, как blend в.</span><span class="sxs-lookup"><span data-stu-id="4996a-254">The fade-out doesn't have to be as slow as the blend-in.</span></span> <span data-ttu-id="4996a-255">Это важно только при наличии высокой контрастности или изменение цвета для вашей выделения.</span><span class="sxs-lookup"><span data-stu-id="4996a-255">This is only critical when you have high contrast or color changes for your highlight.</span></span> <span data-ttu-id="4996a-256">Если с самого начала была довольно слабая обратной связи при наведении указателя мыши, вы подход, скорее всего, не заметят разницы.</span><span class="sxs-lookup"><span data-stu-id="4996a-256">If the hover feedback was pretty subtle to begin with, you probably won't notice a difference.</span></span>

<span data-ttu-id="4996a-257">Следите за синхронизация сигналы взглядом и фиксации: Синхронизации сигналов ввода может быть менее сложной задачей для простой взглядом и фиксации, таким образом, не беспокойтесь!</span><span class="sxs-lookup"><span data-stu-id="4996a-257">Look out for synchronizing gaze and commit signals: The synchronization of input signals may be less of a challenge for simple gaze & commit, so, don't worry!</span></span> <span data-ttu-id="4996a-258">Это что-то нужно обратить внимание в случае, если вы хотите использовать более сложные действия фиксации, хотя, может включать в себя длинный голосовые команды или сложным привычные жесты.</span><span class="sxs-lookup"><span data-stu-id="4996a-258">It is something to look out for in case you want to use more complicated commit actions though that may involve long voice commands or complicated hand gestures.</span></span> <span data-ttu-id="4996a-259">Предположим, вы посмотрите на целевой объект и тещи long голосовые команды.</span><span class="sxs-lookup"><span data-stu-id="4996a-259">Imagine you look at target and utter a long voice command.</span></span> <span data-ttu-id="4996a-260">Учитывать время, когда необходимо говорить и время, когда система требуется обнаружить, что вы сказали, ваши глаза взглядом обычно долго перейдет в некоторых новый целевой объект в сцене.</span><span class="sxs-lookup"><span data-stu-id="4996a-260">Taken into account the time that you needed to speak and the time that the system needed to detect what you said, your eye gaze has usually long moved on to some new target in the scene.</span></span> <span data-ttu-id="4996a-261">Таким образом либо сделайте виду, что они могут нужно продолжить поиск в целевой объект, пока не был распознан команды или обработал эти входные данные, как определить начале команды и что пользователь просмотрев тогда пользователи.</span><span class="sxs-lookup"><span data-stu-id="4996a-261">Hence, either make your users aware that they may need to keep looking at a target until the command has been recognized or handle the input in a way to determine the onset of the command and what the user had been looking at back then.</span></span>

## <a name="see-also"></a><span data-ttu-id="4996a-262">См. также</span><span class="sxs-lookup"><span data-stu-id="4996a-262">See also</span></span>
* [<span data-ttu-id="4996a-263">Направление головы и фиксация</span><span class="sxs-lookup"><span data-stu-id="4996a-263">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="4996a-264">Жесты</span><span class="sxs-lookup"><span data-stu-id="4996a-264">Gestures</span></span>](gestures.md)
* [<span data-ttu-id="4996a-265">Голосовые команды</span><span class="sxs-lookup"><span data-stu-id="4996a-265">Voice commanding</span></span>](voice-design.md)
* [<span data-ttu-id="4996a-266">Контроллеры движения</span><span class="sxs-lookup"><span data-stu-id="4996a-266">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="4996a-267">Комфорт</span><span class="sxs-lookup"><span data-stu-id="4996a-267">Comfort</span></span>](comfort.md)
