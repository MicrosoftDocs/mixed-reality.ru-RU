---
title: Отслеживание взгляда
description: HoloLens 2 позволяет организовать голографическое взаимодействие на новом уровне понимания контекста и намерений человека, предоставляя разработчикам возможности для использования информации о том, куда смотрят пользователи.
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: Отслеживание взгляда, Смешанная реальность, ввод, глаз-взгляд, калибровка
ms.openlocfilehash: 60de5ceb9f55ca7e2f74856af9bd75567763e382
ms.sourcegitcommit: a5dc182da237f63f0487d40a2e11894027208b6c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/02/2019
ms.locfileid: "73441115"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="7f8f5-104">Отслеживание взгляда в HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="7f8f5-104">Eye tracking on HoloLens 2</span></span>

![Демонстрация отслеживания взгляда в МРТК](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="7f8f5-106">HoloLens 2 позволяет организовать голографическое взаимодействие на новом уровне понимания контекста и намерений человека, предоставляя разработчикам возможности для использования информации о том, куда смотрят пользователи.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-106">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="7f8f5-107">На этой странице представлен обзор этой новой возможности для разработчиков и проектировщиков, позволяющих получить преимущества от отслеживания взгляда для различных вариантов использования и базовых руководств для разработчиков.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-107">This page provides an overview of this new capability to developers and designers on how they can benefit from eye tracking for various use cases and basic developer guidance.</span></span> 


## <a name="calibration"></a><span data-ttu-id="7f8f5-108">Монитора</span><span class="sxs-lookup"><span data-stu-id="7f8f5-108">Calibration</span></span> 
<span data-ttu-id="7f8f5-109">Чтобы отслеживание взгляда работало правильно, каждый пользователь должен пройти по [калибровке пользователя с отслеживанием взгляда](calibration.md) , для которого пользователь должен взглянуть на набор holographic мишеней.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-109">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="7f8f5-110">Это позволяет устройству настроить систему для более удобного и качественного просмотра для пользователя, а также для обеспечения точного отслеживания в то же время.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-110">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> <span data-ttu-id="7f8f5-111">Отслеживание взгляда должно работать для большинства пользователей, но в редких случаях пользователь не может успешно выполнить калибровку.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-111">Eye tracking should work for most users, but there are rare cases in which a user might be unable to calibrate successfully.</span></span>
<span data-ttu-id="7f8f5-112">Дополнительные сведения о калибровке и о том, как обеспечить бесперебойную работу, см. на странице [калибровка пользователей для отслеживания взгляда](calibration.md) .</span><span class="sxs-lookup"><span data-stu-id="7f8f5-112">To learn more about the calibration and about how to ensure a smooth experience, please check our [eye tracking user calibration](calibration.md) page.</span></span>


## <a name="device-support"></a><span data-ttu-id="7f8f5-113">Поддержка устройств</span><span class="sxs-lookup"><span data-stu-id="7f8f5-113">Device support</span></span>
<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="7f8f5-114"><strong>Функциями</strong></span><span class="sxs-lookup"><span data-stu-id="7f8f5-114"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="7f8f5-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1-го поколения)</strong></a></span><span class="sxs-lookup"><span data-stu-id="7f8f5-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="7f8f5-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="7f8f5-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="7f8f5-117"><a href="immersive-headset-hardware-details.md"><strong>Иммерсивные гарнитуры</strong></a></span><span class="sxs-lookup"><span data-stu-id="7f8f5-117"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="7f8f5-118">Взгляд — взгляд</span><span class="sxs-lookup"><span data-stu-id="7f8f5-118">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="7f8f5-119">✔️</span><span class="sxs-lookup"><span data-stu-id="7f8f5-119">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

## <a name="available-eye-tracking-data"></a><span data-ttu-id="7f8f5-120">Доступные данные отслеживания взгляда</span><span class="sxs-lookup"><span data-stu-id="7f8f5-120">Available eye tracking data</span></span>
<span data-ttu-id="7f8f5-121">Прежде чем приступить к подробному рассмотрению конкретных вариантов использования для ввода взгляда, мы хотим вкратце описать возможности, предоставляемые [API отслеживания взгляда](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-121">Before going into detail about specific use cases for eye-gaze input, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="7f8f5-122">Разработчики получают доступ к одному лучау глаза (источнику и направлению взгляда) приблизительно в _30 кадров/с (30 Гц)_ .</span><span class="sxs-lookup"><span data-stu-id="7f8f5-122">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (30 Hz)_.</span></span>
<span data-ttu-id="7f8f5-123">Более подробные сведения о том, как получить доступ к данным отслеживания взгляда, см. в руководствах для разработчиков, посвященных использованию [глаз-взгляда в DirectX](gaze-in-directx.md) и [глаза-взгляде в Unity](https://aka.ms/mrtk-eyes).</span><span class="sxs-lookup"><span data-stu-id="7f8f5-123">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="7f8f5-124">Прогнозируемый глаз — это приблизительно в 1,5 градусов визуального угла вокруг фактического целевого объекта (см. рисунок ниже).</span><span class="sxs-lookup"><span data-stu-id="7f8f5-124">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="7f8f5-125">Как и в случае с небольшим количеством неточностей, разработчики должны запланировать некоторое поле вокруг этого нижнего значения (например, 2.0-3.0 градусов может привести к более удобному интерфейсу).</span><span class="sxs-lookup"><span data-stu-id="7f8f5-125">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="7f8f5-126">Мы обсудим, как более подробно решать выбор мелких целевых объектов.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-126">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="7f8f5-127">Чтобы отслеживание взгляда работало точно, каждому пользователю нужно пройти калибровку отслеживания взгляда.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-127">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="7f8f5-128">![Оптимальный размер целевого объекта на расстоянии 2 метра](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="7f8f5-128">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="7f8f5-129">*Оптимальный размер целевого объекта на расстоянии в 2 метра*</span><span class="sxs-lookup"><span data-stu-id="7f8f5-129">*Optimal target size at a 2-meter distance*</span></span>

<br>

## <a name="use-cases"></a><span data-ttu-id="7f8f5-130">Варианты использования</span><span class="sxs-lookup"><span data-stu-id="7f8f5-130">Use cases</span></span>
<span data-ttu-id="7f8f5-131">Функция отслеживание взгляда предоставляет приложениям сведения о том, куда смотрит пользователь в реальном времени.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-131">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="7f8f5-132">В следующих вариантах использования описаны некоторые взаимодействия, которые можно выполнить с отслеживанием глаз в HoloLens 2 в смешанной реальности.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-132">The following use cases describe some interactions that are possible with eye tracking on HoloLens 2 in mixed reality.</span></span>
<span data-ttu-id="7f8f5-133">Обратите внимание, что эти варианты использования еще не являются частью работы с оболочкой holographic (т. е. интерфейса, который вы видите при запуске HoloLens 2).</span><span class="sxs-lookup"><span data-stu-id="7f8f5-133">Please note that these use cases are not yet part of the Holographic Shell experience (i.e., the interface that you see when you start up your HoloLens 2).</span></span>
<span data-ttu-id="7f8f5-134">Некоторые из них можно испытать в [наборе средств для смешанной реальности](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) , который предоставляет несколько интересных и мощных примеров для использования отслеживания взгляда, таких как быстрый и простой в использовании Выбор целевого объекта, а также автоматическая прокрутка текста на основе о том, что видят пользователи.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-134">You can try some of them out in the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) which provides several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="7f8f5-135">Намерения пользователя</span><span class="sxs-lookup"><span data-stu-id="7f8f5-135">User intent</span></span>    
<span data-ttu-id="7f8f5-136">Сведения о том, где и как выглядит пользователь, предоставляет мощный **контекст для других входных данных**, таких как Voice, руки и контроллеры.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-136">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="7f8f5-137">Эти данные можно применять в разных задачах.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-137">This can be used for various tasks.</span></span>
<span data-ttu-id="7f8f5-138">Например, это может варьироваться от быстрого и легко **нацеливания** на сцену, просто взглянув на голограмму и выполнив *команду "Select"* (см. раздел « [взгляд» и «фиксация](gaze-and-commit.md)») или *«поместить это...»* , просматривая место, где пользователь хочет поместить голограмму и сказать *: «... Здесь "* .</span><span class="sxs-lookup"><span data-stu-id="7f8f5-138">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying *"select"* (also see [gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="7f8f5-139">Подобные примеры доступны в наборах средств для смешанной реальности для [выбора целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) и [позиционирования целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="7f8f5-139">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="7f8f5-140">Кроме того, пример намерения пользователя может включать в себя сведения о том, что видят пользователи, чтобы улучшить работу с помощью применяющихся виртуальных агентов и интерактивных голограмм.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-140">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="7f8f5-141">Например, виртуальные агенты могут адаптировать доступные параметры и их поведение на основе текущего просматриваемого содержимого.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-141">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="7f8f5-142">Неявные действия</span><span class="sxs-lookup"><span data-stu-id="7f8f5-142">Implicit actions</span></span>
<span data-ttu-id="7f8f5-143">Категория неявных действий тесно связана с намерениями пользователя.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-143">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="7f8f5-144">Идея состоит в том, что голограммы или элементы пользовательского интерфейса реагируют на инстинктуале, что может даже не показаться, что пользователь взаимодействует с системой вообще, а сам система и пользователь синхронизированы. Одним из примеров является **Автоматическая прокрутка на основе взгляда на глаза** , когда пользователь может прочитать длинный текст, который автоматически начинает прокручиваться после того, как пользователь получит доступ к нижней части текстового поля, чтобы пользователь оставался в потоке чтения без отрыва пальца.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-144">The idea is that holograms or user interface elements react in an instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="7f8f5-145">Ключевым аспектом этого процесса является то, что скорость прокрутки адаптируется к скорости чтения пользователя.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-145">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="7f8f5-146">В качестве другого примера можно возместить **масштаб и панораму** , в котором пользователь может точно соответствовать тем, на что он направлен.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-146">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="7f8f5-147">Для управления скоростью масштабирования и управления ею можно управлять с помощью голоса или ввода-вывода, что важно для предоставления пользователю прав на управление и предотвращения переполнения.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-147">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="7f8f5-148">Более подробно эти вопросы по проектированию будут обсуждаться ниже.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-148">We will talk about these design considerations in more detail below.</span></span> <span data-ttu-id="7f8f5-149">После масштабирования пользователь может плавно проследить за тем, что, например, разообразить свое окружение, просто воспользовавшись знаком взгляда.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-149">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="7f8f5-150">Эти типы взаимодействия демонстрируются в примере набора средств для смешанной реальности для [навигации с поддержкой взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="7f8f5-150">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="7f8f5-151">В качестве дополнительных примеров _неявных действий_ можно назвать следующее:</span><span class="sxs-lookup"><span data-stu-id="7f8f5-151">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="7f8f5-152">**Интеллектуальные уведомления:** Всегда получаете раздражен по уведомлениям, которые выводятся справа, где вы находитесь?</span><span class="sxs-lookup"><span data-stu-id="7f8f5-152">**Smart notifications:** Ever get annoyed by notifications popping up right where you are looking?</span></span> <span data-ttu-id="7f8f5-153">Принимая во внимание то, к какому пользователю относится пользователь, вы можете сделать этот процесс более эффективным, потратив уведомления от того, где пользователь в настоящее время облаками.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-153">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="7f8f5-154">Это ограничивает число обращений и автоматически закрывает их после того, как пользователь закончит чтение.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-154">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="7f8f5-155">**Голограммы внимательный:** Голограммы, которые слегка реагируют на газед.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-155">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="7f8f5-156">Это может варьироваться от слегка свечения элементов пользовательского интерфейса, медленного цветутного цветок до виртуальной Dog, начинающейся с пользователя, и ваггинг его хвост.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-156">This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.</span></span> <span data-ttu-id="7f8f5-157">Это взаимодействие может предоставить интересное представление о подключении и удовлетворенности приложения.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-157">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="7f8f5-158">Отслеживание внимания</span><span class="sxs-lookup"><span data-stu-id="7f8f5-158">Attention tracking</span></span>   
<span data-ttu-id="7f8f5-159">Сведения о том, где или как видят пользователи, — это чрезвычайно мощный инструмент для оценки удобства использования дизайнов и выявления проблем в эффективных рабочих процессах.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-159">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="7f8f5-160">Визуализация и аналитика отслеживания взгляда являются распространенной практикой в различных областях приложений.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-160">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="7f8f5-161">С помощью HoloLens 2 мы предоставляем новое измерение для понимания того, как трехмерные голограммы могут быть помещены в реальные контексты и оцениваться соответствующим образом.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-161">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="7f8f5-162">[Набор средств Mixed Reality](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) предоставляет основные примеры ведения журнала и загрузки данных отслеживания взгляда, а также способы их визуализации.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-162">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and how to visualize them.</span></span>

<span data-ttu-id="7f8f5-163">Другие приложения из этой сферы поддерживают следующие функции:</span><span class="sxs-lookup"><span data-stu-id="7f8f5-163">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="7f8f5-164">**Удаленный взгляд — визуализация взгляда:** Визуализация удаленных участников совместной работы для повышения общего понимания.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-164">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to increase shared understanding.</span></span>
-   <span data-ttu-id="7f8f5-165">Исследования **пользователей:** Отслеживание внимания помогает лучше понять, как мы будем воспринимать и привлекать к нашей среде, что может помочь в улучшении моделей человеческих людей для более инстинктуалного взаимодействия с человеком-компьютером.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-165">**User research studies:** Attention tracking can help better understanding how we perceive and engage with our environment which may help in better human intent models for more instinctual human-computer-interactions.</span></span> 
-   <span data-ttu-id="7f8f5-166">**Обучение:** Улучшенное обучение для новичков. лучше понимать шаблоны визуального поиска экспертов и выполнять сложные задачи, например для анализа медицинских данных или использования операционных машин.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-166">**Training:** Improved training of novices by better understanding experts' visual search patterns and their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="7f8f5-167">**Оценка проектирования и исследование рынка:** Отслеживание взгляда — это распространенный инструмент для исследования рынка при оценке моделей веб-сайтов и продуктов.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-167">**Design evaluations and market research:** Eye tracking is a common tool for market research when evaluating website and product designs.</span></span> <span data-ttu-id="7f8f5-168">С помощью HoloLens 2 можно расширить это до трехмерных пространств, объединив варианты проектирования цифровых продуктов с физической средой.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-168">With HoloLens 2, we can extend this to 3D spaces by merging digital product design variants with the physical environment.</span></span> 

### <a name="additional-use-cases"></a><span data-ttu-id="7f8f5-169">Другие варианты использования</span><span class="sxs-lookup"><span data-stu-id="7f8f5-169">Additional use cases</span></span>
- <span data-ttu-id="7f8f5-170">**Игры:** Когда-нибудь хотели, чтобы у меня была сила?</span><span class="sxs-lookup"><span data-stu-id="7f8f5-170">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="7f8f5-171">Вам сюда!</span><span class="sxs-lookup"><span data-stu-id="7f8f5-171">Here's your chance!</span></span> <span data-ttu-id="7f8f5-172">Вы можете левитате голограммы на них.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-172">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="7f8f5-173">Прокрутка лазерного беамса от глаз. Попробуйте в [робораид для HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span><span class="sxs-lookup"><span data-stu-id="7f8f5-173">Shoot laser beams from your eyes - try it out in [RoboRaid for HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span></span>
<span data-ttu-id="7f8f5-174">Превратите противников в камень или закрепите их.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-174">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="7f8f5-175">Примените рентгеновское зрение, чтобы исследовать здания.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-175">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="7f8f5-176">Вы ограничены только пределами своего воображения!</span><span class="sxs-lookup"><span data-stu-id="7f8f5-176">Your imagination is the limit!</span></span>
<span data-ttu-id="7f8f5-177">Будьте осторожны, чтобы узнать больше, ознакомьтесь с [рекомендациями по проектированию ввода на основе взгляда на глаза](eye-gaze-interaction.md).</span><span class="sxs-lookup"><span data-stu-id="7f8f5-177">Beware of not overwhelming the user though - to find out more, check out our [eye-gaze-based input design guidelines](eye-gaze-interaction.md).</span></span>

- <span data-ttu-id="7f8f5-178">**Выразительные аватары:** Отслеживание взгляда помогает в более выразительных трехмерных аватарах, используя данные отслеживания взгляда, чтобы анимировать глаза аватара, указывающие, что именно видят пользователи.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-178">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="7f8f5-179">**Текстовая запись:** Отслеживание взгляда можно использовать в качестве альтернативы для ввода текста с низкой наработкой, особенно если речь или руки неудобны для использования.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-179">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 

<br>

## <a name="using-eye-gaze-for-interaction"></a><span data-ttu-id="7f8f5-180">Использование глаза — взгляд на взаимодействие</span><span class="sxs-lookup"><span data-stu-id="7f8f5-180">Using eye-gaze for interaction</span></span>
<span data-ttu-id="7f8f5-181">Создание взаимодействия, которое использует преимущества быстрого перемещения глаз, может оказаться сложной задачей.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-181">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span>
<span data-ttu-id="7f8f5-182">С одной стороны, глаза перемещаются настолько быстро, что необходимо соблюдать осторожность при использовании входных данных взгляда на глаза, так как в противном случае пользователь может найти ненужные или неудобства.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-182">On the one hand, the eyes move so fast that you need to be careful on how to use eye-gaze input, because otherwise user may find the experience overwhelming or distracting.</span></span> <span data-ttu-id="7f8f5-183">С другой стороны, вы также можете создать действительно magicalные возможности, которые будут Стимулируйте обучение ваши пользователи!</span><span class="sxs-lookup"><span data-stu-id="7f8f5-183">On the other hand, you can also create truly magical experiences that will excite your users!</span></span> <span data-ttu-id="7f8f5-184">Чтобы помочь вам, ознакомьтесь с обзором основных преимуществ, задач и рекомендаций по проектированию, чтобы узнать о [взаимодействии](eye-gaze-interaction.md).</span><span class="sxs-lookup"><span data-stu-id="7f8f5-184">To help you, check out our overview of key advantages, challenges and design recommendations for [eye-gaze for interaction](eye-gaze-interaction.md).</span></span> 

<br>
 
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a><span data-ttu-id="7f8f5-185">Руководство разработчика: что делать, если отслеживание взгляда недоступно?</span><span class="sxs-lookup"><span data-stu-id="7f8f5-185">Dev guidance: What if eye tracking is not available?</span></span>
<span data-ttu-id="7f8f5-186">Возможны ситуации, когда приложение не будет получать данные отслеживания взгляда по различным причинам, включая, помимо прочего, следующие:</span><span class="sxs-lookup"><span data-stu-id="7f8f5-186">There may be situations in which your app will not receive any eye tracking data due to various reasons including but not limited to:</span></span>
* <span data-ttu-id="7f8f5-187">Пользователь пропустил калибровку отслеживания взгляда.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-187">The user skipped the eye tracking calibration.</span></span>
* <span data-ttu-id="7f8f5-188">Пользователь откалиброван, но решил не предоставлять приложению разрешение на использование данных отслеживания взгляда.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-188">The user calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>
* <span data-ttu-id="7f8f5-189">Пользователь имеет уникальные очков или некоторые условия для глаз, которые система пока не поддерживает.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-189">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>
* <span data-ttu-id="7f8f5-190">Внешние факторы отслеживают надежность отслеживания взгляда, например палец на делителе HoloLens или очков, интенсивность прямого солнечного света и окклусионс из-за перекрестных глаз.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-190">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>

<span data-ttu-id="7f8f5-191">Разработчикам приложений это означает, что необходимо учитывать, как поддерживать пользователей, для которых данные отслеживания взгляда могут быть недоступны.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-191">For you as an app developer, this means that you need to account for how to support users for whom eye tracking data may not be available.</span></span> <span data-ttu-id="7f8f5-192">Ниже мы сначала объясним, как определить, доступно ли отслеживание взгляда, и как решить, когда оно недоступно для различных приложений.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-192">Below we first explain how to detect whether eye tracking is available and how to address when it is not available for different applications.</span></span>

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a><span data-ttu-id="7f8f5-193">1. как определить доступность отслеживания взгляда</span><span class="sxs-lookup"><span data-stu-id="7f8f5-193">1. How to detect that eye tracking is available</span></span>
<span data-ttu-id="7f8f5-194">Существует несколько проверок, позволяющих определить, доступны ли данные отслеживания взгляда.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-194">There are a few checks to determine whether eye tracking data is available.</span></span> <span data-ttu-id="7f8f5-195">Проверьте, нет ли...</span><span class="sxs-lookup"><span data-stu-id="7f8f5-195">Check whether...</span></span>
* <span data-ttu-id="7f8f5-196">... система поддерживает отслеживание взгляда.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-196">... the system supports eye tracking at all.</span></span> <span data-ttu-id="7f8f5-197">Вызовите следующий *метод*: [Windows. восприятие. People. эйеспосе. Поддержка ()](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span><span class="sxs-lookup"><span data-stu-id="7f8f5-197">Call the following *method*: [Windows.Perception.People.EyesPose.IsSupported()](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span></span>

* <span data-ttu-id="7f8f5-198">... пользователь откалиброван.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-198">... the user is calibrated.</span></span> <span data-ttu-id="7f8f5-199">Вызовите следующее *свойство*: [Windows. восприятие. People. эйеспосе. искалибратионвалид](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span><span class="sxs-lookup"><span data-stu-id="7f8f5-199">Call the following *property*: [Windows.Perception.People.EyesPose.IsCalibrationValid](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span></span>

* <span data-ttu-id="7f8f5-200">... пользователь предоставил приложению разрешение на использование данных отслеживания взгляда: получение текущего _"газеинпутакцессстатус"_ .</span><span class="sxs-lookup"><span data-stu-id="7f8f5-200">... the user has given your app permission to use their eye tracking data: Retrieve the current _'GazeInputAccessStatus'_.</span></span> <span data-ttu-id="7f8f5-201">Пример того, как это сделать, объясняется в [запросе доступа к вводу с помощью взгляда](https://docs.microsoft.com/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span><span class="sxs-lookup"><span data-stu-id="7f8f5-201">An example on how to do this is explained at [Requesting access to gaze input](https://docs.microsoft.com/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span></span>

<span data-ttu-id="7f8f5-202">Кроме того, может потребоваться проверить, что данные отслеживания взгляда не устарели, добавив время ожидания между полученными обновлениями данных отслеживания взгляда и иным способом откатом к заголовку, как описано ниже.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-202">In addition, you may want to check that your eye tracking data is not stale by adding a timeout between received eye tracking data updates and otherwise fallback to head-gaze as discussed below.</span></span> 

<span data-ttu-id="7f8f5-203">Как описано выше, существует несколько причин, по которым данные отслеживания взгляда могут быть недоступны.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-203">As described above, there are several reasons why eye tracking data may not be available.</span></span> <span data-ttu-id="7f8f5-204">Хотя некоторые пользователи, возможно, решили отменять доступ к данным отслеживания взгляда, и, в некоторых случаях, не предоставить доступ к данным отслеживания взгляда, это может быть непреднамеренно.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-204">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="7f8f5-205">Таким образом, если приложение использует отслеживание взгляда, и это важная часть работы, мы рекомендуем четко взаимодействовать с пользователем.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-205">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span> <span data-ttu-id="7f8f5-206">Пользователь должен знать, почему отслеживание взгляда является критически важным для вашего приложения (возможно, даже перечисление некоторых улучшенных функций), чтобы помочь пользователю лучше понять, что они предоставляют.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-206">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span> <span data-ttu-id="7f8f5-207">Помогите пользователю определить, почему отслеживание взгляда может не работать (на основе описанных выше проверок) и предложить некоторые рекомендации для быстрого устранения потенциальных проблем.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-207">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> <span data-ttu-id="7f8f5-208">Например, если вы обнаружите, что система поддерживает отслеживание взгляда, пользователь откалиброван и даже имеет соответствующее разрешение, но данные отслеживания взгляда не принимаются, это может указывать на некоторые другие проблемы, такие как Растушевка или перекрыто глаза.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-208">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> <span data-ttu-id="7f8f5-209">Обратите внимание, что в редких случаях пользователи, для которых отслеживание взгляда может просто не работать.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-209">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span> <span data-ttu-id="7f8f5-210">Таким образом, будьте Уважайте, чтобы отклонять или даже отключать напоминания о включении отслеживания взгляда в приложении.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-210">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="7f8f5-211">2. откат для приложений, использующих глаз — это первичный указатель ввода</span><span class="sxs-lookup"><span data-stu-id="7f8f5-211">2. Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="7f8f5-212">Если приложение использует указатель мыши в качестве входных указателей, чтобы быстро выбирать голограммы в сцене, но данные отслеживания взгляда недоступны, мы рекомендуем вернуться к Head-взгляду и начать отображение курсора Head-взгляда.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-212">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="7f8f5-213">Мы рекомендуем использовать время ожидания (например, 500 – 1500 мс) для определения необходимости переключения.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-213">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="7f8f5-214">Это позволяет избежать выталкивания курсора при каждой ошибке, когда система может ненадолго потерять отслеживание из-за движения с высокой продолженностью или мультиков и мерцаний.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-214">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="7f8f5-215">Если вы являетесь разработчиком Unity, автоматическое переключение на Heading-взгляд уже обработано в наборе средств Mixed Reality.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-215">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="7f8f5-216">Если вы являетесь разработчиком DirectX, вам нужно самостоятельно справиться с этим параметром.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-216">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="7f8f5-217">3. откат для других приложений, зависящих от отслеживания взгляда</span><span class="sxs-lookup"><span data-stu-id="7f8f5-217">3. Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="7f8f5-218">Ваше приложение может использовать глаза в уникальном виде, специально предназначенном для глаз, например, для анимации глаза аватара или для внимания на глаза, тепловые карты с точной информацией о визуальном внимание.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-218">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="7f8f5-219">В этом случае нет четких резервных.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-219">In this case, there is no clear fallback.</span></span> <span data-ttu-id="7f8f5-220">Если отслеживание взгляда недоступно, эти возможности могут просто быть отключены.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-220">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span>
<span data-ttu-id="7f8f5-221">Опять же, рекомендуется явно сообщить об этом пользователю, который может не знать, что эта возможность не работает.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-221">Again, we recommend to clearly communicate this to the user who may be unaware that the capability is not working.</span></span>

<br>

<span data-ttu-id="7f8f5-222">На этой странице мы надеемся, что вы получите хорошее представление о роли отслеживания взгляда и взгляда на глаза для HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="7f8f5-222">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="7f8f5-223">Чтобы приступить к разработке, ознакомьтесь с нашими сведениями о роли [взгляда с голограммами](eye-gaze-interaction.md), [Взгляните на](https://aka.ms/mrtk-eyes) глаза в Unity и [глаза-взгляд в DirectX](gaze-in-directx.md).</span><span class="sxs-lookup"><span data-stu-id="7f8f5-223">To get started developing, check out our information on the role of [eye-gaze for interacting with holograms](eye-gaze-interaction.md), [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="7f8f5-224">См. также</span><span class="sxs-lookup"><span data-stu-id="7f8f5-224">See also</span></span>
* [<span data-ttu-id="7f8f5-225">Калибровка</span><span class="sxs-lookup"><span data-stu-id="7f8f5-225">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="7f8f5-226">Комфорт</span><span class="sxs-lookup"><span data-stu-id="7f8f5-226">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="7f8f5-227">Взаимодействие на основе взгляда</span><span class="sxs-lookup"><span data-stu-id="7f8f5-227">Eye-gaze-based interaction</span></span>](eye-gaze-interaction.md)
* [<span data-ttu-id="7f8f5-228">Глаза. Взгляните на DirectX</span><span class="sxs-lookup"><span data-stu-id="7f8f5-228">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="7f8f5-229">Взгляд — Взгляните на Unity (набор средств Mixed Reality)</span><span class="sxs-lookup"><span data-stu-id="7f8f5-229">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="7f8f5-230">Взгляните и зафиксируйте</span><span class="sxs-lookup"><span data-stu-id="7f8f5-230">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="7f8f5-231">Голосовой ввод</span><span class="sxs-lookup"><span data-stu-id="7f8f5-231">Voice input</span></span>](voice-design.md)


