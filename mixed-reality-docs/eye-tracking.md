---
title: Взгляд — взгляд
description: HoloLens 2 предоставляет разработчикам возможность использовать информацию о том, что видят пользователи, для нового уровня контекста и человеческого понимания в Holographic.
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: Отслеживание глаз, Смешанная реальность, ввод, глаз-взгляд, взгляд глаз
ms.openlocfilehash: c847f7de2cf4492c89225a88aeaf189f51cfbc40
ms.sourcegitcommit: b0b1b8e1182cce93929d409706cdaa99ff24fdee
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/23/2019
ms.locfileid: "68387595"
---
# <a name="eye-gaze-on-hololens-2"></a><span data-ttu-id="a14a5-104">Глаз — Взгляните на HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="a14a5-104">Eye-gaze on HoloLens 2</span></span>
<span data-ttu-id="a14a5-105">HoloLens 2 предоставляет разработчикам возможность использовать информацию о том, что видят пользователи, для нового уровня контекста и человеческого понимания в Holographic.</span><span class="sxs-lookup"><span data-stu-id="a14a5-105">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="a14a5-106">Эта страница указывает разработчикам, как они могут воспользоваться преимуществами отслеживания взгляда для различных вариантов использования, а также то, что следует искать при проектировании пользовательских интерфейсов на основе взгляда.</span><span class="sxs-lookup"><span data-stu-id="a14a5-106">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interfaces.</span></span> 


## <a name="device-support"></a><span data-ttu-id="a14a5-107">Поддержка устройств</span><span class="sxs-lookup"><span data-stu-id="a14a5-107">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="a14a5-108"><strong>Возможность</strong></span><span class="sxs-lookup"><span data-stu-id="a14a5-108"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="a14a5-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1-го поколения)</strong></a></span><span class="sxs-lookup"><span data-stu-id="a14a5-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="a14a5-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="a14a5-110"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="a14a5-111"><a href="immersive-headset-hardware-details.md"><strong>Иммерсивные гарнитуры</strong></a></span><span class="sxs-lookup"><span data-stu-id="a14a5-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="a14a5-112">Взгляд — взгляд</span><span class="sxs-lookup"><span data-stu-id="a14a5-112">Eye-gaze</span></span></td>
     <td><span data-ttu-id="a14a5-113">❌</span><span class="sxs-lookup"><span data-stu-id="a14a5-113">❌</span></span></td>
     <td><span data-ttu-id="a14a5-114">✔️</span><span class="sxs-lookup"><span data-stu-id="a14a5-114">✔️</span></span></td>
     <td><span data-ttu-id="a14a5-115">❌</span><span class="sxs-lookup"><span data-stu-id="a14a5-115">❌</span></span></td>
</tr>
</table>

## <a name="use-cases"></a><span data-ttu-id="a14a5-116">Варианты использования</span><span class="sxs-lookup"><span data-stu-id="a14a5-116">Use cases</span></span>
<span data-ttu-id="a14a5-117">Функция отслеживание взгляда предоставляет приложениям сведения о том, куда смотрит пользователь в реальном времени.</span><span class="sxs-lookup"><span data-stu-id="a14a5-117">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="a14a5-118">В следующих сценариях использования описаны некоторые взаимодействия, которые можно реализовать с помощью отслеживания взгляда в смешанной реальности.</span><span class="sxs-lookup"><span data-stu-id="a14a5-118">The following use cases describe some interactions that are possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="a14a5-119">Следует помнить, что [набор средств Mixed Reality](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) полезен для предоставления нескольких интересных и удобных примеров использования отслеживания взгляда, таких как быстрый и простой способ выбора целевого объекта, а также автоматическая прокрутка текста на основе вид пользователя.</span><span class="sxs-lookup"><span data-stu-id="a14a5-119">Keep in mind that the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) is useful for providing several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="a14a5-120">Намерения пользователя</span><span class="sxs-lookup"><span data-stu-id="a14a5-120">User intent</span></span>    
<span data-ttu-id="a14a5-121">Сведения о том, где и как выглядит пользователь, предоставляет мощный **контекст для других входных данных**, таких как Voice, руки и контроллеры.</span><span class="sxs-lookup"><span data-stu-id="a14a5-121">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="a14a5-122">Эти данные можно применять в разных задачах.</span><span class="sxs-lookup"><span data-stu-id="a14a5-122">This can be used for various tasks.</span></span>
<span data-ttu-id="a14a5-123">Например, это может варьироваться от быстрого и легко нацеливания на сцену, просто взглянув на голограмму и выполнив команду "Select" (см. также «  [head-взгляд» и «Commit](gaze-and-commit.md)») или «поместить это...», а затем взглянуть на место размещения пользователя голограмма и скажите «... Здесь ".</span><span class="sxs-lookup"><span data-stu-id="a14a5-123">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where the user wants to place the hologram and say "...there".</span></span> <span data-ttu-id="a14a5-124">Подобные примеры доступны в наборах средств для смешанной реальности для [выбора целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) и [позиционирования целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="a14a5-124">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="a14a5-125">Кроме того, пример намерения пользователя может включать в себя сведения о том, что видят пользователи, чтобы улучшить работу с помощью применяющихся виртуальных агентов и интерактивных голограмм.</span><span class="sxs-lookup"><span data-stu-id="a14a5-125">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="a14a5-126">Например, виртуальные агенты могут адаптировать доступные параметры и их поведение на основе текущего просматриваемого содержимого.</span><span class="sxs-lookup"><span data-stu-id="a14a5-126">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="a14a5-127">Неявные действия</span><span class="sxs-lookup"><span data-stu-id="a14a5-127">Implicit actions</span></span>
<span data-ttu-id="a14a5-128">Категория неявных действий тесно связана с намерениями пользователя.</span><span class="sxs-lookup"><span data-stu-id="a14a5-128">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="a14a5-129">Идея состоит в том, что голограммы или элементы пользовательского интерфейса реагируют на инстинктуале, что может даже не показаться, что пользователь взаимодействует с системой вообще, а сам система и пользователь синхронизированы. Одним из примеров является **Автоматическая прокрутка на основе взгляда** , когда пользователь считывает текст, когда текст прокручивается или помещается в синхронизацию с взглядом пользователя.</span><span class="sxs-lookup"><span data-stu-id="a14a5-129">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user reads text as the text continues to scroll or flow in sync with with the user's gaze.</span></span> <span data-ttu-id="a14a5-130">Ключевым аспектом этого процесса является то, что скорость прокрутки адаптируется к скорости чтения пользователя.</span><span class="sxs-lookup"><span data-stu-id="a14a5-130">A key aspect of this is that scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="a14a5-131">В качестве другого примера можно возместить **масштаб и панораму** , в котором пользователь может точно оценить порядок, в котором он или она ориентированы на o.</span><span class="sxs-lookup"><span data-stu-id="a14a5-131">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused o.</span></span> <span data-ttu-id="a14a5-132">Для управления скоростью масштабирования и управления ею можно управлять с помощью голоса или ввода-вывода, что важно для предоставления пользователю прав на управление и предотвращения переполнения.</span><span class="sxs-lookup"><span data-stu-id="a14a5-132">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="a14a5-133">Мы рассмотрим эти рекомендации по проектированию более подробно.</span><span class="sxs-lookup"><span data-stu-id="a14a5-133">We will talk about these design guidelines in more detail below.</span></span> <span data-ttu-id="a14a5-134">После масштабирования пользователь может плавно проследить за тем, что, например, разообразить свое окружение, просто воспользовавшись знаком взгляда.</span><span class="sxs-lookup"><span data-stu-id="a14a5-134">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="a14a5-135">Эти типы взаимодействия демонстрируются в примере набора средств для смешанной реальности для [навигации с поддержкой взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="a14a5-135">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="a14a5-136">Дополнительные варианты использования неявных _действий_ могут включать:</span><span class="sxs-lookup"><span data-stu-id="a14a5-136">Additional use cases for _implicit actions_ can include:</span></span>
- <span data-ttu-id="a14a5-137">**Интеллектуальные уведомления**. Вас раздражают уведомления, которые всплывают ровно в том месте, на которое вы смотрите?</span><span class="sxs-lookup"><span data-stu-id="a14a5-137">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="a14a5-138">Принимая во внимание то, к какому пользователю относится пользователь, вы можете сделать этот процесс более эффективным, потратив уведомления от того, где пользователь в настоящее время облаками.</span><span class="sxs-lookup"><span data-stu-id="a14a5-138">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="a14a5-139">Это ограничивает число обращений и автоматически закрывает их после того, как пользователь закончит чтение.</span><span class="sxs-lookup"><span data-stu-id="a14a5-139">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="a14a5-140">**"Вежливые" голограммы**. Голограммы, которые слегка реагируют на газед.</span><span class="sxs-lookup"><span data-stu-id="a14a5-140">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="a14a5-141">Это может варьироваться от слегка свечения элементов пользовательского интерфейса до медленного цветутного цветок до виртуального животного, начинающегося с пользователя, или пытаясь избежать глаза пользователя после длительной звездочки.</span><span class="sxs-lookup"><span data-stu-id="a14a5-141">This can range from slightly glowing UI elements to a slowly blooming flower to a virtual pet starting to look back at the user or trying to avoid the user's eye-gaze after a prolonged stare.</span></span> <span data-ttu-id="a14a5-142">Это взаимодействие может предоставить интересное представление о подключении и удовлетворенности приложения.</span><span class="sxs-lookup"><span data-stu-id="a14a5-142">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="a14a5-143">Отслеживание внимания</span><span class="sxs-lookup"><span data-stu-id="a14a5-143">Attention tracking</span></span>   
<span data-ttu-id="a14a5-144">Сведения о том, где или как видят пользователи, — это чрезвычайно мощный инструмент для оценки удобства использования дизайнов и выявления проблем в эффективных рабочих процессах.</span><span class="sxs-lookup"><span data-stu-id="a14a5-144">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="a14a5-145">Визуализация и аналитика отслеживания взгляда являются распространенной практикой в различных областях приложений.</span><span class="sxs-lookup"><span data-stu-id="a14a5-145">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="a14a5-146">С помощью HoloLens 2 мы предоставляем новое измерение для понимания того, как трехмерные голограммы могут быть помещены в реальные контексты и оцениваться соответствующим образом.</span><span class="sxs-lookup"><span data-stu-id="a14a5-146">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="a14a5-147">[Набор средств Mixed Reality](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) предоставляет основные примеры ведения журнала и загрузки данных отслеживания взгляда, а также способы их визуализации.</span><span class="sxs-lookup"><span data-stu-id="a14a5-147">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and  how to visualize them.</span></span>

<span data-ttu-id="a14a5-148">Другие приложения в этой области могут включать:</span><span class="sxs-lookup"><span data-stu-id="a14a5-148">Other applications in this area can include:</span></span> 
-   <span data-ttu-id="a14a5-149">**Удаленный взгляд — визуализация взгляда:** Визуализируйте, что просматривает удаленные участники совместной работы, чтобы убедиться, что инструкции правильно понятны и следуют.</span><span class="sxs-lookup"><span data-stu-id="a14a5-149">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="a14a5-150">**Исследование пользователей.** Отслеживание внимания можно использовать для изучения того, как новички и пользователи с экспертами визуально анализируют содержимое или способ координации сложных задач, например для анализа медицинских данных или при работе с операционным механизмом.</span><span class="sxs-lookup"><span data-stu-id="a14a5-150">**User research studies:** Attention tracking can be used to explore the way novice vs. expert users visually analyze content or how their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="a14a5-151">**Обучающее моделирование и мониторинг производительности.** Тренировка и оптимизация выполнения задач, которые позволят более эффективно выявлять узкие места в потоке выполнения.</span><span class="sxs-lookup"><span data-stu-id="a14a5-151">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="a14a5-152">**Оценка проекта, реклама и маркетинговые исследования.** Отслеживание взгляда — это распространенный инструмент для исследования рынка при оценке моделей веб-сайтов и продуктов.</span><span class="sxs-lookup"><span data-stu-id="a14a5-152">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research when evaluateing website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="a14a5-153">Другие варианты использования</span><span class="sxs-lookup"><span data-stu-id="a14a5-153">Additional use cases</span></span>
- <span data-ttu-id="a14a5-154">**Игры.** Вам нужны суперспособности?</span><span class="sxs-lookup"><span data-stu-id="a14a5-154">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="a14a5-155">Вам сюда!</span><span class="sxs-lookup"><span data-stu-id="a14a5-155">Here's your chance!</span></span> <span data-ttu-id="a14a5-156">Вы можете левитате голограммы на них.</span><span class="sxs-lookup"><span data-stu-id="a14a5-156">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="a14a5-157">Стреляйте лазерными лучами из глаз.</span><span class="sxs-lookup"><span data-stu-id="a14a5-157">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="a14a5-158">Превратите противников в камень или закрепите их.</span><span class="sxs-lookup"><span data-stu-id="a14a5-158">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="a14a5-159">Примените рентгеновское зрение, чтобы исследовать здания.</span><span class="sxs-lookup"><span data-stu-id="a14a5-159">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="a14a5-160">Вы ограничены только пределами своего воображения!</span><span class="sxs-lookup"><span data-stu-id="a14a5-160">Your imagination is the limit!</span></span>  

- <span data-ttu-id="a14a5-161">**Выразительные аватары.** Отслеживание взгляда позволяет использовать более выразительные трехмерные аватары с помощью даты отслеживания в реальном времени для анимации глаз аватара, указывающих на то, что видят пользователи.</span><span class="sxs-lookup"><span data-stu-id="a14a5-161">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live-eye tracking date to animate the avatar's eyes that indicate what the user is looking at.</span></span> <span data-ttu-id="a14a5-162">Вы можете усилить выразительность, добавив моргания и подмигивания.</span><span class="sxs-lookup"><span data-stu-id="a14a5-162">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="a14a5-163">**Ввод текста.** Отслеживание взгляда можно использовать в качестве альтернативы для ввода текста с низкой наработкой, особенно если речь или руки неудобны для использования.</span><span class="sxs-lookup"><span data-stu-id="a14a5-163">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="a14a5-164">API отслеживания взгляда</span><span class="sxs-lookup"><span data-stu-id="a14a5-164">Eye tracking API</span></span>
<span data-ttu-id="a14a5-165">Прежде чем приступить к подробному рассмотрению конкретных руководств по проектированию для взаимодействия с взглядом, мы хотим вкратце описать возможности API-интерфейса, отслеживающего отслеживание взглядов HoloLens 2, для разработчиков.</span><span class="sxs-lookup"><span data-stu-id="a14a5-165">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point out the capabilities that the HoloLens 2 Eye Tracker API provides to developers.</span></span> <span data-ttu-id="a14a5-166">Он предоставляет один источник и направление взгляда на глаза — предоставление данных приблизительно в _30 кадров/_ с.</span><span class="sxs-lookup"><span data-stu-id="a14a5-166">It provides a single eye-gaze--gaze origin and direction--providing data at approximately _30 FPS_.</span></span> 

<span data-ttu-id="a14a5-167">Прогнозируемый взгляд — взгляд находится в центре сертификации.</span><span class="sxs-lookup"><span data-stu-id="a14a5-167">The predicted eye-gaze lies within ca.</span></span> <span data-ttu-id="a14a5-168">1,0-1,5 градусов в визуальном уголе вокруг фактического целевого объекта.</span><span class="sxs-lookup"><span data-stu-id="a14a5-168">1.0 - 1.5 degrees in visual angle around the actual target.</span></span> <span data-ttu-id="a14a5-169">Следует ожидать и учитывать небольшую неточность, добавляя запас для нижней границы.</span><span class="sxs-lookup"><span data-stu-id="a14a5-169">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="a14a5-170">Подробнее мы рассмотрим это ниже.</span><span class="sxs-lookup"><span data-stu-id="a14a5-170">We will discuss this more below.</span></span> <span data-ttu-id="a14a5-171">Чтобы отслеживание взгляда работало точно, каждому пользователю нужно пройти калибровку отслеживания взгляда.</span><span class="sxs-lookup"><span data-stu-id="a14a5-171">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="a14a5-172">![Оптимальный размер целевого объекта на расстоянии 2 метра](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="a14a5-172">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="a14a5-173">*Оптимальный размер целевого объекта на расстоянии в 2 метра*</span><span class="sxs-lookup"><span data-stu-id="a14a5-173">*Optimal target size at a 2-meter distance*</span></span>
<br>
<br>
<span data-ttu-id="a14a5-174">[API отслеживания взгляда](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) доступен через: "Windows. восприятие. People. эйеспосе".</span><span class="sxs-lookup"><span data-stu-id="a14a5-174">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: \`Windows.Perception.People.EyesPose'.</span></span> 

## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="a14a5-175">Рекомендации по проектированию взгляда</span><span class="sxs-lookup"><span data-stu-id="a14a5-175">Eye-gaze design guidelines</span></span>
<span data-ttu-id="a14a5-176">Создание взаимодействий, в которых используется нацеливание на основе быстрого перемещения глаз, может оказаться сложной задачей.</span><span class="sxs-lookup"><span data-stu-id="a14a5-176">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="a14a5-177">В этом разделе мы обобщены основные преимущества и проблемы, которые необходимо учитывать при проектировании приложения.</span><span class="sxs-lookup"><span data-stu-id="a14a5-177">In this section, we summarize the key advantages and challenges to take into account when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="a14a5-178">Преимущества входных данных взгляда</span><span class="sxs-lookup"><span data-stu-id="a14a5-178">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="a14a5-179">**Высокая скорость нацеливания**.</span><span class="sxs-lookup"><span data-stu-id="a14a5-179">**High speed pointing.**</span></span> <span data-ttu-id="a14a5-180">Мускулы глаз — самые быстрые во всем теле человека.</span><span class="sxs-lookup"><span data-stu-id="a14a5-180">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="a14a5-181">**Низкий уровень усилий**.</span><span class="sxs-lookup"><span data-stu-id="a14a5-181">**Low effort.**</span></span> <span data-ttu-id="a14a5-182">Физическое перемещение почти не требуется.</span><span class="sxs-lookup"><span data-stu-id="a14a5-182">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="a14a5-183">**Ненавязчивость**.</span><span class="sxs-lookup"><span data-stu-id="a14a5-183">**Implicitness.**</span></span> <span data-ttu-id="a14a5-184">Сведения о перемещении глаз, часто описываемые пользователями, позволяют системе узнать, какую цель планирует пользователь придерживаться.</span><span class="sxs-lookup"><span data-stu-id="a14a5-184">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="a14a5-185">**Альтернативный канал ввода.**</span><span class="sxs-lookup"><span data-stu-id="a14a5-185">**Alternative input channel.**</span></span> <span data-ttu-id="a14a5-186">Взгляд на глаза — это мощный вспомогательный ввод, позволяющий создавать руки и речевые входные данные в течение многих лет работы пользователей, основанных на координации глаз.</span><span class="sxs-lookup"><span data-stu-id="a14a5-186">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="a14a5-187">**Визуальное внимание.**</span><span class="sxs-lookup"><span data-stu-id="a14a5-187">**Visual attention.**</span></span> <span data-ttu-id="a14a5-188">Еще одним важным преимуществом является возможность определить, к чему пользователь оплачивает внимание.</span><span class="sxs-lookup"><span data-stu-id="a14a5-188">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="a14a5-189">Это может помочь в различных областях приложений, от более эффективного оценки различных проектов до упрощения работы с более интеллектуальными пользовательскими интерфейсами и расширенными социальными подсказками для удаленного взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="a14a5-189">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="a14a5-190">В двух словах, использование глаз-взгляда в качестве входных данных обеспечивает быстрый и простой контекстный сигнал.</span><span class="sxs-lookup"><span data-stu-id="a14a5-190">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual signal.</span></span> <span data-ttu-id="a14a5-191">Это особенно удобно в сочетании с другими входными данными,  например с голосовыми и *ручными* вводами, для подтверждения намерений пользователя.</span><span class="sxs-lookup"><span data-stu-id="a14a5-191">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="a14a5-192">Проблемы с глазом. Взгляните на входные данные</span><span class="sxs-lookup"><span data-stu-id="a14a5-192">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="a14a5-193">Благодаря большому энергопотреблению приходится отвечать за множество обязанностей.</span><span class="sxs-lookup"><span data-stu-id="a14a5-193">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="a14a5-194">Хотя с помощью взгляда можно использовать для создания соответствия пользовательским интерфейсам, что делает вас похожим на супергерой, важно иметь представление о том, что он не подходит для соответствующей учетной записи.</span><span class="sxs-lookup"><span data-stu-id="a14a5-194">While eye-gaze can be used to create satisfying user experiences thata makes you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="a14a5-195">Ниже обсуждаются некоторые *проблемы* , которые необходимо учитывать при работе с входными данными взгляда на глаза.</span><span class="sxs-lookup"><span data-stu-id="a14a5-195">The following discusses some *challenges* to take into account as well as how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="a14a5-196">**Взгляд на глаза — "Always On"** Когда вы откроете Лидс глаз, ваши глаза начнут фиксатинг на вещи в среде.</span><span class="sxs-lookup"><span data-stu-id="a14a5-196">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="a14a5-197">При каждом взгляде вы выполняете и случайно выдаете действия, так как вы просматриваете что-то слишком длинное, что привело бы к неудовлетворенности.</span><span class="sxs-lookup"><span data-stu-id="a14a5-197">Reacting to every look you make and accidentally issuing actions because you looked at something for too long would result in an unsatisfying experience.</span></span>
<span data-ttu-id="a14a5-198">Именно поэтому мы рекомендуем объединять глаза с помощью *команды Voice*, жеста *руки*, нажатия *кнопки* или расширенного вдаваясь, чтобы активировать выбор цели.</span><span class="sxs-lookup"><span data-stu-id="a14a5-198">This is why we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="a14a5-199">Это решение также обеспечивает режим, в котором пользователь может просмотреться без лишних пошагового запуска чего-либо.</span><span class="sxs-lookup"><span data-stu-id="a14a5-199">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="a14a5-200">Эту проблему важно принимать во внимание при проектировании визуального и звукового отклика целевого объекта на взгляд.</span><span class="sxs-lookup"><span data-stu-id="a14a5-200">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="a14a5-201">Не перегружайте каналы взаимодействия с пользователем навязчивыми звуками всплывающих элементов или фокусировки.</span><span class="sxs-lookup"><span data-stu-id="a14a5-201">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="a14a5-202">Тонкость — это ключ.</span><span class="sxs-lookup"><span data-stu-id="a14a5-202">Subtlety is key.</span></span> <span data-ttu-id="a14a5-203">Некоторые рекомендации по этому аспекту мы рассмотрим ниже, когда речь пойдет о проектировании.</span><span class="sxs-lookup"><span data-stu-id="a14a5-203">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="a14a5-204">**Наблюдение и управление** Представьте себе, что вы хотите точно выгадать фотографию на стене.</span><span class="sxs-lookup"><span data-stu-id="a14a5-204">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="a14a5-205">Вы внимательно смотрите на рамку и окружающие объекты, чтобы оценить горизонтальность линий.</span><span class="sxs-lookup"><span data-stu-id="a14a5-205">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="a14a5-206">Теперь представьте себе, как это сделать, если вы хотите использовать глаз в качестве входных данных для перемещения изображения.</span><span class="sxs-lookup"><span data-stu-id="a14a5-206">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="a14a5-207">Сложно, правда?</span><span class="sxs-lookup"><span data-stu-id="a14a5-207">Difficult, isn't it?</span></span> <span data-ttu-id="a14a5-208">В этом описана двойная роль глаза — Взгляните, когда требуется как для ввода, так и для управления.</span><span class="sxs-lookup"><span data-stu-id="a14a5-208">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="a14a5-209">**Изменение фокуса перед щелчком**. Для быстрого выбора целевых объектов исследование показало, что перед завершением ручного щелчка (например, аиртап) можно перейти на глаза.</span><span class="sxs-lookup"><span data-stu-id="a14a5-209">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="a14a5-210">Следовательно, особое внимание должно быть оплачено для синхронизации сигнала с быстрым глазом взгляда с медленным входом (например, с помощью голоса, руки, контроллера).</span><span class="sxs-lookup"><span data-stu-id="a14a5-210">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="a14a5-211">**Маленькие целевые объекты**. Вы знаете, что происходит при попытке чтения текста, который слишком мал, чтобы быть удобным для чтения?</span><span class="sxs-lookup"><span data-stu-id="a14a5-211">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortable?</span></span> <span data-ttu-id="a14a5-212">Это может привести к тому, что вы захотите и надеты, так как вы попытаетесь перенастроить глаза, чтобы лучше сосредоточиться на них.</span><span class="sxs-lookup"><span data-stu-id="a14a5-212">This straining feeling on your eyes can cause you to feel tired and worn out because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="a14a5-213">Это незначительное время, которое может быть вызвано пользователями при принудительном выборе целевых объектов, которые слишком малы в приложении, с помощью нацеленности на глаз.</span><span class="sxs-lookup"><span data-stu-id="a14a5-213">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="a14a5-214">Чтобы поддерживать приятное и уверенное взаимодействие с пользователем, мы рекомендуем учесть при разработке, что минимальный размер целевых объектов должен быть не менее 2°, а желательно еще больше.</span><span class="sxs-lookup"><span data-stu-id="a14a5-214">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="a14a5-215">**Неоднородный взгляд — перемещения Взгляните** Наши глаза выполняют быстрые перемещения от с фиксацией к с фиксацией.</span><span class="sxs-lookup"><span data-stu-id="a14a5-215">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="a14a5-216">Изучая записанный путь перемещения глаз, вы быстро заметите его неравномерность.</span><span class="sxs-lookup"><span data-stu-id="a14a5-216">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="a14a5-217">Глаза движутся очень быстро и импульсивно по сравнению с *направлением головы* и *движениями рук*.</span><span class="sxs-lookup"><span data-stu-id="a14a5-217">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="a14a5-218">**Надежность отслеживания**. Точность отслеживания взгляда может немного ухудшаться при изменении освещенности, пока глаза привыкают к новым условиям.</span><span class="sxs-lookup"><span data-stu-id="a14a5-218">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="a14a5-219">Хотя это не должно повлиять на структуру приложения, так как точность должна быть в пределах 2 °, для пользователя может потребоваться другая калибровка.</span><span class="sxs-lookup"><span data-stu-id="a14a5-219">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, i might be necessary for the user to run another calibration.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="a14a5-220">Рекомендации по проектированию</span><span class="sxs-lookup"><span data-stu-id="a14a5-220">Design recommendations</span></span>
<span data-ttu-id="a14a5-221">Ниже приведен список конкретных рекомендаций по проектированию, основанных на указанных преимуществах и проблемах для ввода взгляда на глаза:</span><span class="sxs-lookup"><span data-stu-id="a14a5-221">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="a14a5-222">**Глаз — взгляд! = Head — взгляд:**</span><span class="sxs-lookup"><span data-stu-id="a14a5-222">**Eye-gaze != Head-gaze:**</span></span>
    - <span data-ttu-id="a14a5-223">**Обдумайте, подходит ли быстрое и неровное перемещение глаз для вашей задачи ввода данных.** Несмотря на то, что наши быстрые и неровные перемещения глаз отлично подходят для быстрого выбора целевых объектов в нашем поле View (фов), оно будет менее применимо для задач, требующих сглаживания входных траекторий (например, для рисования или енЦирклинг заметок).</span><span class="sxs-lookup"><span data-stu-id="a14a5-223">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view (FoV), it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="a14a5-224">Для таких задач лучше использовать движения рук или головы.</span><span class="sxs-lookup"><span data-stu-id="a14a5-224">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="a14a5-225">**Старайтесь не прикреплять что-либо непосредственно к глазу пользователя (например, к ползунку или курсору).**</span><span class="sxs-lookup"><span data-stu-id="a14a5-225">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="a14a5-226">В случае с курсором это может привести к эффекту "флиинг Cursor" из-за небольших смещений в прогнозируемом сигнале взгляда.</span><span class="sxs-lookup"><span data-stu-id="a14a5-226">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="a14a5-227">В случае с ползунком он может конфликтовать с двойной ролью управления ползунком с глазами, а также проверить, находится ли объект в нужном месте.</span><span class="sxs-lookup"><span data-stu-id="a14a5-227">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="a14a5-228">В двух словах, пользователи могут стать перегруженными и нечеткими, особенно если сигнал неточен для этого пользователя.</span><span class="sxs-lookup"><span data-stu-id="a14a5-228">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="a14a5-229">**Объединение глаз-взгляда с другими входными данными:** Интеграция отслеживания взгляда с другими входными данными, такими как жесты, речевые команды или нажатие кнопки, обеспечивает ряд преимуществ.</span><span class="sxs-lookup"><span data-stu-id="a14a5-229">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="a14a5-230">**Свободное наблюдение.** Учитывая, что основная роль наших глаз заключается в том, чтобы наблюдать за нашей средой, важно, чтобы пользователи могли выполнять поиск без запуска отзывов или действий (визуальных, аудитов и т. д.).</span><span class="sxs-lookup"><span data-stu-id="a14a5-230">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="a14a5-231">Объединение отслеживания взгляда с другим элементом управления вводом позволяет плавно переходить между наблюдения за отслеживанием взгляда и режимами управления вводом.</span><span class="sxs-lookup"><span data-stu-id="a14a5-231">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="a14a5-232">**Мощный источник информации о контексте**. С помощью сведений о месте и том, что видят пользователи, в то время как уттеринг голосовое действие или выполнение жеста руки позволяет легко передавать входные данные по полю представления.</span><span class="sxs-lookup"><span data-stu-id="a14a5-232">**Powerful context provider:** Using information about where and what the user is looking at while uttering a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="a14a5-233">Пример: Команда Put that there позволяет быстро и без усилий выбрать голограмму и поместить ее в другую область сцены, просто просмотрев на объект и место назначения.</span><span class="sxs-lookup"><span data-stu-id="a14a5-233">For example: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="a14a5-234">**Потребность в синхронизации между несколькими источниками входных данных (проблема изменения фокуса перед щелчком).** Сочетание быстрых движений с более сложными дополнительными входами, например длинными голосовыми командами или жестами руки, несет ответственность за продолжение глаза перед завершением дополнительной команды ввода.</span><span class="sxs-lookup"><span data-stu-id="a14a5-234">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk of continuing your eye-gaze before finishing the additional input command.</span></span> <span data-ttu-id="a14a5-235">А значит, при создании собственных элементов управления (например, настраиваемых жестов руками) обязательно фиксируйте момент начала или ожидаемую длительность такого действия, чтобы сопоставлять эти данные с направлением взгляда пользователя в прошлом.</span><span class="sxs-lookup"><span data-stu-id="a14a5-235">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="a14a5-236">**Ненавязчивый отклик на действия, полученные с помощью отслеживания взгляда**. При просмотре целевого объекта полезно оставить отзыв, чтобы указать, что система работает как намеченная, но должна быть незаметной.</span><span class="sxs-lookup"><span data-stu-id="a14a5-236">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended, but should be kept subtle.</span></span> <span data-ttu-id="a14a5-237">Это может включать в себя медленное смешивание, включение и отображение визуальных элементов или выполнение других тонких целевых объектов, например медленное движение, например небольшое увеличение целевого объекта, чтобы указать, что система правильно определила, что пользователь просматривает целевой объект без Необязательное прерывание текущего рабочего процесса пользователя.</span><span class="sxs-lookup"><span data-stu-id="a14a5-237">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="a14a5-238">**Старайтесь не использовать нетипичные перемещения глаз для ввода данных.** Не вынуждайте пользователей выполнять определенные движения глаз (жесты вздействия) для запуска действий в приложении.</span><span class="sxs-lookup"><span data-stu-id="a14a5-238">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="a14a5-239">**Оставьте запас на неточность.** Мы расразличимы два типа неточностей, которые заметны для пользователей: смещение и нарушение.</span><span class="sxs-lookup"><span data-stu-id="a14a5-239">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="a14a5-240">Самый простой способ устранить это смещение — предоставить достаточно большие целевые объекты для взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="a14a5-240">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="a14a5-241">Рекомендуется использовать визуальный угол больше 2 ° в качестве ссылки.</span><span class="sxs-lookup"><span data-stu-id="a14a5-241">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="a14a5-242">Например, размер эскиза составляет примерно 2 ° в визуальном элементе при растяжении ARM.</span><span class="sxs-lookup"><span data-stu-id="a14a5-242">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="a14a5-243">На этом основана следующая рекомендация.</span><span class="sxs-lookup"><span data-stu-id="a14a5-243">This leads to the following guidance:</span></span>
    - <span data-ttu-id="a14a5-244">Не вынуждайте пользователей выбирать крошечные целевые объекты.</span><span class="sxs-lookup"><span data-stu-id="a14a5-244">Do not force users to select tiny targets.</span></span> <span data-ttu-id="a14a5-245">Исследование показало, что если целевые объекты достаточно велики и система спроектирована правильно, пользователи описывают взаимодействие как простые и Magical.</span><span class="sxs-lookup"><span data-stu-id="a14a5-245">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="a14a5-246">Если же целевые объекты становятся слишком маленькими, взаимодействие вызывает у пользователей усталость и раздражение.</span><span class="sxs-lookup"><span data-stu-id="a14a5-246">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="a14a5-247">См. также</span><span class="sxs-lookup"><span data-stu-id="a14a5-247">See also</span></span>
* [<span data-ttu-id="a14a5-248">Направление головы и фиксация</span><span class="sxs-lookup"><span data-stu-id="a14a5-248">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="a14a5-249">Руководитель и глаза — Взгляните на DirectX</span><span class="sxs-lookup"><span data-stu-id="a14a5-249">Head and eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="a14a5-250">Взгляд — Взгляните на Unity (набор средств Mixed Reality)</span><span class="sxs-lookup"><span data-stu-id="a14a5-250">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="a14a5-251">Жесты руками</span><span class="sxs-lookup"><span data-stu-id="a14a5-251">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="a14a5-252">Голосовой ввод</span><span class="sxs-lookup"><span data-stu-id="a14a5-252">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="a14a5-253">Контроллеры движения</span><span class="sxs-lookup"><span data-stu-id="a14a5-253">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="a14a5-254">Комфорт</span><span class="sxs-lookup"><span data-stu-id="a14a5-254">Comfort</span></span>](comfort.md)
