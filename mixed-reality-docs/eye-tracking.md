---
title: Отслеживание взгляда
description: Отслеживание взгляда
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Eye Tracking, Mixed Reality, Input, Eye Gaze
ms.openlocfilehash: 7298a34a946f86aaf789cfe44ad971169fc8ece3
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/05/2019
ms.locfileid: "66453700"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="bb8e1-104">Отслеживание взгляда в HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="bb8e1-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="bb8e1-105">HoloLens 2 позволяет организовать голографическое взаимодействие на совершенно новом уровне понимания контекста и намерений человека, предоставляя разработчикам невероятные возможности для использования информации о том, куда смотрят пользователи.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-105">HoloLens 2 allows for a whole new level of context and human understanding within the holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="bb8e1-106">На этой странице собраны общие сведения о том, как разработчики могут использовать отслеживание взгляда в разных сценариях и на что нужно обратить внимание при проектировании пользовательских интерфейсов с отслеживанием направления взгляда.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="bb8e1-107">Варианты использования</span><span class="sxs-lookup"><span data-stu-id="bb8e1-107">Use cases</span></span>
<span data-ttu-id="bb8e1-108">Функция отслеживание взгляда предоставляет приложениям сведения о том, куда смотрит пользователь в реальном времени.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="bb8e1-109">В этом разделе описываются возможные варианты использования и новые способы взаимодействия, которые становятся возможными в смешанной реальности благодаря функции отслеживания взгляда.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="bb8e1-110">Перед началом работы мы немного расскажем о [наборе средств для смешанной реальности](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html), который предоставляет несколько интересных примеров использования технологии отслеживания взгляда. Например, с помощью функции отслеживания взгляда можно быстро и легко выбирать целевые объекты или автоматически прокручивать текст.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="bb8e1-111">Намерения пользователя</span><span class="sxs-lookup"><span data-stu-id="bb8e1-111">User intent</span></span>    
<span data-ttu-id="bb8e1-112">Сведения о том, куда смотрит пользователь, предоставляют важный **контекст для других поступающих от человека данных**, включая голос, жесты рук и движения контроллеров.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="bb8e1-113">Эти данные можно применять в разных задачах.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-113">This can be used for various tasks.</span></span>
<span data-ttu-id="bb8e1-114">Например, можно быстро и легко выполнять **нацеливание** в виртуальной сцене, просто просмотрев на голограмму и произнеся команду select (см. руководство по [ направлению взгляда и фиксации](gaze-and-commit.md)). Также можно произнести команду put this, а затем посмотреть на место для размещения голограммы и произнести команду there.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="bb8e1-115">Подобные примеры доступны в наборах средств для смешанной реальности для [выбора целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) и [позиционирования целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="bb8e1-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="bb8e1-116">Еще один пример использования намерений пользователя — это применение информации о том, на что смотрит пользователь, для улучшения взаимодействия с визуализированными виртуальными агентами и интерактивными голограммами.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="bb8e1-117">Например, виртуальные агенты могут изменять доступные варианты действий и свое поведение с учетом того, какое содержимое сейчас просматривается.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="bb8e1-118">Неявные действия</span><span class="sxs-lookup"><span data-stu-id="bb8e1-118">Implicit actions</span></span>
<span data-ttu-id="bb8e1-119">Категория неявных действий тесно связана с намерениями пользователя.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="bb8e1-120">Идея заключается в том, что голограммы и элементы пользовательского интерфейса по умолчанию реагируют так, что взаимодействие не замечается вообще. Создается впечатление, что система просто действует синхронно с пользователем. Невероятно эффективным примером такого взаимодействия является **автопрокрутка на основе направления взгляда**.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="bb8e1-121">Идея очень проста. Пользователь читает текст, не совершая дополнительных действий.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="bb8e1-122">Текст плавно перемещается вверх на той скорости, с которой пользователь его читает.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="bb8e1-123">Ключевым аспектом здесь является то, что скорость прокрутки адаптируется к скорости чтения пользователя.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="bb8e1-124">Еще один пример — **масштабирование и панорамирование с поддержкой направления взгляда**. В этом режиме пользователь будто приближает объект, на котором он фокусируется.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="bb8e1-125">Активация масштабирования и управление скоростью координируется голосом или жестами рук. Это очень важно, так как пользователь не должен терять чувство контроля над происходящим (рекомендации по проектированию мы подробнее рассмотрим ниже).</span><span class="sxs-lookup"><span data-stu-id="bb8e1-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="bb8e1-126">После увеличения масштаба пользователь может, например, проследовать по улице, чтобы изучить расположенные на ней объекты, просто переводя на них взгляд.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="bb8e1-127">Эти типы взаимодействия демонстрируются в примере набора средств для смешанной реальности для [навигации с поддержкой взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="bb8e1-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="bb8e1-128">В качестве дополнительных примеров _неявных действий_ можно назвать следующее:</span><span class="sxs-lookup"><span data-stu-id="bb8e1-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="bb8e1-129">**Интеллектуальные уведомления**. Вас раздражают уведомления, которые всплывают ровно в том месте, на которое вы смотрите?</span><span class="sxs-lookup"><span data-stu-id="bb8e1-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="bb8e1-130">Но если вы будете учитывать то, куда смотрит пользователь в текущий момент, вы сможете улучшить это поведение!</span><span class="sxs-lookup"><span data-stu-id="bb8e1-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="bb8e1-131">Отображайте уведомления на некотором расстоянии от области, которую рассматривает пользователь, чтобы меньше отвлекать его, а затем автоматически закройте прочитанное уведомление.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="bb8e1-132">**"Вежливые" голограммы**. Голограммы могут немного изменять поведение при взгляде на них.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="bb8e1-133">Например, можно слегка подсвечивать элементы пользовательского интерфейса, медленно распускать цветок или даже создать виртуальную зверушку, которая смотрит вам в глаза или избегает длительного контакта глаз.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="bb8e1-134">Это создаст в приложении интересную атмосферу связи и удовлетворения.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="bb8e1-135">Отслеживание внимания</span><span class="sxs-lookup"><span data-stu-id="bb8e1-135">Attention tracking</span></span>   
<span data-ttu-id="bb8e1-136">Сведения о том, куда смотрит пользователь — это очень мощное средство для оценки удобства работы и выявления проблем в эффективных рабочих потоках.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="bb8e1-137">Отслеживание направления взгляда уже стало стандартным инструментом для визуализации и аналитики в самых разных приложениях.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="bb8e1-138">HoloLens 2 расширяет эти возможности, ведь теперь трехмерные голограммы можно размещать в реальном контексте и оценивать с учетом этого контекста.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="bb8e1-139">[Набор средств для смешанной реальности](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) предоставляет простые примеры регистрации, загрузки и визуализации данных об отслеживании взгляда.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="bb8e1-140">Другие приложения из этой сферы поддерживают следующие функции:</span><span class="sxs-lookup"><span data-stu-id="bb8e1-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="bb8e1-141">**Визуализация направления удаленного взгляда.** Визуализация объектов, на которые смотрят участники сеанса совместной дистанционной работы, для контроля правильности понимания и соблюдения инструкций.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="bb8e1-142">**Исследование пользователей.** Отслеживание внимания позволяет сравнить, как новички и профессионалы изучают содержимое или координируют движения глаз и рук при решении сложных задач (например, при анализе медицинских данных или управлении аппаратурой).</span><span class="sxs-lookup"><span data-stu-id="bb8e1-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="bb8e1-143">**Обучающее моделирование и мониторинг производительности.** Тренировка и оптимизация выполнения задач, которые позволят более эффективно выявлять узкие места в потоке выполнения.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="bb8e1-144">**Оценка проекта, реклама и маркетинговые исследования.** Отслеживание взгляда широко используется в маркетинговых исследованиях для оценки дизайна сайтов и продуктов.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="bb8e1-145">Другие варианты использования</span><span class="sxs-lookup"><span data-stu-id="bb8e1-145">Additional use cases</span></span>
- <span data-ttu-id="bb8e1-146">**Игры.** Вам нужны суперспособности?</span><span class="sxs-lookup"><span data-stu-id="bb8e1-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="bb8e1-147">Вам сюда!</span><span class="sxs-lookup"><span data-stu-id="bb8e1-147">Here's your chance!</span></span> <span data-ttu-id="bb8e1-148">Заставьте взглядом голограмму летать.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="bb8e1-149">Стреляйте лазерными лучами из глаз.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="bb8e1-150">Превратите противников в камни или заморозьте их!</span><span class="sxs-lookup"><span data-stu-id="bb8e1-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="bb8e1-151">Примените рентгеновское зрение, чтобы исследовать здания.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="bb8e1-152">Вы ограничены только пределами своего воображения!</span><span class="sxs-lookup"><span data-stu-id="bb8e1-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="bb8e1-153">**Выразительные аватары.** Отслеживание взгляда помогает создавать более выразительные трехмерные аватары, анимируя глаза аватара с учетом того, на что в текущий момент смотрит пользователь.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="bb8e1-154">Вы можете усилить выразительность, добавив моргания и подмигивания.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="bb8e1-155">**Ввод текста.** Отслеживание взгляда может стать интересной альтернативой для ввода текста без больших усилий, особенно если говорить или печатать неудобно.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="bb8e1-156">API отслеживания взгляда</span><span class="sxs-lookup"><span data-stu-id="bb8e1-156">Eye tracking API</span></span>
<span data-ttu-id="bb8e1-157">Прежде чем углубляться в подробные рекомендации по разработке функций с поддержкой описываемой здесь функции, мы хотим кратко перечислить возможности средства отслеживания взгляда в HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="bb8e1-158">[API отслеживания глаз](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) можно использовать через `Windows.Perception.People.EyesPose`.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="bb8e1-159">Он предоставляет разработчику сведения об одном взгляде (исходная точка и направление).</span><span class="sxs-lookup"><span data-stu-id="bb8e1-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="bb8e1-160">Средство отслеживания глаз предоставляет данные с частотой около _30 кадров/с_.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="bb8e1-161">Прогнозируемое направление взгляда соответствует конусу с отклонением примерно</span><span class="sxs-lookup"><span data-stu-id="bb8e1-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="bb8e1-162">1,0–1,5 градуса от фактического направления в отношении рассматриваемого объекта.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="bb8e1-163">Следует ожидать и учитывать небольшую неточность, добавляя запас для нижней границы.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="bb8e1-164">Подробнее мы рассмотрим это ниже.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-164">We will discuss this more below.</span></span> <span data-ttu-id="bb8e1-165">Чтобы отслеживание взгляда работало точно, каждому пользователю нужно пройти калибровку отслеживания взгляда.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="bb8e1-166">![Оптимальный размер целевого объекта на расстоянии 2 метра](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="bb8e1-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="bb8e1-167">*Оптимальный размер целевого объекта на расстоянии 2 метра*</span><span class="sxs-lookup"><span data-stu-id="bb8e1-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="bb8e1-168">Рекомендации по проектированию взаимодействия с использованием отслеживания взгляда</span><span class="sxs-lookup"><span data-stu-id="bb8e1-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="bb8e1-169">Создание взаимодействий, в которых используется нацеливание на основе быстрого перемещения глаз, может оказаться сложной задачей.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="bb8e1-170">В этом разделе мы собрали ключевые преимущества и проблемы, которые необходимо учитывать при разработке приложения.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="bb8e1-171">Преимущества отслеживания взгляда</span><span class="sxs-lookup"><span data-stu-id="bb8e1-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="bb8e1-172">**Высокая скорость нацеливания**.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-172">**High speed pointing.**</span></span> <span data-ttu-id="bb8e1-173">Мускулы глаз — самые быстрые во всем теле человека.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="bb8e1-174">**Низкий уровень усилий**.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-174">**Low effort.**</span></span> <span data-ttu-id="bb8e1-175">Физическое перемещение почти не требуется.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="bb8e1-176">**Ненавязчивость**.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-176">**Implicitness.**</span></span> <span data-ttu-id="bb8e1-177">Подобный тип взаимодействия иногда называется "чтением мыслей", так как оценивая движения глаз, система быстро узнает, с каким объектом пользователь намерен взаимодействовать.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="bb8e1-178">**Альтернативный канал ввода.**</span><span class="sxs-lookup"><span data-stu-id="bb8e1-178">**Alternative input channel.**</span></span> <span data-ttu-id="bb8e1-179">Взгляд может стать значимым источником входных данных, который дополняет ручной и голосовой ввод, ведь функция отслеживания учитывает координацию движений глаз и рук пользователей.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="bb8e1-180">**Визуальное внимание.**</span><span class="sxs-lookup"><span data-stu-id="bb8e1-180">**Visual attention.**</span></span> <span data-ttu-id="bb8e1-181">Еще одно важное преимущество — это возможность определить то, на что обращает внимание пользователь.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="bb8e1-182">Это полезно в очень разных сценариях, от повышения эффективности при оценке дизайна до создания более интеллектуальных пользовательских интерфейсов и улучшения социальных подсказок при удаленном взаимодействии.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="bb8e1-183">По сути, использование взгляда для ввода данных позволяет быстро и без усилий передавать контекстные сигналы, что особенно эффективно в сочетании с другими методами ввода, такими как *голос* и *жесты руками*, для подтверждения намерений пользователя.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="bb8e1-184">Проблемы с использованием взгляда для ввода данных</span><span class="sxs-lookup"><span data-stu-id="bb8e1-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="bb8e1-185">Большая мощь означает и большую ответственность: Отслеживание взгляда позволяет создать поистине волшебное взаимодействие с пользователем, который чувствует себя супергероем, но при этом важно помнить и учитывать ограничения и слабости этого метода.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="bb8e1-186">Далее мы рассмотрим некоторые *проблемы*, которые нужно учитывать, а также опишем, как их устранять при работе с вводом данных через отслеживание взгляда.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="bb8e1-187">**Глаза постоянно "включены"** . Пока у человека открыты веки, глаза постоянно фокусируются на разных объектах окружающей среды.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="bb8e1-188">Если вы будете реагировать на каждый взгляд и выполнять какие-то действия, даже когда пользователь случайно задержал взгляд на каком-то объекте, это будет настоящий кошмар!</span><span class="sxs-lookup"><span data-stu-id="bb8e1-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="bb8e1-189">Поэтому мы рекомендуем сочетать отслеживание взгляда с *голосовыми командами*, *жестами руками*, *нажатиями кнопок* или использовать долгие задержки для выбора целевых объектов.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="bb8e1-190">Это решение также позволяет пользователю свободно рассматривать окружение, не испытывая дискомфорт, в том числе от случайной активации каких-либо действий.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="bb8e1-191">Эту проблему важно принимать во внимание при проектировании визуального и звукового отклика целевого объекта на взгляд.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="bb8e1-192">Не перегружайте каналы взаимодействия с пользователем навязчивыми звуками всплывающих элементов или фокусировки.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="bb8e1-193">Тонкость очень важна</span><span class="sxs-lookup"><span data-stu-id="bb8e1-193">Subtlety is key!</span></span> <span data-ttu-id="bb8e1-194">Некоторые рекомендации по этому аспекту мы рассмотрим ниже, когда речь пойдет о проектировании.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="bb8e1-195">**Наблюдение и управление**. Предположим, вам нужно аккуратно выровнять фотографию на стене.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="bb8e1-196">Вы внимательно смотрите на рамку и окружающие объекты, чтобы оценить горизонтальность линий.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="bb8e1-197">А теперь подумайте, как это сделать, если вы хотите применить отслеживание взгляда в качестве входного канала для управления перемещением фотографии.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="bb8e1-198">Сложно, правда?</span><span class="sxs-lookup"><span data-stu-id="bb8e1-198">Difficult, isn't it?</span></span> <span data-ttu-id="bb8e1-199">Этот пример иллюстрирует двойную функцию взгляда, который используется и для получения данных, и для управления.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="bb8e1-200">**Изменение фокуса перед щелчком**. Исследования показали, что при быстром выборе целевых объектов взгляд пользователя может сместиться с объекта раньше, чем он выполнит действие рукой (например, щелчок в воздухе).</span><span class="sxs-lookup"><span data-stu-id="bb8e1-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="bb8e1-201">Это означает, что важно уделить особое внимание синхронизации сигналов между быстрым каналом (взгляд) и медленным каналом управления (голос, руки, контроллер).</span><span class="sxs-lookup"><span data-stu-id="bb8e1-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="bb8e1-202">**Маленькие целевые объекты**. Знакомо ли вам то ощущение, когда шрифт немного мелковат для комфортного чтения текста?</span><span class="sxs-lookup"><span data-stu-id="bb8e1-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="bb8e1-203">Это напряжение глаз, вызванное постоянными попытками сфокусировать взгляд, приводит к усталости и раздраженности.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="bb8e1-204">Вы можете вызывать такие же ощущения у своих пользователей, если заставите их выбирать в приложении слишком мелкие объекты с помощью отслеживания взгляда.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="bb8e1-205">Чтобы поддерживать приятное и уверенное взаимодействие с пользователем, мы рекомендуем учесть при разработке, что минимальный размер целевых объектов должен быть не менее 2°, а желательно еще больше.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="bb8e1-206">**Неравномерное перемещение глаз**. Глаза постоянно и очень быстро перемещаются от одного фиксированного положения к другому.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="bb8e1-207">Изучая записанный путь перемещения глаз, вы быстро заметите его неравномерность.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="bb8e1-208">Глаза движутся очень быстро и импульсивно по сравнению с *направлением головы* и *движениями рук*.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="bb8e1-209">**Надежность отслеживания**. Точность отслеживания взгляда может немного ухудшаться при изменении освещенности, пока глаза привыкают к новым условиям.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="bb8e1-210">Это не обязательно учитывать при разработке приложения, как точность не должна становиться хуже указанных выше 2°.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="bb8e1-211">Но, возможно, пользователю придется повторно выполнить калибровку.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="bb8e1-212">Рекомендации по проектированию</span><span class="sxs-lookup"><span data-stu-id="bb8e1-212">Design recommendations</span></span>
<span data-ttu-id="bb8e1-213">Ниже перечислены конкретные рекомендации по проектированию, основанные на описанных выше преимуществах и ограничениях, связанных с отслеживанием взгляда.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="bb8e1-214">**Взгляд != направление головы.**</span><span class="sxs-lookup"><span data-stu-id="bb8e1-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="bb8e1-215">**Обдумайте, подходит ли быстрое и неровное перемещение глаз для вашей задачи ввода данных.** Быстрые и неравномерные перемещения глаз отлично подходят для выбора целевых объектов в поле зрения, но плохо применимы для задач с плавными траекториями (например, для рисования или выделения обводкой).</span><span class="sxs-lookup"><span data-stu-id="bb8e1-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="bb8e1-216">Для таких задач лучше использовать движения рук или головы.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="bb8e1-217">**Не привязывайте к взгляду пользователя никакие объекты напрямую (например, ползунок или курсор).**</span><span class="sxs-lookup"><span data-stu-id="bb8e1-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="bb8e1-218">Для курсора возникает эффект убегания, связанный с небольшими задержками в отображении сигнала направления взгляда.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="bb8e1-219">Для ползунка возникает конфликт между двумя задачами зрения: управление ползунком и проверка правильности расположения перемещаемого объекта.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="bb8e1-220">В таких случаях пользователи будут быстро уставать и отвлекаться, особенно если для пользователя плохо откалиброван сигнал.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="bb8e1-221">**Сочетайте взгляд с другими входными данными**. Интеграция отслеживания глаз с другими входными данными, такими как жесты рук, голосовые команды или нажатия кнопок, предоставляет целый ряд преимуществ.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="bb8e1-222">**Свободное наблюдение.** Так как основной работой глаз остается наблюдение за средой, важно сохранить для пользователей возможность осматриваться без активации обратной связи или действий (визуальных, звуковых и т. п.).</span><span class="sxs-lookup"><span data-stu-id="bb8e1-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="bb8e1-223">Совместное использование отслеживания взгляда с другими источниками данных позволяет плавно переключаться между режимами наблюдения и управления взглядом.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="bb8e1-224">**Мощный источник информации о контексте**. Использование сведений о том, куда смотрит пользователь при произнесении голосовых команд или выполнении жестов руками, позволяет без труда передавать входные данные в пределах поля зрения.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="bb8e1-225">Ниже перечислены примеры таких данных. Команда Put that there позволяет быстро и без усилий выбрать голограмму и поместить ее в другую область сцены, просто просмотрев на объект и место назначения.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="bb8e1-226">**Потребность в синхронизации между несколькими источниками входных данных (проблема изменения фокуса перед щелчком).** При сочетании быстрых перемещений глаз с дополнительными источниками более сложных входных данных (например, длинные голосовые команды или жесты руками) возникает риск отвести глаза от объекта раньше, чем завершится подача дополнительной команды.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="bb8e1-227">А значит, при создании собственных элементов управления (например, настраиваемых жестов руками) обязательно фиксируйте момент начала или ожидаемую длительность такого действия, чтобы сопоставлять эти данные с направлением взгляда пользователя в прошлом.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="bb8e1-228">**Ненавязчивый отклик на действия, полученные с помощью отслеживания взгляда**. Часто бывает полезно предоставлять отклик при взгляде на объект (чтобы пользователь понимал, что система работает, как ожидается), но этот отклик должен быть ненавязчивым.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="bb8e1-229">Например, можно слегка выгибать область визуального выделения или медленно перемещать объект (например, слегка увеличивать его размер), чтобы подтверждать правильное определение направления взгляда пользователя, не прерывая при этом текущий рабочий процесс пользователя.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="bb8e1-230">**Старайтесь не использовать нетипичные перемещения глаз для ввода данных.** Не вынуждайте пользователей выполнять конкретные перемещения глаз ("жесты" глазами) для запуска действий в приложении.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="bb8e1-231">**Оставьте запас на неточность.** Мы различаем два типа неточностей, которые будут заметны для пользователей. Смещение и дрожание.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="bb8e1-232">Для предотвращения смещения проще всего предоставить достаточно большие целевые объекты для взаимодействия (с видимым диаметром не менее 2°, что примерно соответствует ширине ногтя на большом пальце при полностью вытянутой руке (1)).</span><span class="sxs-lookup"><span data-stu-id="bb8e1-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="bb8e1-233">На этом основана следующая рекомендация.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="bb8e1-234">Не вынуждайте пользователей выбирать крошечные объекты. Исследования показали, что при достаточно больших целевых объектах (и тщательно продуманной системе) пользователи описывают взаимодействие как легкое и сказочное.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="bb8e1-235">Если же целевые объекты становятся слишком маленькими, взаимодействие вызывает у пользователей усталость и раздражение.</span><span class="sxs-lookup"><span data-stu-id="bb8e1-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="bb8e1-236">См. также</span><span class="sxs-lookup"><span data-stu-id="bb8e1-236">See also</span></span>
* [<span data-ttu-id="bb8e1-237">Направление головы и фиксация</span><span class="sxs-lookup"><span data-stu-id="bb8e1-237">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="bb8e1-238">Направление головы и взгляда в DirectX</span><span class="sxs-lookup"><span data-stu-id="bb8e1-238">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="bb8e1-239">Набор средств для смешанной реальности. Отслеживание взгляда в Unity</span><span class="sxs-lookup"><span data-stu-id="bb8e1-239">Eye gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="bb8e1-240">Жесты руками</span><span class="sxs-lookup"><span data-stu-id="bb8e1-240">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="bb8e1-241">Голосовой ввод</span><span class="sxs-lookup"><span data-stu-id="bb8e1-241">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="bb8e1-242">Контроллеры движения</span><span class="sxs-lookup"><span data-stu-id="bb8e1-242">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="bb8e1-243">Комфорт</span><span class="sxs-lookup"><span data-stu-id="bb8e1-243">Comfort</span></span>](comfort.md)
