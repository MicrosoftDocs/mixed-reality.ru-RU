---
title: Отслеживание взгляда
description: HoloLens 2 позволяет организовать голографическое взаимодействие на новом уровне понимания контекста и намерений человека, предоставляя разработчикам возможности для использования информации о том, куда смотрят пользователи.
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: Отслеживание взгляда, Смешанная реальность, ввод, глаз-взгляд, калибровка
ms.openlocfilehash: 60de5ceb9f55ca7e2f74856af9bd75567763e382
ms.sourcegitcommit: a5dc182da237f63f0487d40a2e11894027208b6c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/02/2019
ms.locfileid: "73441115"
---
# <a name="eye-tracking-on-hololens-2"></a>Отслеживание взгляда в HoloLens 2

![Демонстрация отслеживания взгляда в МРТК](images/mrtk_et_scenemenu.jpg)

HoloLens 2 позволяет организовать голографическое взаимодействие на новом уровне понимания контекста и намерений человека, предоставляя разработчикам возможности для использования информации о том, куда смотрят пользователи. На этой странице представлен обзор этой новой возможности для разработчиков и проектировщиков, позволяющих получить преимущества от отслеживания взгляда для различных вариантов использования и базовых руководств для разработчиков. 


## <a name="calibration"></a>Монитора 
Чтобы отслеживание взгляда работало правильно, каждый пользователь должен пройти по [калибровке пользователя с отслеживанием взгляда](calibration.md) , для которого пользователь должен взглянуть на набор holographic мишеней. Это позволяет устройству настроить систему для более удобного и качественного просмотра для пользователя, а также для обеспечения точного отслеживания в то же время. Отслеживание взгляда должно работать для большинства пользователей, но в редких случаях пользователь не может успешно выполнить калибровку.
Дополнительные сведения о калибровке и о том, как обеспечить бесперебойную работу, см. на странице [калибровка пользователей для отслеживания взгляда](calibration.md) .


## <a name="device-support"></a>Поддержка устройств
<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><strong>Функциями</strong></td>
     <td><a href="hololens-hardware-details.md"><strong>HoloLens (1-го поколения)</strong></a></td>
     <td><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></td>
     <td><a href="immersive-headset-hardware-details.md"><strong>Иммерсивные гарнитуры</strong></a></td>
</tr>
<tr>
     <td>Взгляд — взгляд</td>
     <td>❌</td>
     <td>✔️</td>
     <td>❌</td>
</tr>
</table>

## <a name="available-eye-tracking-data"></a>Доступные данные отслеживания взгляда
Прежде чем приступить к подробному рассмотрению конкретных вариантов использования для ввода взгляда, мы хотим вкратце описать возможности, предоставляемые [API отслеживания взгляда](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) HoloLens 2. Разработчики получают доступ к одному лучау глаза (источнику и направлению взгляда) приблизительно в _30 кадров/с (30 Гц)_ .
Более подробные сведения о том, как получить доступ к данным отслеживания взгляда, см. в руководствах для разработчиков, посвященных использованию [глаз-взгляда в DirectX](gaze-in-directx.md) и [глаза-взгляде в Unity](https://aka.ms/mrtk-eyes).

Прогнозируемый глаз — это приблизительно в 1,5 градусов визуального угла вокруг фактического целевого объекта (см. рисунок ниже). Как и в случае с небольшим количеством неточностей, разработчики должны запланировать некоторое поле вокруг этого нижнего значения (например, 2.0-3.0 градусов может привести к более удобному интерфейсу). Мы обсудим, как более подробно решать выбор мелких целевых объектов. Чтобы отслеживание взгляда работало точно, каждому пользователю нужно пройти калибровку отслеживания взгляда. 

![Оптимальный размер целевого объекта на расстоянии 2 метра](images/gazetargeting-size-1000px.jpg)<br>
*Оптимальный размер целевого объекта на расстоянии в 2 метра*

<br>

## <a name="use-cases"></a>Варианты использования
Функция отслеживание взгляда предоставляет приложениям сведения о том, куда смотрит пользователь в реальном времени. В следующих вариантах использования описаны некоторые взаимодействия, которые можно выполнить с отслеживанием глаз в HoloLens 2 в смешанной реальности.
Обратите внимание, что эти варианты использования еще не являются частью работы с оболочкой holographic (т. е. интерфейса, который вы видите при запуске HoloLens 2).
Некоторые из них можно испытать в [наборе средств для смешанной реальности](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) , который предоставляет несколько интересных и мощных примеров для использования отслеживания взгляда, таких как быстрый и простой в использовании Выбор целевого объекта, а также автоматическая прокрутка текста на основе о том, что видят пользователи. 

### <a name="user-intent"></a>Намерения пользователя    
Сведения о том, где и как выглядит пользователь, предоставляет мощный **контекст для других входных данных**, таких как Voice, руки и контроллеры.
Эти данные можно применять в разных задачах.
Например, это может варьироваться от быстрого и легко **нацеливания** на сцену, просто взглянув на голограмму и выполнив *команду "Select"* (см. раздел « [взгляд» и «фиксация](gaze-and-commit.md)») или *«поместить это...»* , просматривая место, где пользователь хочет поместить голограмму и сказать *: «... Здесь "* . Подобные примеры доступны в наборах средств для смешанной реальности для [выбора целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) и [позиционирования целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).

Кроме того, пример намерения пользователя может включать в себя сведения о том, что видят пользователи, чтобы улучшить работу с помощью применяющихся виртуальных агентов и интерактивных голограмм. Например, виртуальные агенты могут адаптировать доступные параметры и их поведение на основе текущего просматриваемого содержимого. 

### <a name="implicit-actions"></a>Неявные действия
Категория неявных действий тесно связана с намерениями пользователя.
Идея состоит в том, что голограммы или элементы пользовательского интерфейса реагируют на инстинктуале, что может даже не показаться, что пользователь взаимодействует с системой вообще, а сам система и пользователь синхронизированы. Одним из примеров является **Автоматическая прокрутка на основе взгляда на глаза** , когда пользователь может прочитать длинный текст, который автоматически начинает прокручиваться после того, как пользователь получит доступ к нижней части текстового поля, чтобы пользователь оставался в потоке чтения без отрыва пальца.  
Ключевым аспектом этого процесса является то, что скорость прокрутки адаптируется к скорости чтения пользователя.
В качестве другого примера можно возместить **масштаб и панораму** , в котором пользователь может точно соответствовать тем, на что он направлен. Для управления скоростью масштабирования и управления ею можно управлять с помощью голоса или ввода-вывода, что важно для предоставления пользователю прав на управление и предотвращения переполнения. Более подробно эти вопросы по проектированию будут обсуждаться ниже. После масштабирования пользователь может плавно проследить за тем, что, например, разообразить свое окружение, просто воспользовавшись знаком взгляда.
Эти типы взаимодействия демонстрируются в примере набора средств для смешанной реальности для [навигации с поддержкой взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).

В качестве дополнительных примеров _неявных действий_ можно назвать следующее:
- **Интеллектуальные уведомления:** Всегда получаете раздражен по уведомлениям, которые выводятся справа, где вы находитесь? Принимая во внимание то, к какому пользователю относится пользователь, вы можете сделать этот процесс более эффективным, потратив уведомления от того, где пользователь в настоящее время облаками. Это ограничивает число обращений и автоматически закрывает их после того, как пользователь закончит чтение. 
- **Голограммы внимательный:** Голограммы, которые слегка реагируют на газед. Это может варьироваться от слегка свечения элементов пользовательского интерфейса, медленного цветутного цветок до виртуальной Dog, начинающейся с пользователя, и ваггинг его хвост. Это взаимодействие может предоставить интересное представление о подключении и удовлетворенности приложения.

### <a name="attention-tracking"></a>Отслеживание внимания   
Сведения о том, где или как видят пользователи, — это чрезвычайно мощный инструмент для оценки удобства использования дизайнов и выявления проблем в эффективных рабочих процессах. Визуализация и аналитика отслеживания взгляда являются распространенной практикой в различных областях приложений. С помощью HoloLens 2 мы предоставляем новое измерение для понимания того, как трехмерные голограммы могут быть помещены в реальные контексты и оцениваться соответствующим образом. [Набор средств Mixed Reality](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) предоставляет основные примеры ведения журнала и загрузки данных отслеживания взгляда, а также способы их визуализации.

Другие приложения из этой сферы поддерживают следующие функции: 
-   **Удаленный взгляд — визуализация взгляда:** Визуализация удаленных участников совместной работы для повышения общего понимания.
-   Исследования **пользователей:** Отслеживание внимания помогает лучше понять, как мы будем воспринимать и привлекать к нашей среде, что может помочь в улучшении моделей человеческих людей для более инстинктуалного взаимодействия с человеком-компьютером. 
-   **Обучение:** Улучшенное обучение для новичков. лучше понимать шаблоны визуального поиска экспертов и выполнять сложные задачи, например для анализа медицинских данных или использования операционных машин.
-   **Оценка проектирования и исследование рынка:** Отслеживание взгляда — это распространенный инструмент для исследования рынка при оценке моделей веб-сайтов и продуктов. С помощью HoloLens 2 можно расширить это до трехмерных пространств, объединив варианты проектирования цифровых продуктов с физической средой. 

### <a name="additional-use-cases"></a>Другие варианты использования
- **Игры:** Когда-нибудь хотели, чтобы у меня была сила? Вам сюда! Вы можете левитате голограммы на них. Прокрутка лазерного беамса от глаз. Попробуйте в [робораид для HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).
Превратите противников в камень или закрепите их. Примените рентгеновское зрение, чтобы исследовать здания. Вы ограничены только пределами своего воображения!
Будьте осторожны, чтобы узнать больше, ознакомьтесь с [рекомендациями по проектированию ввода на основе взгляда на глаза](eye-gaze-interaction.md).

- **Выразительные аватары:** Отслеживание взгляда помогает в более выразительных трехмерных аватарах, используя данные отслеживания взгляда, чтобы анимировать глаза аватара, указывающие, что именно видят пользователи. 

- **Текстовая запись:** Отслеживание взгляда можно использовать в качестве альтернативы для ввода текста с низкой наработкой, особенно если речь или руки неудобны для использования. 

<br>

## <a name="using-eye-gaze-for-interaction"></a>Использование глаза — взгляд на взаимодействие
Создание взаимодействия, которое использует преимущества быстрого перемещения глаз, может оказаться сложной задачей.
С одной стороны, глаза перемещаются настолько быстро, что необходимо соблюдать осторожность при использовании входных данных взгляда на глаза, так как в противном случае пользователь может найти ненужные или неудобства. С другой стороны, вы также можете создать действительно magicalные возможности, которые будут Стимулируйте обучение ваши пользователи! Чтобы помочь вам, ознакомьтесь с обзором основных преимуществ, задач и рекомендаций по проектированию, чтобы узнать о [взаимодействии](eye-gaze-interaction.md). 

<br>
 
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a>Руководство разработчика: что делать, если отслеживание взгляда недоступно?
Возможны ситуации, когда приложение не будет получать данные отслеживания взгляда по различным причинам, включая, помимо прочего, следующие:
* Пользователь пропустил калибровку отслеживания взгляда.
* Пользователь откалиброван, но решил не предоставлять приложению разрешение на использование данных отслеживания взгляда.
* Пользователь имеет уникальные очков или некоторые условия для глаз, которые система пока не поддерживает.
* Внешние факторы отслеживают надежность отслеживания взгляда, например палец на делителе HoloLens или очков, интенсивность прямого солнечного света и окклусионс из-за перекрестных глаз.

Разработчикам приложений это означает, что необходимо учитывать, как поддерживать пользователей, для которых данные отслеживания взгляда могут быть недоступны. Ниже мы сначала объясним, как определить, доступно ли отслеживание взгляда, и как решить, когда оно недоступно для различных приложений.

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a>1. как определить доступность отслеживания взгляда
Существует несколько проверок, позволяющих определить, доступны ли данные отслеживания взгляда. Проверьте, нет ли...
* ... система поддерживает отслеживание взгляда. Вызовите следующий *метод*: [Windows. восприятие. People. эйеспосе. Поддержка ()](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)

* ... пользователь откалиброван. Вызовите следующее *свойство*: [Windows. восприятие. People. эйеспосе. искалибратионвалид](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)

* ... пользователь предоставил приложению разрешение на использование данных отслеживания взгляда: получение текущего _"газеинпутакцессстатус"_ . Пример того, как это сделать, объясняется в [запросе доступа к вводу с помощью взгляда](https://docs.microsoft.com/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).

Кроме того, может потребоваться проверить, что данные отслеживания взгляда не устарели, добавив время ожидания между полученными обновлениями данных отслеживания взгляда и иным способом откатом к заголовку, как описано ниже. 

Как описано выше, существует несколько причин, по которым данные отслеживания взгляда могут быть недоступны. Хотя некоторые пользователи, возможно, решили отменять доступ к данным отслеживания взгляда, и, в некоторых случаях, не предоставить доступ к данным отслеживания взгляда, это может быть непреднамеренно. Таким образом, если приложение использует отслеживание взгляда, и это важная часть работы, мы рекомендуем четко взаимодействовать с пользователем. Пользователь должен знать, почему отслеживание взгляда является критически важным для вашего приложения (возможно, даже перечисление некоторых улучшенных функций), чтобы помочь пользователю лучше понять, что они предоставляют. Помогите пользователю определить, почему отслеживание взгляда может не работать (на основе описанных выше проверок) и предложить некоторые рекомендации для быстрого устранения потенциальных проблем. Например, если вы обнаружите, что система поддерживает отслеживание взгляда, пользователь откалиброван и даже имеет соответствующее разрешение, но данные отслеживания взгляда не принимаются, это может указывать на некоторые другие проблемы, такие как Растушевка или перекрыто глаза. Обратите внимание, что в редких случаях пользователи, для которых отслеживание взгляда может просто не работать. Таким образом, будьте Уважайте, чтобы отклонять или даже отключать напоминания о включении отслеживания взгляда в приложении.

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a>2. откат для приложений, использующих глаз — это первичный указатель ввода
Если приложение использует указатель мыши в качестве входных указателей, чтобы быстро выбирать голограммы в сцене, но данные отслеживания взгляда недоступны, мы рекомендуем вернуться к Head-взгляду и начать отображение курсора Head-взгляда. Мы рекомендуем использовать время ожидания (например, 500 – 1500 мс) для определения необходимости переключения. Это позволяет избежать выталкивания курсора при каждой ошибке, когда система может ненадолго потерять отслеживание из-за движения с высокой продолженностью или мультиков и мерцаний. Если вы являетесь разработчиком Unity, автоматическое переключение на Heading-взгляд уже обработано в наборе средств Mixed Reality. Если вы являетесь разработчиком DirectX, вам нужно самостоятельно справиться с этим параметром.

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a>3. откат для других приложений, зависящих от отслеживания взгляда
Ваше приложение может использовать глаза в уникальном виде, специально предназначенном для глаз, например, для анимации глаза аватара или для внимания на глаза, тепловые карты с точной информацией о визуальном внимание. В этом случае нет четких резервных. Если отслеживание взгляда недоступно, эти возможности могут просто быть отключены.
Опять же, рекомендуется явно сообщить об этом пользователю, который может не знать, что эта возможность не работает.

<br>

На этой странице мы надеемся, что вы получите хорошее представление о роли отслеживания взгляда и взгляда на глаза для HoloLens 2. Чтобы приступить к разработке, ознакомьтесь с нашими сведениями о роли [взгляда с голограммами](eye-gaze-interaction.md), [Взгляните на](https://aka.ms/mrtk-eyes) глаза в Unity и [глаза-взгляд в DirectX](gaze-in-directx.md).


## <a name="see-also"></a>См. также
* [Калибровка](calibration.md)
* [Комфорт](comfort.md)
* [Взаимодействие на основе взгляда](eye-gaze-interaction.md)
* [Глаза. Взгляните на DirectX](gaze-in-directx.md)
* [Взгляд — Взгляните на Unity (набор средств Mixed Reality)](https://aka.ms/mrtk-eyes)
* [Взгляните и зафиксируйте](gaze-and-commit.md)
* [Голосовой ввод](voice-design.md)


