---
title: Взгляд — взгляд
description: HoloLens 2 предоставляет разработчикам возможность использовать информацию о том, что видят пользователи, для нового уровня контекста и человеческого понимания в Holographic.
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: Отслеживание глаз, Смешанная реальность, ввод, глаз-взгляд, взгляд глаз
ms.openlocfilehash: c847f7de2cf4492c89225a88aeaf189f51cfbc40
ms.sourcegitcommit: b0b1b8e1182cce93929d409706cdaa99ff24fdee
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/23/2019
ms.locfileid: "68387595"
---
# <a name="eye-gaze-on-hololens-2"></a>Глаз — Взгляните на HoloLens 2
HoloLens 2 предоставляет разработчикам возможность использовать информацию о том, что видят пользователи, для нового уровня контекста и человеческого понимания в Holographic. Эта страница указывает разработчикам, как они могут воспользоваться преимуществами отслеживания взгляда для различных вариантов использования, а также то, что следует искать при проектировании пользовательских интерфейсов на основе взгляда. 


## <a name="device-support"></a>Поддержка устройств

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><strong>Возможность</strong></td>
     <td><a href="hololens-hardware-details.md"><strong>HoloLens (1-го поколения)</strong></a></td>
     <td><strong>HoloLens 2</strong></td>
     <td><a href="immersive-headset-hardware-details.md"><strong>Иммерсивные гарнитуры</strong></a></td>
</tr>
<tr>
     <td>Взгляд — взгляд</td>
     <td>❌</td>
     <td>✔️</td>
     <td>❌</td>
</tr>
</table>

## <a name="use-cases"></a>Варианты использования
Функция отслеживание взгляда предоставляет приложениям сведения о том, куда смотрит пользователь в реальном времени. В следующих сценариях использования описаны некоторые взаимодействия, которые можно реализовать с помощью отслеживания взгляда в смешанной реальности.
Следует помнить, что [набор средств Mixed Reality](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) полезен для предоставления нескольких интересных и удобных примеров использования отслеживания взгляда, таких как быстрый и простой способ выбора целевого объекта, а также автоматическая прокрутка текста на основе вид пользователя. 

### <a name="user-intent"></a>Намерения пользователя    
Сведения о том, где и как выглядит пользователь, предоставляет мощный **контекст для других входных данных**, таких как Voice, руки и контроллеры.
Эти данные можно применять в разных задачах.
Например, это может варьироваться от быстрого и легко нацеливания на сцену, просто взглянув на голограмму и выполнив команду "Select" (см. также «  [head-взгляд» и «Commit](gaze-and-commit.md)») или «поместить это...», а затем взглянуть на место размещения пользователя голограмма и скажите «... Здесь ". Подобные примеры доступны в наборах средств для смешанной реальности для [выбора целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) и [позиционирования целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).

Кроме того, пример намерения пользователя может включать в себя сведения о том, что видят пользователи, чтобы улучшить работу с помощью применяющихся виртуальных агентов и интерактивных голограмм. Например, виртуальные агенты могут адаптировать доступные параметры и их поведение на основе текущего просматриваемого содержимого. 

### <a name="implicit-actions"></a>Неявные действия
Категория неявных действий тесно связана с намерениями пользователя.
Идея состоит в том, что голограммы или элементы пользовательского интерфейса реагируют на инстинктуале, что может даже не показаться, что пользователь взаимодействует с системой вообще, а сам система и пользователь синхронизированы. Одним из примеров является **Автоматическая прокрутка на основе взгляда** , когда пользователь считывает текст, когда текст прокручивается или помещается в синхронизацию с взглядом пользователя. Ключевым аспектом этого процесса является то, что скорость прокрутки адаптируется к скорости чтения пользователя.
В качестве другого примера можно возместить **масштаб и панораму** , в котором пользователь может точно оценить порядок, в котором он или она ориентированы на o. Для управления скоростью масштабирования и управления ею можно управлять с помощью голоса или ввода-вывода, что важно для предоставления пользователю прав на управление и предотвращения переполнения. Мы рассмотрим эти рекомендации по проектированию более подробно. После масштабирования пользователь может плавно проследить за тем, что, например, разообразить свое окружение, просто воспользовавшись знаком взгляда.
Эти типы взаимодействия демонстрируются в примере набора средств для смешанной реальности для [навигации с поддержкой взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).

Дополнительные варианты использования неявных _действий_ могут включать:
- **Интеллектуальные уведомления**. Вас раздражают уведомления, которые всплывают ровно в том месте, на которое вы смотрите? Принимая во внимание то, к какому пользователю относится пользователь, вы можете сделать этот процесс более эффективным, потратив уведомления от того, где пользователь в настоящее время облаками. Это ограничивает число обращений и автоматически закрывает их после того, как пользователь закончит чтение. 
- **"Вежливые" голограммы**. Голограммы, которые слегка реагируют на газед. Это может варьироваться от слегка свечения элементов пользовательского интерфейса до медленного цветутного цветок до виртуального животного, начинающегося с пользователя, или пытаясь избежать глаза пользователя после длительной звездочки. Это взаимодействие может предоставить интересное представление о подключении и удовлетворенности приложения.

### <a name="attention-tracking"></a>Отслеживание внимания   
Сведения о том, где или как видят пользователи, — это чрезвычайно мощный инструмент для оценки удобства использования дизайнов и выявления проблем в эффективных рабочих процессах. Визуализация и аналитика отслеживания взгляда являются распространенной практикой в различных областях приложений. С помощью HoloLens 2 мы предоставляем новое измерение для понимания того, как трехмерные голограммы могут быть помещены в реальные контексты и оцениваться соответствующим образом. [Набор средств Mixed Reality](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) предоставляет основные примеры ведения журнала и загрузки данных отслеживания взгляда, а также способы их визуализации.

Другие приложения в этой области могут включать: 
-   **Удаленный взгляд — визуализация взгляда:** Визуализируйте, что просматривает удаленные участники совместной работы, чтобы убедиться, что инструкции правильно понятны и следуют.
-   **Исследование пользователей.** Отслеживание внимания можно использовать для изучения того, как новички и пользователи с экспертами визуально анализируют содержимое или способ координации сложных задач, например для анализа медицинских данных или при работе с операционным механизмом.
-   **Обучающее моделирование и мониторинг производительности.** Тренировка и оптимизация выполнения задач, которые позволят более эффективно выявлять узкие места в потоке выполнения.
-   **Оценка проекта, реклама и маркетинговые исследования.** Отслеживание взгляда — это распространенный инструмент для исследования рынка при оценке моделей веб-сайтов и продуктов.

### <a name="additional-use-cases"></a>Другие варианты использования
- **Игры.** Вам нужны суперспособности? Вам сюда! Вы можете левитате голограммы на них. Стреляйте лазерными лучами из глаз. Превратите противников в камень или закрепите их. Примените рентгеновское зрение, чтобы исследовать здания. Вы ограничены только пределами своего воображения!  

- **Выразительные аватары.** Отслеживание взгляда позволяет использовать более выразительные трехмерные аватары с помощью даты отслеживания в реальном времени для анимации глаз аватара, указывающих на то, что видят пользователи. Вы можете усилить выразительность, добавив моргания и подмигивания. 

- **Ввод текста.** Отслеживание взгляда можно использовать в качестве альтернативы для ввода текста с низкой наработкой, особенно если речь или руки неудобны для использования. 


## <a name="eye-tracking-api"></a>API отслеживания взгляда
Прежде чем приступить к подробному рассмотрению конкретных руководств по проектированию для взаимодействия с взглядом, мы хотим вкратце описать возможности API-интерфейса, отслеживающего отслеживание взглядов HoloLens 2, для разработчиков. Он предоставляет один источник и направление взгляда на глаза — предоставление данных приблизительно в _30 кадров/_ с. 

Прогнозируемый взгляд — взгляд находится в центре сертификации. 1,0-1,5 градусов в визуальном уголе вокруг фактического целевого объекта. Следует ожидать и учитывать небольшую неточность, добавляя запас для нижней границы. Подробнее мы рассмотрим это ниже. Чтобы отслеживание взгляда работало точно, каждому пользователю нужно пройти калибровку отслеживания взгляда. 

![Оптимальный размер целевого объекта на расстоянии 2 метра](images/gazetargeting-size-1000px.jpg)<br>
*Оптимальный размер целевого объекта на расстоянии в 2 метра*
<br>
<br>
[API отслеживания взгляда](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) доступен через: "Windows. восприятие. People. эйеспосе". 

## <a name="eye-gaze-design-guidelines"></a>Рекомендации по проектированию взгляда
Создание взаимодействий, в которых используется нацеливание на основе быстрого перемещения глаз, может оказаться сложной задачей. В этом разделе мы обобщены основные преимущества и проблемы, которые необходимо учитывать при проектировании приложения. 

### <a name="benefits-of-eye-gaze-input"></a>Преимущества входных данных взгляда
- **Высокая скорость нацеливания**. Мускулы глаз — самые быстрые во всем теле человека. 

- **Низкий уровень усилий**. Физическое перемещение почти не требуется. 

- **Ненавязчивость**. Сведения о перемещении глаз, часто описываемые пользователями, позволяют системе узнать, какую цель планирует пользователь придерживаться. 

- **Альтернативный канал ввода.** Взгляд на глаза — это мощный вспомогательный ввод, позволяющий создавать руки и речевые входные данные в течение многих лет работы пользователей, основанных на координации глаз.

- **Визуальное внимание.** Еще одним важным преимуществом является возможность определить, к чему пользователь оплачивает внимание. Это может помочь в различных областях приложений, от более эффективного оценки различных проектов до упрощения работы с более интеллектуальными пользовательскими интерфейсами и расширенными социальными подсказками для удаленного взаимодействия.

В двух словах, использование глаз-взгляда в качестве входных данных обеспечивает быстрый и простой контекстный сигнал. Это особенно удобно в сочетании с другими входными данными,  например с голосовыми и *ручными* вводами, для подтверждения намерений пользователя.


### <a name="challenges-of-eye-gaze-as-an-input"></a>Проблемы с глазом. Взгляните на входные данные
Благодаря большому энергопотреблению приходится отвечать за множество обязанностей.
Хотя с помощью взгляда можно использовать для создания соответствия пользовательским интерфейсам, что делает вас похожим на супергерой, важно иметь представление о том, что он не подходит для соответствующей учетной записи. Ниже обсуждаются некоторые *проблемы* , которые необходимо учитывать при работе с входными данными взгляда на глаза. 

- **Взгляд на глаза — "Always On"** Когда вы откроете Лидс глаз, ваши глаза начнут фиксатинг на вещи в среде. При каждом взгляде вы выполняете и случайно выдаете действия, так как вы просматриваете что-то слишком длинное, что привело бы к неудовлетворенности.
Именно поэтому мы рекомендуем объединять глаза с помощью *команды Voice*, жеста *руки*, нажатия *кнопки* или расширенного вдаваясь, чтобы активировать выбор цели.
Это решение также обеспечивает режим, в котором пользователь может просмотреться без лишних пошагового запуска чего-либо. Эту проблему важно принимать во внимание при проектировании визуального и звукового отклика целевого объекта на взгляд.
Не перегружайте каналы взаимодействия с пользователем навязчивыми звуками всплывающих элементов или фокусировки. Тонкость — это ключ. Некоторые рекомендации по этому аспекту мы рассмотрим ниже, когда речь пойдет о проектировании.

- **Наблюдение и управление** Представьте себе, что вы хотите точно выгадать фотографию на стене. Вы внимательно смотрите на рамку и окружающие объекты, чтобы оценить горизонтальность линий. Теперь представьте себе, как это сделать, если вы хотите использовать глаз в качестве входных данных для перемещения изображения. Сложно, правда? В этом описана двойная роль глаза — Взгляните, когда требуется как для ввода, так и для управления. 

- **Изменение фокуса перед щелчком**. Для быстрого выбора целевых объектов исследование показало, что перед завершением ручного щелчка (например, аиртап) можно перейти на глаза. Следовательно, особое внимание должно быть оплачено для синхронизации сигнала с быстрым глазом взгляда с медленным входом (например, с помощью голоса, руки, контроллера).

- **Маленькие целевые объекты**. Вы знаете, что происходит при попытке чтения текста, который слишком мал, чтобы быть удобным для чтения? Это может привести к тому, что вы захотите и надеты, так как вы попытаетесь перенастроить глаза, чтобы лучше сосредоточиться на них.
Это незначительное время, которое может быть вызвано пользователями при принудительном выборе целевых объектов, которые слишком малы в приложении, с помощью нацеленности на глаз.
Чтобы поддерживать приятное и уверенное взаимодействие с пользователем, мы рекомендуем учесть при разработке, что минимальный размер целевых объектов должен быть не менее 2°, а желательно еще больше.

- **Неоднородный взгляд — перемещения Взгляните** Наши глаза выполняют быстрые перемещения от с фиксацией к с фиксацией. Изучая записанный путь перемещения глаз, вы быстро заметите его неравномерность. Глаза движутся очень быстро и импульсивно по сравнению с *направлением головы* и *движениями рук*.  

- **Надежность отслеживания**. Точность отслеживания взгляда может немного ухудшаться при изменении освещенности, пока глаза привыкают к новым условиям.
Хотя это не должно повлиять на структуру приложения, так как точность должна быть в пределах 2 °, для пользователя может потребоваться другая калибровка. 


## <a name="design-recommendations"></a>Рекомендации по проектированию
Ниже приведен список конкретных рекомендаций по проектированию, основанных на указанных преимуществах и проблемах для ввода взгляда на глаза:

1. **Глаз — взгляд! = Head — взгляд:**
    - **Обдумайте, подходит ли быстрое и неровное перемещение глаз для вашей задачи ввода данных.** Несмотря на то, что наши быстрые и неровные перемещения глаз отлично подходят для быстрого выбора целевых объектов в нашем поле View (фов), оно будет менее применимо для задач, требующих сглаживания входных траекторий (например, для рисования или енЦирклинг заметок). Для таких задач лучше использовать движения рук или головы.
  
    - **Старайтесь не прикреплять что-либо непосредственно к глазу пользователя (например, к ползунку или курсору).**
В случае с курсором это может привести к эффекту "флиинг Cursor" из-за небольших смещений в прогнозируемом сигнале взгляда. В случае с ползунком он может конфликтовать с двойной ролью управления ползунком с глазами, а также проверить, находится ли объект в нужном месте. В двух словах, пользователи могут стать перегруженными и нечеткими, особенно если сигнал неточен для этого пользователя. 
  
2. **Объединение глаз-взгляда с другими входными данными:** Интеграция отслеживания взгляда с другими входными данными, такими как жесты, речевые команды или нажатие кнопки, обеспечивает ряд преимуществ.
    - **Свободное наблюдение.** Учитывая, что основная роль наших глаз заключается в том, чтобы наблюдать за нашей средой, важно, чтобы пользователи могли выполнять поиск без запуска отзывов или действий (визуальных, аудитов и т. д.). 
    Объединение отслеживания взгляда с другим элементом управления вводом позволяет плавно переходить между наблюдения за отслеживанием взгляда и режимами управления вводом.
  
    - **Мощный источник информации о контексте**. С помощью сведений о месте и том, что видят пользователи, в то время как уттеринг голосовое действие или выполнение жеста руки позволяет легко передавать входные данные по полю представления. Пример: Команда Put that there позволяет быстро и без усилий выбрать голограмму и поместить ее в другую область сцены, просто просмотрев на объект и место назначения. 

    - **Потребность в синхронизации между несколькими источниками входных данных (проблема изменения фокуса перед щелчком).** Сочетание быстрых движений с более сложными дополнительными входами, например длинными голосовыми командами или жестами руки, несет ответственность за продолжение глаза перед завершением дополнительной команды ввода. А значит, при создании собственных элементов управления (например, настраиваемых жестов руками) обязательно фиксируйте момент начала или ожидаемую длительность такого действия, чтобы сопоставлять эти данные с направлением взгляда пользователя в прошлом.
    
3. **Ненавязчивый отклик на действия, полученные с помощью отслеживания взгляда**. При просмотре целевого объекта полезно оставить отзыв, чтобы указать, что система работает как намеченная, но должна быть незаметной. Это может включать в себя медленное смешивание, включение и отображение визуальных элементов или выполнение других тонких целевых объектов, например медленное движение, например небольшое увеличение целевого объекта, чтобы указать, что система правильно определила, что пользователь просматривает целевой объект без Необязательное прерывание текущего рабочего процесса пользователя. 

4. **Старайтесь не использовать нетипичные перемещения глаз для ввода данных.** Не вынуждайте пользователей выполнять определенные движения глаз (жесты вздействия) для запуска действий в приложении.

5. **Оставьте запас на неточность.** Мы расразличимы два типа неточностей, которые заметны для пользователей: смещение и нарушение. Самый простой способ устранить это смещение — предоставить достаточно большие целевые объекты для взаимодействия. Рекомендуется использовать визуальный угол больше 2 ° в качестве ссылки. Например, размер эскиза составляет примерно 2 ° в визуальном элементе при растяжении ARM. На этом основана следующая рекомендация.
    - Не вынуждайте пользователей выбирать крошечные целевые объекты. Исследование показало, что если целевые объекты достаточно велики и система спроектирована правильно, пользователи описывают взаимодействие как простые и Magical. Если же целевые объекты становятся слишком маленькими, взаимодействие вызывает у пользователей усталость и раздражение.
   

## <a name="see-also"></a>См. также
* [Направление головы и фиксация](gaze-and-commit.md)
* [Руководитель и глаза — Взгляните на DirectX](gaze-in-directx.md)
* [Взгляд — Взгляните на Unity (набор средств Mixed Reality)](https://aka.ms/mrtk-eyes)
* [Жесты руками](gestures.md)
* [Голосовой ввод](voice-design.md)
* [Контроллеры движения](motion-controllers.md)
* [Комфорт](comfort.md)
