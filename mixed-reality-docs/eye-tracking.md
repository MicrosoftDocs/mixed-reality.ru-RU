---
title: Отслеживание взгляда
description: Отслеживание взгляда
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Eye Tracking, Mixed Reality, Input, Eye Gaze
ms.openlocfilehash: 7298a34a946f86aaf789cfe44ad971169fc8ece3
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/05/2019
ms.locfileid: "66453700"
---
# <a name="eye-tracking-on-hololens-2"></a>Отслеживание взгляда в HoloLens 2
HoloLens 2 позволяет организовать голографическое взаимодействие на совершенно новом уровне понимания контекста и намерений человека, предоставляя разработчикам невероятные возможности для использования информации о том, куда смотрят пользователи. На этой странице собраны общие сведения о том, как разработчики могут использовать отслеживание взгляда в разных сценариях и на что нужно обратить внимание при проектировании пользовательских интерфейсов с отслеживанием направления взгляда. 

## <a name="use-cases"></a>Варианты использования
Функция отслеживание взгляда предоставляет приложениям сведения о том, куда смотрит пользователь в реальном времени. В этом разделе описываются возможные варианты использования и новые способы взаимодействия, которые становятся возможными в смешанной реальности благодаря функции отслеживания взгляда.
Перед началом работы мы немного расскажем о [наборе средств для смешанной реальности](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html), который предоставляет несколько интересных примеров использования технологии отслеживания взгляда. Например, с помощью функции отслеживания взгляда можно быстро и легко выбирать целевые объекты или автоматически прокручивать текст. 

### <a name="user-intent"></a>Намерения пользователя    
Сведения о том, куда смотрит пользователь, предоставляют важный **контекст для других поступающих от человека данных**, включая голос, жесты рук и движения контроллеров.
Эти данные можно применять в разных задачах.
Например, можно быстро и легко выполнять **нацеливание** в виртуальной сцене, просто просмотрев на голограмму и произнеся команду select (см. руководство по [ направлению взгляда и фиксации](gaze-and-commit.md)). Также можно произнести команду put this, а затем посмотреть на место для размещения голограммы и произнести команду there. Подобные примеры доступны в наборах средств для смешанной реальности для [выбора целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) и [позиционирования целевого объекта с поддержкой направления взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).

Еще один пример использования намерений пользователя — это применение информации о том, на что смотрит пользователь, для улучшения взаимодействия с визуализированными виртуальными агентами и интерактивными голограммами. Например, виртуальные агенты могут изменять доступные варианты действий и свое поведение с учетом того, какое содержимое сейчас просматривается. 

### <a name="implicit-actions"></a>Неявные действия
Категория неявных действий тесно связана с намерениями пользователя.
Идея заключается в том, что голограммы и элементы пользовательского интерфейса по умолчанию реагируют так, что взаимодействие не замечается вообще. Создается впечатление, что система просто действует синхронно с пользователем. Невероятно эффективным примером такого взаимодействия является **автопрокрутка на основе направления взгляда**. Идея очень проста. Пользователь читает текст, не совершая дополнительных действий. Текст плавно перемещается вверх на той скорости, с которой пользователь его читает. Ключевым аспектом здесь является то, что скорость прокрутки адаптируется к скорости чтения пользователя.
Еще один пример — **масштабирование и панорамирование с поддержкой направления взгляда**. В этом режиме пользователь будто приближает объект, на котором он фокусируется. Активация масштабирования и управление скоростью координируется голосом или жестами рук. Это очень важно, так как пользователь не должен терять чувство контроля над происходящим (рекомендации по проектированию мы подробнее рассмотрим ниже). После увеличения масштаба пользователь может, например, проследовать по улице, чтобы изучить расположенные на ней объекты, просто переводя на них взгляд.
Эти типы взаимодействия демонстрируются в примере набора средств для смешанной реальности для [навигации с поддержкой взгляда](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).

В качестве дополнительных примеров _неявных действий_ можно назвать следующее:
- **Интеллектуальные уведомления**. Вас раздражают уведомления, которые всплывают ровно в том месте, на которое вы смотрите? Но если вы будете учитывать то, куда смотрит пользователь в текущий момент, вы сможете улучшить это поведение! Отображайте уведомления на некотором расстоянии от области, которую рассматривает пользователь, чтобы меньше отвлекать его, а затем автоматически закройте прочитанное уведомление. 
- **"Вежливые" голограммы**. Голограммы могут немного изменять поведение при взгляде на них. Например, можно слегка подсвечивать элементы пользовательского интерфейса, медленно распускать цветок или даже создать виртуальную зверушку, которая смотрит вам в глаза или избегает длительного контакта глаз. Это создаст в приложении интересную атмосферу связи и удовлетворения.

### <a name="attention-tracking"></a>Отслеживание внимания   
Сведения о том, куда смотрит пользователь — это очень мощное средство для оценки удобства работы и выявления проблем в эффективных рабочих потоках. Отслеживание направления взгляда уже стало стандартным инструментом для визуализации и аналитики в самых разных приложениях. HoloLens 2 расширяет эти возможности, ведь теперь трехмерные голограммы можно размещать в реальном контексте и оценивать с учетом этого контекста. [Набор средств для смешанной реальности](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) предоставляет простые примеры регистрации, загрузки и визуализации данных об отслеживании взгляда.

Другие приложения из этой сферы поддерживают следующие функции: 
-   **Визуализация направления удаленного взгляда.** Визуализация объектов, на которые смотрят участники сеанса совместной дистанционной работы, для контроля правильности понимания и соблюдения инструкций.
-   **Исследование пользователей.** Отслеживание внимания позволяет сравнить, как новички и профессионалы изучают содержимое или координируют движения глаз и рук при решении сложных задач (например, при анализе медицинских данных или управлении аппаратурой).
-   **Обучающее моделирование и мониторинг производительности.** Тренировка и оптимизация выполнения задач, которые позволят более эффективно выявлять узкие места в потоке выполнения.
-   **Оценка проекта, реклама и маркетинговые исследования.** Отслеживание взгляда широко используется в маркетинговых исследованиях для оценки дизайна сайтов и продуктов.

### <a name="additional-use-cases"></a>Другие варианты использования
- **Игры.** Вам нужны суперспособности? Вам сюда! Заставьте взглядом голограмму летать. Стреляйте лазерными лучами из глаз. Превратите противников в камни или заморозьте их! Примените рентгеновское зрение, чтобы исследовать здания. Вы ограничены только пределами своего воображения!  

- **Выразительные аватары.** Отслеживание взгляда помогает создавать более выразительные трехмерные аватары, анимируя глаза аватара с учетом того, на что в текущий момент смотрит пользователь. Вы можете усилить выразительность, добавив моргания и подмигивания. 

- **Ввод текста.** Отслеживание взгляда может стать интересной альтернативой для ввода текста без больших усилий, особенно если говорить или печатать неудобно. 


## <a name="eye-tracking-api"></a>API отслеживания взгляда
Прежде чем углубляться в подробные рекомендации по разработке функций с поддержкой описываемой здесь функции, мы хотим кратко перечислить возможности средства отслеживания взгляда в HoloLens 2. [API отслеживания глаз](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) можно использовать через `Windows.Perception.People.EyesPose`. Он предоставляет разработчику сведения об одном взгляде (исходная точка и направление).
Средство отслеживания глаз предоставляет данные с частотой около _30 кадров/с_.
Прогнозируемое направление взгляда соответствует конусу с отклонением примерно 1,0–1,5 градуса от фактического направления в отношении рассматриваемого объекта. Следует ожидать и учитывать небольшую неточность, добавляя запас для нижней границы. Подробнее мы рассмотрим это ниже. Чтобы отслеживание взгляда работало точно, каждому пользователю нужно пройти калибровку отслеживания взгляда. 

![Оптимальный размер целевого объекта на расстоянии 2 метра](images/gazetargeting-size-1000px.jpg)<br>
*Оптимальный размер целевого объекта на расстоянии 2 метра*


## <a name="eye-gaze-design-guidelines"></a>Рекомендации по проектированию взаимодействия с использованием отслеживания взгляда
Создание взаимодействий, в которых используется нацеливание на основе быстрого перемещения глаз, может оказаться сложной задачей. В этом разделе мы собрали ключевые преимущества и проблемы, которые необходимо учитывать при разработке приложения. 

### <a name="benefits-of-eye-gaze-input"></a>Преимущества отслеживания взгляда
- **Высокая скорость нацеливания**. Мускулы глаз — самые быстрые во всем теле человека. 

- **Низкий уровень усилий**. Физическое перемещение почти не требуется. 

- **Ненавязчивость**. Подобный тип взаимодействия иногда называется "чтением мыслей", так как оценивая движения глаз, система быстро узнает, с каким объектом пользователь намерен взаимодействовать. 

- **Альтернативный канал ввода.** Взгляд может стать значимым источником входных данных, который дополняет ручной и голосовой ввод, ведь функция отслеживания учитывает координацию движений глаз и рук пользователей.

- **Визуальное внимание.** Еще одно важное преимущество — это возможность определить то, на что обращает внимание пользователь. Это полезно в очень разных сценариях, от повышения эффективности при оценке дизайна до создания более интеллектуальных пользовательских интерфейсов и улучшения социальных подсказок при удаленном взаимодействии.

По сути, использование взгляда для ввода данных позволяет быстро и без усилий передавать контекстные сигналы, что особенно эффективно в сочетании с другими методами ввода, такими как *голос* и *жесты руками*, для подтверждения намерений пользователя.


### <a name="challenges-of-eye-gaze-as-an-input"></a>Проблемы с использованием взгляда для ввода данных
Большая мощь означает и большую ответственность: Отслеживание взгляда позволяет создать поистине волшебное взаимодействие с пользователем, который чувствует себя супергероем, но при этом важно помнить и учитывать ограничения и слабости этого метода. Далее мы рассмотрим некоторые *проблемы*, которые нужно учитывать, а также опишем, как их устранять при работе с вводом данных через отслеживание взгляда. 

- **Глаза постоянно "включены"** . Пока у человека открыты веки, глаза постоянно фокусируются на разных объектах окружающей среды. Если вы будете реагировать на каждый взгляд и выполнять какие-то действия, даже когда пользователь случайно задержал взгляд на каком-то объекте, это будет настоящий кошмар!
Поэтому мы рекомендуем сочетать отслеживание взгляда с *голосовыми командами*, *жестами руками*, *нажатиями кнопок* или использовать долгие задержки для выбора целевых объектов.
Это решение также позволяет пользователю свободно рассматривать окружение, не испытывая дискомфорт, в том числе от случайной активации каких-либо действий. Эту проблему важно принимать во внимание при проектировании визуального и звукового отклика целевого объекта на взгляд.
Не перегружайте каналы взаимодействия с пользователем навязчивыми звуками всплывающих элементов или фокусировки. Тонкость очень важна Некоторые рекомендации по этому аспекту мы рассмотрим ниже, когда речь пойдет о проектировании.

- **Наблюдение и управление**. Предположим, вам нужно аккуратно выровнять фотографию на стене. Вы внимательно смотрите на рамку и окружающие объекты, чтобы оценить горизонтальность линий. А теперь подумайте, как это сделать, если вы хотите применить отслеживание взгляда в качестве входного канала для управления перемещением фотографии. Сложно, правда? Этот пример иллюстрирует двойную функцию взгляда, который используется и для получения данных, и для управления. 

- **Изменение фокуса перед щелчком**. Исследования показали, что при быстром выборе целевых объектов взгляд пользователя может сместиться с объекта раньше, чем он выполнит действие рукой (например, щелчок в воздухе). Это означает, что важно уделить особое внимание синхронизации сигналов между быстрым каналом (взгляд) и медленным каналом управления (голос, руки, контроллер).

- **Маленькие целевые объекты**. Знакомо ли вам то ощущение, когда шрифт немного мелковат для комфортного чтения текста? Это напряжение глаз, вызванное постоянными попытками сфокусировать взгляд, приводит к усталости и раздраженности.
Вы можете вызывать такие же ощущения у своих пользователей, если заставите их выбирать в приложении слишком мелкие объекты с помощью отслеживания взгляда.
Чтобы поддерживать приятное и уверенное взаимодействие с пользователем, мы рекомендуем учесть при разработке, что минимальный размер целевых объектов должен быть не менее 2°, а желательно еще больше.

- **Неравномерное перемещение глаз**. Глаза постоянно и очень быстро перемещаются от одного фиксированного положения к другому. Изучая записанный путь перемещения глаз, вы быстро заметите его неравномерность. Глаза движутся очень быстро и импульсивно по сравнению с *направлением головы* и *движениями рук*.  

- **Надежность отслеживания**. Точность отслеживания взгляда может немного ухудшаться при изменении освещенности, пока глаза привыкают к новым условиям.
Это не обязательно учитывать при разработке приложения, как точность не должна становиться хуже указанных выше 2°. Но, возможно, пользователю придется повторно выполнить калибровку. 


### <a name="design-recommendations"></a>Рекомендации по проектированию
Ниже перечислены конкретные рекомендации по проектированию, основанные на описанных выше преимуществах и ограничениях, связанных с отслеживанием взгляда.

1. **Взгляд != направление головы.**
    - **Обдумайте, подходит ли быстрое и неровное перемещение глаз для вашей задачи ввода данных.** Быстрые и неравномерные перемещения глаз отлично подходят для выбора целевых объектов в поле зрения, но плохо применимы для задач с плавными траекториями (например, для рисования или выделения обводкой). Для таких задач лучше использовать движения рук или головы.
  
    - **Не привязывайте к взгляду пользователя никакие объекты напрямую (например, ползунок или курсор).**
Для курсора возникает эффект убегания, связанный с небольшими задержками в отображении сигнала направления взгляда. Для ползунка возникает конфликт между двумя задачами зрения: управление ползунком и проверка правильности расположения перемещаемого объекта. В таких случаях пользователи будут быстро уставать и отвлекаться, особенно если для пользователя плохо откалиброван сигнал. 
  
2. **Сочетайте взгляд с другими входными данными**. Интеграция отслеживания глаз с другими входными данными, такими как жесты рук, голосовые команды или нажатия кнопок, предоставляет целый ряд преимуществ.
    - **Свободное наблюдение.** Так как основной работой глаз остается наблюдение за средой, важно сохранить для пользователей возможность осматриваться без активации обратной связи или действий (визуальных, звуковых и т. п.). 
    Совместное использование отслеживания взгляда с другими источниками данных позволяет плавно переключаться между режимами наблюдения и управления взглядом.
  
    - **Мощный источник информации о контексте**. Использование сведений о том, куда смотрит пользователь при произнесении голосовых команд или выполнении жестов руками, позволяет без труда передавать входные данные в пределах поля зрения. Ниже перечислены примеры таких данных. Команда Put that there позволяет быстро и без усилий выбрать голограмму и поместить ее в другую область сцены, просто просмотрев на объект и место назначения. 

    - **Потребность в синхронизации между несколькими источниками входных данных (проблема изменения фокуса перед щелчком).** При сочетании быстрых перемещений глаз с дополнительными источниками более сложных входных данных (например, длинные голосовые команды или жесты руками) возникает риск отвести глаза от объекта раньше, чем завершится подача дополнительной команды. А значит, при создании собственных элементов управления (например, настраиваемых жестов руками) обязательно фиксируйте момент начала или ожидаемую длительность такого действия, чтобы сопоставлять эти данные с направлением взгляда пользователя в прошлом.
    
3. **Ненавязчивый отклик на действия, полученные с помощью отслеживания взгляда**. Часто бывает полезно предоставлять отклик при взгляде на объект (чтобы пользователь понимал, что система работает, как ожидается), но этот отклик должен быть ненавязчивым. Например, можно слегка выгибать область визуального выделения или медленно перемещать объект (например, слегка увеличивать его размер), чтобы подтверждать правильное определение направления взгляда пользователя, не прерывая при этом текущий рабочий процесс пользователя. 

4. **Старайтесь не использовать нетипичные перемещения глаз для ввода данных.** Не вынуждайте пользователей выполнять конкретные перемещения глаз ("жесты" глазами) для запуска действий в приложении.

5. **Оставьте запас на неточность.** Мы различаем два типа неточностей, которые будут заметны для пользователей. Смещение и дрожание. Для предотвращения смещения проще всего предоставить достаточно большие целевые объекты для взаимодействия (с видимым диаметром не менее 2°, что примерно соответствует ширине ногтя на большом пальце при полностью вытянутой руке (1)). На этом основана следующая рекомендация.
    - Не вынуждайте пользователей выбирать крошечные объекты. Исследования показали, что при достаточно больших целевых объектах (и тщательно продуманной системе) пользователи описывают взаимодействие как легкое и сказочное. Если же целевые объекты становятся слишком маленькими, взаимодействие вызывает у пользователей усталость и раздражение.
   

## <a name="see-also"></a>См. также
* [Направление головы и фиксация](gaze-and-commit.md)
* [Направление головы и взгляда в DirectX](gaze-in-directx.md)
* [Набор средств для смешанной реальности. Отслеживание взгляда в Unity](https://aka.ms/mrtk-eyes)
* [Жесты руками](gestures.md)
* [Голосовой ввод](voice-design.md)
* [Контроллеры движения](motion-controllers.md)
* [Комфорт](comfort.md)
