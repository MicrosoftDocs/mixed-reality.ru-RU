# <a name="speech-sdk-learning-module"></a>Модуль обучения пакета SDK для распознавания речи

В этом руководстве вы создадите приложение смешанной реальности, которое рассматривает использование Cognitive Speech SDK служб с HoloLens 2. После завершения работы с этой серии руководств, можно использовать микрофон устройства транскрипция речи в текст в режиме реального времени, преобразования речи в других языках и использовать функцию намерений пакета SDK для распознавания речи для понимания с помощью голосовых команд искусственного интеллекта.

Цели:

- Узнайте, как интегрировать Azure Speech SDK в приложении HoloLens 2
- Узнайте, как использовать голосовые команды
- Узнайте, как использовать возможности распознавания речи в текст

## <a name="instructions"></a>Инструкция

### <a name="getting-started"></a>начало работы

1. Запустите Unity и создайте новый проект. Введите имя проекта «Модуля обучения пакета SDK для распознавания речи». Выберите расположение, на который будет сохранен проект. Нажмите кнопку «Создать проект».

![Module2Chapter3step1im](images/module4chapter1step1im.PNG)

> Примечание. Убедитесь, что шаблон имеет значение «объемные эффекты», как показано на рисунке выше.

2. Скачайте [смешанной реальности Toolkit](https://github.com/microsoft/MixedRealityToolkit-Unity/releases/download/v2.0.0-RC2/Microsoft.MixedReality.Toolkit.Unity.Foundation-v2.0.0-RC2.unitypackage) Unity пакет и сохраните его в папку на Компьютере. Импорт пакета в проекта Unity. Подробные инструкции о том, как это сделать, см. в разделе [основной модуль занятие](mrlearning-base-ch1.md). 

3. Загрузите и импортируйте Azure [Speech SDK](https://aka.ms/csspeech/unitypackage) пакета набора средств. Импорт пакета Speech SDK, щелкнув «активы», выбрав «Импорт пакета,» выберите «пользовательский пакет». Найдите пакет SDK для распознавания речи, загруженный ранее и откройте его, чтобы начать процесс импорта. 

![Module4Chapter1step3im](images/module4chapter1step3im.PNG)

4. В следующем всплывающем окне нажмите кнопку «Импорт», чтобы начать импорт пакета SDK для распознавания речи. Убедитесь, что все элементы возвращены, как показано на рисунке ниже.

![Module4Chapter1step4im](images/module4chapter1step4im.PNG)


5. Скачайте [Lunarcom](https://github.com/levilais/Speech-SDK-Module/raw/master/Speech SDK Module/Lunarcom.unitypackage) пакета ОС. Пакет средств Lunarcom является коллекцией активы и скрипты, разработанные для этой серии урок, чтобы продемонстрировать Практическое применение Azure Speech SDK. Это конечная точка голосовых команд, в конечном счете будут взаимодействовать со качества сборки лунного модуля, разработанный в [учебника базового модуля.](mrlearning-base-ch6.md)
6. Импорт пакета средств Lunarcom в проекте Unity, выполнив аналогичные действия, предпринятые, чтобы импортировать смешанной реальности Toolkit и пакета SDK для распознавания речи.
7. Настройка набора средств смешанной реальности (MRTK). Для этого щелкните на панели «Смешанной реальности Toolkit» в правом верхнем углу окна, затем выберите «Добавить сцены и настройка».

![Module4Chapter1step7im](images/module4chapter1step7im.PNG)

8. Сцена будет теперь содержит несколько новых пунктов из MRTK. Сохраните под другим именем, щелкнув «файл» в сцену нажмите «Сохранить как» и назовите в сцену «SpeechScene». 

   > Примечание. Если нажать кнопку play на сцена после добавления MRTK в проект, и не переходит в режим «play», может потребоваться перезапуск Unity. 

9. Объект «MixedRealityToolkit» выбран в иерархии нажмите кнопку «скопировать и адаптировать» на панели инспектора.

![Module4Chapter1step9im](images/module4chapter1step9im.PNG)

10. Также на панели инспектора (с «MixedRealityToolkit» объекта, выбранного в иерархии), можно отключите систему диагностики, снимите этот флажок справа от «Включить систему диагностики».

![Module4Chapter1step10im](images/module4chapter1step10im.PNG)

11. На панели «проект» разверните папку «Lunarcom» и перетащите prefab «Lunarcom_Base» в иерархии.

![Module4Chapter1step11im](images/module4chapter1step11im.PNG)

12. Выберите объект «Lunarcom_Base» в иерархии и убедитесь, что позиция для x = 0, y = 0 и z = 0, а также поворот, значение x = 0, y = 0 и z = 0. Установите масштаб для чтения x = 0.008, y = 0.008 и z = 0,01.

![Module4Chapter1step12im](images/module4chapter1step12im.PNG)

13. Нажмите кнопку «Добавить компонент» и найдите и выберите «LunarcomController.» Этот сценарий входит в пакет ресурсов Lunarcom, импортированный на шаге 6.

![Module4Chapter1step13im](images/module4chapter1step13im.PNG)

14. Для подключения приложения к Azure Cognitive Services, укажите «ключ подписки» также называется «API-ключ» для службы распознавания речи. Следуйте инструкциям в [эту ссылку](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/get-started) получить ключ бесплатную подписку. После получения ключа подписки, введите его в поле «Ключ API службы распознавания речи» компонента «LunarcomController» на панели инспектора, как показано на рисунке ниже.

15. Укажите регион, выбранное при оформлении подписки для ключа подписки в поле «Регион службы речи» компонента «LunarcomController» на панели инспектора.

![Module4Chapter1step15im](images/module4chapter1step15im.PNG)

16. В иерархии разверните объект «Lunarcom_Base», щелкнув стрелку слева от него, а затем используйте его для его дочернего объекта, «Терминал», как показано на рисунке ниже.

17. Когда выбран «Lunarcom_Base», щелкните и перетащите «Lunarcom Text» из иерархии в слоте «Выходной текст» в компоненте «LunarcomController» на панели инспектора, как показано на рисунке ниже.
18. Теперь сделаем то же самое, с объектом «Терминал» в области «терминал» и объект «Light подключения» в слоте «Controller свет подключения».

![Module4Chapter1step18im](images/module4chapter1step18im.PNG)

19. Щелкните стрелку рядом с разделе «Lunarcom кнопки» скрипт «LunarcomController» на панели инспектора и измените размер на 3 и нажмите клавишу ВВОД или Return на клавиатуре. В результате отображаются три новые поля «Элемент».

![Module4Chapter1step19im](images/module4chapter1step19im.PNG)

20. Разверните узел «Кнопок Lunarcom», щелкнув стрелку рядом с ним в иерархии и, используя тот же процесс, как описано выше, перетащите объекты gameobject Mic, вспомогательные и ракеты в ссылку на элемент 0, 1 и 2 соответственно в компоненте «LunarcomController» в панели инспектора. 

![Module4Chapter1step18im](images/module4chapter1step20im.PNG)

21. Выберите объект «Lunarcom_Base» в иерархии. Нажмите кнопку «Добавить компонент» на панели инспектора и найдите и выберите «LunarcomWakeWordRecognizer.»

![Module4Chapter1step18im](images/module4chapter1step21im.PNG)

22. В слоте «Пробуждения слово» введите «Активировать терминалов». Кроме того в слоте «Отклонить слово», введите «Отклонить терминалов».

![Module4Chapter1step18im](images/module4chapter1step22im.PNG)

## <a name="congratulations"></a>Поздравляем!

Настройки распознавания голоса в приложении на платформе Azure! Запустите приложение, чтобы убедиться, что все работает правильно. Начните с о том, слово пробуждения, введенного в шаге 22, «Активировать терминалов». Выберите кнопку "микрофон", чтобы запустить распознавание речи и начните говорить. Вы увидите слова расшифрованной в окне терминала, так как вы говорите. Нажмите кнопку "микрофон" во второй раз, чтобы остановить распознавания голоса. Скажем, «Отклонить терминалов» скрыть Lunarcom терминала. В следующем уроке вы узнаете как динамически переключаться с помощью распознавания голоса на основе устройств, для ситуаций, где Azure speech SDK недоступен из-за 2 HoloLens, находится в автономном режиме.

[Следующий урок. Занятие Speech SDK 2](mrlearning-speechSDK-ch2.md)

