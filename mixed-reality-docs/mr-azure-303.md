---
title: Г-н и 303 Azure - естественного языка, основные сведения о (LUIS)
description: Выполните этот курс, чтобы узнать, как реализовать приложение смешанной реальности Azure Language Understanding Intelligence Service (LUIS).
author: drneil
ms.author: jemccull
ms.date: 07/04/2018
ms.topic: article
keywords: Azure, смешанной реальности, academy, unity, учебник, api, интеллектуальная служба анализа языка, luis, hololens, создающий эффект присутствия, виртуальной реальности
ms.openlocfilehash: fb00fe9079e49a7ada507e7407ef45fa7eeb0d7e
ms.sourcegitcommit: 384b0087899cd835a3a965f75c6f6c607c9edd1b
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/12/2019
ms.locfileid: "59603072"
---
>[!NOTE]
>Учебники Academy реальности Mixed были разработаны с HoloLens (1-го поколения) и смешанной реальности Иммерсивную в виду.  Таким образом мы думаем, что это важно, чтобы эти учебники на месте для разработчиков, которые по-прежнему необходимы сведения при разработке приложений для этих устройств.  Эти руководства будут **_не_** дополняться последние наборы инструментов или взаимодействия, используемых для HoloLens 2.  Они будут сохранены, чтобы продолжить работу на поддерживаемых устройствах. Будет существовать новую серию учебников, которые будут опубликованы в будущем, демонстрируют способ разработки для HoloLens 2.  Это уведомление будет обновляться со ссылкой на эти руководства, когда они учитываются.

<br>

# <a name="mr-and-azure-303-natural-language-understanding-luis"></a>Г-н и Azure 303: Понимание естественного языка (LUIS)

В рамках этого курса вы узнаете, как интегрировать в приложение смешанной реальности, с помощью Azure Cognitive Services, с помощью API понимания языка Language Understanding.

![Результат лаборатории](images/AzureLabs-Lab3-000.png)

*Language Understanding (LUIS)* — это служба Microsoft Azure, которую предоставляет приложениям возможность вносить значения из введенных данных, например, посредством извлечения, что пользователь может возникнуть, по их собственным словам. Это достигается с помощью машинного обучения, которое распознает и изучает входные данные, а затем можно ответить с помощью соответствующих, подробную информацию. Дополнительные сведения см. в статье [страницы Azure Language Understanding (LUIS)](https://azure.microsoft.com/services/cognitive-services/language-understanding-intelligent-service/).

После выполнения этого курса, у вас будет приложение иммерсивных гарнитуры смешанной реальности, которое сможет выполнить следующие:

1.  Запись речи ввода пользователя, с помощью микрофона, подключенного к иммерсивных гарнитуры. 
2.  Отправьте записанный диктовки *Azure Language Understanding Intelligent Service* (*LUIS*). 
3.  Иметь LUIS извлечения, то есть от отправки сведений, который будет анализироваться и пытаться определить цели запроса пользователя будут внесены.

Разработки будет включать создание приложения, где пользователь сможет использовать голосовые и/или помощи, чтобы изменить размер и цвет объекты на сцене. Использование контроллеров движения здесь не рассматриваются.

В приложении зависит от пользователя о том, как интегрировать результаты проектированию. Этот курс призван научить позволяют интегрировать службу Azure с проектом Unity. Это задание может использовать знание, что вы получите из этого курса можно улучшить приложение смешанной реальности.

Приготовьтесь Train LUIS несколько раз, который рассматривается в [Глава 12](#chapter-12--improving-your-luis-service). Дополнительные случаи, когда будет обучена LUIS позволит добиться лучших результатов.

## <a name="device-support"></a>Поддержка устройств

<table>
<tr>
<th>Курс</th><th style="width:150px"> <a href="hololens-hardware-details.md">HoloLens</a></th><th style="width:150px"> <a href="immersive-headset-hardware-details.md">Иммерсивную</a></th>
</tr><tr>
<td>Г-н и Azure 303: Понимание естественного языка (LUIS)</td><td style="text-align: center;"> ✔️</td><td style="text-align: center;"> ✔️</td>
</tr>
</table>

> [!NOTE]
> Хотя этот курс основное внимание уделяется Windows Mixed Reality иммерсивную (VR), можно также применить полученные знания в этом курсе для Microsoft HoloLens. При выполнении, а также курс, вы увидите заметки обо всех изменениях, может потребоваться использовать для поддержки HoloLens. При использовании HoloLens, вы можете заметить некоторые echo во время записи голоса.

## <a name="prerequisites"></a>Предварительные требования

> [!NOTE]
> Этот учебник предназначен для разработчиков, имеющих минимальный опыт с помощью Unity и C#. Также имейте в виду, что предварительные требования и инструкции в этом документе представляют новые были протестированы и проверены на момент написания статьи (мая 2018 г.). Вы можете свободно использовать последнюю программное обеспечение, как указано в [установить средства](install-the-tools.md) статьи, то, что следует не полагать, что информация в этом курсе будет точным соответствием что можно найти в новой версии по сравнению приведенных ниже .

Рекомендуется следующее оборудование и программное обеспечение для этого курса:

- На Компьютере, разработки [совместимы с Windows Mixed Reality](https://support.microsoft.com/help/4039260/windows-10-mixed-reality-pc-hardware-guidelines) для иммерсивных разработки Гарнитура (VR)
- [Windows 10 Fall Creators Update (или более поздней версии) с включенным режимом разработчика](install-the-tools.md)
- [Последний пакет SDK Windows 10](install-the-tools.md)
- [Unity 2017.4](install-the-tools.md)
- [Visual Studio 2017](install-the-tools.md)
- Объект [иммерсивных (VR) гарнитуры смешанной реальности Windows](immersive-headset-hardware-details.md) или [Microsoft HoloLens](hololens-hardware-details.md) с включенным режимом разработчика
- Наушники с помощью встроенного микрофона (если гарнитура отсутствует встроенный mic, а также докладчиков)
- Доступ к Интернету для настройки Azure и извлечения LUIS

## <a name="before-you-start"></a>Прежде чем начать

1.  Чтобы избежать возникновения проблем сборки этого проекта, настоятельно рекомендуется создать проект, упомянутые в этом руководстве в корень или рядом с корневой папки (пути к папкам long может привести к проблемам во время сборки). 
2.  Чтобы разрешить компьютер, чтобы включить режим диктовки, перейдите к **параметры Windows > конфиденциальности > речи, рукописного ввода и введя** и нажмите кнопку **Включение службы распознавания речи и ввода предложения**.
3.  Код в этом руководстве, позволит вам требуется записать **микрофон устройством по умолчанию** на локальном компьютере. Убедитесь, что устройства "микрофон" по умолчанию имеет значение, которое вы хотите использовать для записи голоса.
4.  Если ваш гарнитура имеет встроенный микрофон, убедитесь, что параметр *«После я wear Мой гарнитуры, перейдите на mic гарнитура»* включен *смешанной реальности портала* параметры.

    ![Настройка иммерсивных гарнитура](images/AzureLabs-Lab3-00.png)

## <a name="chapter-1--setup-azure-portal"></a>Глава 1 – Настройка портала Azure

Чтобы использовать *Language Understanding* службы в Azure, необходимо настроить экземпляр службы, чтобы сделать доступными для приложения.

1.  Войдите в [портала Azure](https://portal.azure.com).

    > [!NOTE]
    > Если у вас еще нет учетной записи Azure, необходимо будет создать его. Если вы следуете этим руководством, аудитории или лаборатории ситуации, попросите преподавателем или из прокторов для сведения о настройке новой учетной записи.

2.  После входа в систему щелкните **New** в левом верхнем углу, а поиск *Language Understanding*и нажмите кнопку **ввод**. 

    ![Создание ресурса LUIS](images/AzureLabs-Lab3-01.png)

    > [!NOTE]
    > Слово **New** может были заменены **создать ресурс**, в новых порталов.
 
3.  Новая страница справа будет предоставить описание службы Language Understanding. В нижней левой части этой страницы выберите **создать** кнопку, чтобы создать экземпляр этой службы.

    ![Создание службы LUIS - Юридическая информация](images/AzureLabs-Lab3-02.png)
 
4.  После нажатия на создание:

    1. Вставить нужный **имя** для данного экземпляра службы.
    2. Выберите **подписки**.
    3. Выберите **Ценовая** подходит для вас, если это первое времени на создание *службы LUIS*, уровень "бесплатный" (с именем F0) должны быть доступны для вас. Бесплатный выделение должно быть более чем достаточно для этого курса.
    4. Выберите **группы ресурсов** или создайте новую. Группа ресурсов предоставляет способ отслеживания, контроля доступа, Подготовка и управление выставлением счетов для набора средств Azure. Рекомендуется хранить все службы Azure, связанные с один проект (например, такие как этих курсов) для распространенных группы ресурсов). 

        > Если вы хотите получить дополнительные сведения о группах ресурсов Azure, пожалуйста, [откройте статью группы ресурсов](https://docs.microsoft.com/azure/azure-resource-manager/resource-group-portal).

    5. Определить **расположение** для группы ресурсов (Если вы создаете новую группу ресурсов). Расположение оптимально подойдет в регионе, в котором приложение будет работать. Некоторые ресурсы Azure доступны только в определенных регионах.
    6. Также необходимо будет подтвердить, что мы рассмотрели, положения и условия, применяемые к этой службе.
    7. Щелкните **Создать**.

        ![Создание службы LUIS — ввод данных пользователем](images/AzureLabs-Lab3-03.png)
 
5.  Когда вы перейдете на **создать**, вы получите ожидания службы должен быть создан, это может занять около минуты.
6.  Уведомление будет отображаться на портале, после создания экземпляра службы. 
 
    ![Новый образ уведомлений Azure](images/AzureLabs-Lab3-04.png)

7.  Щелкните уведомление, чтобы изучить ваш новый экземпляр службы.

    ![Уведомление о создании успешно ресурсов](images/AzureLabs-Lab3-05.png)
 
8.  Нажмите кнопку **перейти к ресурсу** кнопки в уведомлении для просмотра в новом экземпляре службы. Откроется в новом экземпляре службы LUIS. 
 
    ![Доступ к ключам LUIS](images/AzureLabs-Lab3-06.png)

9.  В этом руководстве описано приложение должно выполнять вызовы в службу, которая осуществляется с помощью ключа подписки вашей службы.
10. Из *быстрого запуска* странице из вашей *LUIS API* службы, перейдите к первому шагу *получите ключи*и нажмите кнопку **ключи** (вы также можете добиться этого, щелкнув синий гиперссылки ключи, расположенный в меню навигации служб, обозначенное с помощью значок ключа). Это позволит службе *ключи*.
11. Сделайте копию один из отображаемых разделов, так как он потребуется позже в проекте. 
12. В *службы* нажмите кнопку *портал Language Understanding* перенаправление на веб-страницу, который будет использоваться для создания новой службы, в приложении LUIS. 

## <a name="chapter-2--the-language-understanding-portal"></a>Глава 2 – на портал Language Understanding

В этом разделе вы узнаете, как сделать приложения LUIS на портале LUIS. 

> [!IMPORTANT]
> Имейте в виду, что настройка *сущностей*, *намерения*, и *фразы* в этой главе является только первым шагом при создании вашей службы LUIS: также необходимо будет переобучить службу, несколько раз, поэтому для обеспечивают более высокую точность. Повторное обучение службы рассматривается в [последняя глава](#chapter-12--improving-your-luis-service) этого курса, поэтому убедитесь, завершить его.

1.  При достижении *портал Language Understanding*, может потребоваться войти в систему, если вы еще не сделали, с теми же учетными данными, как портал Azure. 

    ![Страница входа LUIS](images/AzureLabs-Lab3-07.png)
 
2.  Это при первом использовании LUIS, необходимо будет выполнить прокрутку вниз до нижней части начальной страницы, найдите и щелкните **приложения создайте LUIS** кнопки.

    ![Создание страницы приложения LUIS](images/AzureLabs-Lab3-08.png)
 
3.  После входа в систему, щелкните **Мои приложения** (Если вы не в этом разделе в данный момент). Вы можете нажать на **создать приложение**.

    ![ЛУИС - образ приложения](images/AzureLabs-Lab3-09.png)
 
4.  Присвойте приложению *имя*.
5.  Если приложения должны понимать языке, отличном от английского, следует изменить *языка и региональных параметров* для соответствующего языка.
6.  Здесь вы можете также добавить *описание* для нового приложения LUIS.

    ![ЛУИС - Создание нового приложения](images/AzureLabs-Lab3-10.png)

7.  После нажатия кнопки **сделать**, необходимо ввести *построения* новой странице *LUIS* приложения.
8.  Существует несколько важных понятий здесь:

    -   *Намерение*, представляющий метод, который будет вызываться после запроса от пользователя. *НАМЕРЕНИЕ* может иметь один или несколько *СУЩНОСТЕЙ*.
    -   *Сущность*, входит в состав запроса, который описывает сведения, относящиеся к *НАМЕРЕНИЕ*.
    -   *Фразы продолжительностью*, предоставляются примеры запросов разработчиком, LUIS, будет использовать для подготовки.

Если эти понятия не вполне снимите, не волнуйтесь, так как этот курс прояснить их далее в этой главе.

Сначала путем создания *сущностей* необходимые для создания этого курса.

9.  В левой части страницы щелкните *сущностей*, затем щелкните **создать новую сущность**.

    ![Создание новой сущности](images/AzureLabs-Lab3-11.png)

10. Вызовите новую сущность *цвет*, установите для него *простой*, нажмите клавишу **сделать**.

    ![Создание простого объекта - цвет](images/AzureLabs-Lab3-12.png)
 
11. Повторите эту процедуру для создания трех (3) Дополнительные простые сущности с именем:

    -   *преобразования*
    -   *уменьшить*
    -   *target*

Результат должен выглядеть как на следующем рисунке:

![Результат создания сущности](images/AzureLabs-Lab3-13.png)
 
На этом этапе можно начать создавать *Intents*. 

> [!WARNING]
> Не удаляйте **None** намерение.

12. В левой части страницы щелкните **Intents**, затем щелкните **создать новый намерение**.

    ![Создание новых инструментов intents](images/AzureLabs-Lab3-14.png)

13. Вызовите новый *намерение* **ChangeObjectColor**.

    > [!IMPORTANT]
    > Это *намерение* имя используется внутри кода далее в этом курсе, поэтому для получения наилучших результатов используйте это имя предоставленное.

После того как вы убедились, имя, которое вы будете перенаправлены на страницу намерения.

![ЛУИС - намерения страницы](images/AzureLabs-Lab3-15.png)

Вы заметите, что есть текстовое поле, запрашивающее типу, 5 или более разных *фразы*.

> [!NOTE]
> LUIS преобразует все фразы в нижний регистр.

14. Вставьте следующий текст *Utterance* в верхнем поле (в настоящее время с текстом *тип около 5 примеры...* ) и нажмите клавишу **ввод**:

```
The color of the cylinder must be red
```

Можно будет заметить, что новый *Utterance* отобразится в списке ниже.

После выполнения вставьте следующие фразы шести (6):

```
make the cube black

make the cylinder color white

change the sphere to red

change it to green

make this yellow

change the color of this object to blue
```

Для каждого Utterance, которую вы создали необходимо определить, какие слова должна использоваться LUIS как сущности. В этом примере необходимо пометить все цвета как *цвет* сущности и всех возможных ссылку на объект как *целевой* сущности.

15. Чтобы сделать это, попробуйте щелкнуть слово *цилиндра* в первый Utterance и выберите *целевой*.

    ![Определение целевых объектов Utterance](images/AzureLabs-Lab3-16.png)
 
16. Теперь щелкните слово *red* в первый Utterance и выберите *цвет*.

    ![Идентификация сущностей Utterance](images/AzureLabs-Lab3-17.png)
 
17. Метка следующей строке, кроме того, где *куба* должно быть *целевой*, и *черной* должно быть *цвет*. Обратите также внимание на использование слов *«this»*, *«it»*, и *«этот объект»*, которой предоставляются, так что иметь отслеживании целевой типы доступных также. 

18. Повторите описанный выше процесс, все фразы иметь сущности меткой. См. в разделе под изображением, если вам нужна помощь.

    > [!TIP]
    > При выборе слов, которые они помечены как сущности:
    > - Для отдельных слов просто щелкните их.
    > - В наборе два или несколько слов щелкните в начале, а затем в конце набора.

    > [!NOTE]
    > Можно использовать *представление маркеры* кнопки-переключателя для переключения между **сущностей или просмотре маркеры**!

19. Результаты должны быть, как показано на рисунке ниже, отображение **сущностей или просмотре маркеры**:

    ![Маркеры & представлений сущностей](images/AzureLabs-Lab3-18.png)
  
20. После этого нажмите клавишу **Train** кнопку в правой верхней части страницы и дождитесь небольшой индикатор round ее, чтобы стать зеленым. Это означает, что LUIS успешного обучения распознавать этой цели.

    ![Обучение LUIS](images/AzureLabs-Lab3-19.png)
 
21. В качестве упражнения для вас создать новый намерения с именем **ChangeObjectSize**, в которых используются сущности *целевой*, *преобразования*, и *уменьшать их размер*.
22. Следуя тому же процессу, как предыдущим намерением, вставьте следующие фразы 8 (восьми) для *размер* изменить:

    ```
    increase the dimensions of that

    reduce the size of this

    i want the sphere smaller

    make the cylinder bigger

    size down the sphere

    size up the cube

    decrease the size of that object

    increase the size of this object
    ```

23. Результат должен быть, как показано на рисунке ниже:

    ![Настройка маркеров ChangeObjectSize / сущностей](images/AzureLabs-Lab3-20.png) 

24. Один раз обоих намерения **ChangeObjectColor** и **ChangeObjectSize**, будут созданы и обучения, щелкните **публикации** кнопку в верхней части страницы.

    ![Публикация службы LUIS](images/AzureLabs-Lab3-21.png)

25. На *публикации* страниц будет финализировать и публикация приложения LUIS, таким образом, чтобы он доступен в коде.

    1. Отставить раскрывающегося *публиковать в* как **рабочей**.
    2. Задайте *часовой пояс* в местный часовой пояс.
    3. Установите флажок **Include все прогнозируемые оценки намерения**.
    4. Щелкните **опубликовать рабочий слот**.

        ![Параметры публикации](images/AzureLabs-Lab3-22.png)

26. В разделе *ресурсы и ключи*:

    1.  Выберите регион, установленные для экземпляра службы на портале Azure.
    2.  Обратите внимание, **Starter_Key** элемент ниже, игнорируйте его.
    3.  Щелкните **добавить ключ** и вставить *ключ* , полученный на портале Azure при создании своего экземпляра службы. В тот же пользователь, вошедший в Azure и портала LUIS, вам будут предоставлены раскрывающиеся меню для *имя_клиента*, *Имя_подписки*и *ключ* вы хотите использовать () как было введено ранее на портале Azure будет тем же именем.

    > [!IMPORTANT] 
    > Под *конечной точки*, сделайте копию конечной точки, соответствующее ключу вставки, вскоре он будет использоваться в коде.
 
## <a name="chapter-3--set-up-the-unity-project"></a>Глава 3 – Настройка проекта Unity

Следующие запущена типичный набор для разработки с помощью смешанной реальности и, таким образом, — это хороший шаблон для других проектов.

1.  Откройте *Unity* и нажмите кнопку **New**. 

    ![Начните новый проект Unity.](images/AzureLabs-Lab3-24.png)

2.  Введите имя проекта Unity, теперь нужно вставить **MR_LUIS**. Убедитесь, что тип проекта присваивается **3D**. Задайте **расположение** в другое место, наиболее подходящего для вас (Помните, что лучше, чем ближе к корневые каталоги). Щелкните **создать проект**.

    ![Укажите сведения для нового проекта Unity.](images/AzureLabs-Lab3-25.png)
 
3.  С помощью Unity откройте, стоит проверки по умолчанию **редактор сценариев** присваивается **Visual Studio**. Откройте для редактирования > Параметры и затем в окне «Новый» перейдите к **внешние средства**. Изменение **внешнего редактора скриптов** для **Visual Studio 2017**. Закрыть **предпочтения** окна.

    ![Обновите настройки редактора скриптов.](images/AzureLabs-Lab3-26.png)
 
4.  Перейдите к **файл > Параметры сборки** и переключитесь на платформе, которое **универсальной платформы Windows**, щелкнув **переключения платформы** кнопки.

    ![Создавайте окно "Параметры", переключить платформу для универсальной платформы Windows.](images/AzureLabs-Lab3-27.png)
 
5.  Перейдите к **файл > Параметры сборки** и убедитесь, что:

    1. **Целевое устройство** присваивается **любого устройства**

        > Microsoft HoloLens, задайте **целевое устройство** для *HoloLens*.

    2. **Тип сборки** присваивается **D3D**
    3. **Пакет SDK для** присваивается **самую новую установленную**
    4. **Версия Visual Studio** присваивается **самую новую установленную**
    5. **Сборка и запуск** присваивается **локального компьютера**
    6. Сохраните сцены и добавить его к сборке.

        1. Это сделать, выбрав **добавьте откройте сцены**. Сохранение окно будет отображаться.
        
            ![Нажмите кнопку Добавить кнопку open сцены](images/AzureLabs-Lab3-28.png)

        2. Создайте новую папку и все будущие, сцены, затем выберите **новую папку** кнопку, чтобы создать новую папку, назовите его **сцены**.

            ![Создание новой папки scripts](images/AzureLabs-Lab3-29.png)

        3. Откройте только что созданный **сцены** папку, а затем в *имя файла*: текстовое поле, тип **MR_LuisScene**, нажмите клавишу **Сохранить**.

            ![Присвойте имя новой сцены.](images/AzureLabs-Lab3-30.png)

    7. Для остальных параметров, в *параметры построения*, следует оставить значение по умолчанию сейчас.

6. В *параметры построения* щелкните **параметры проигрывателя** кнопки, откроется панель связанных в пространстве где *инспектор* находится. 

    ![Открытие параметров проигрывателя.](images/AzureLabs-Lab3-31.png) 
 
7. В этой панели необходимо проверить некоторые настройки:

    1. В **другие параметры** вкладке:

        1. **Версия среды выполнения сценариев** должно быть **стабильной** (.NET 3.5 эквивалент).
        2. **Создание сценариев серверной части** должно быть **.NET**
        3. **Уровень совместимости API** должно быть **.NET 4.6**

            ![Обновите другие параметры.](images/AzureLabs-Lab3-32.png)
      
    2. В рамках **параметров публикации** в списке **возможности**, проверьте:

        1. **internetClient**
        2. **"Микрофон"**

            ![Обновление параметров публикации.](images/AzureLabs-Lab3-33.png)

    3. Далее панели в **XR параметры** (под **параметры публикации**), деления **поддерживается виртуальной реальности**, убедитесь, что **смешанной реальности SDK Windows**  добавляется.

        ![Обновление параметров R X.](images/AzureLabs-Lab3-34.png)

8.  Вернитесь в *параметры построения* _Unity C#_  проектов больше не отображается серым, установите флажок рядом с это. 
9.  Закройте окно Параметры построения.
10. Сохраните сцену и проекта (**ФАЙЛ > Сохранить СЦЕНУ / FILE > Сохранить ПРОЕКТ**).

## <a name="chapter-4--create-the-scene"></a>Глава 4 – Create сцены

> [!IMPORTANT]
> Если вы хотите пропустить *Настройка Unity* компонент курс и по-прежнему непосредственно в код, вы можете загрузить [.unitypackage](https://github.com/Microsoft/HolographicAcademy/raw/Azure-MixedReality-Labs/Azure%20Mixed%20Reality%20Labs/MR%20and%20Azure%20303%20-%20Natural%20language%20understanding/Azure-MR-303.unitypackage), импортировать его в проект в качестве [пользовательского пакета ](https://docs.unity3d.com/Manual/AssetPackages.html), а затем продолжить из [Глава 5](#chapter-5--create-the-microphonemanager-class). 

1.  Щелкните правой кнопкой мыши пустую часть области *панели иерархии*в разделе **трехмерный объект**, добавьте **плоскости**.

    ![Создайте плоскость.](images/AzureLabs-Lab3-35.png)

2.  Имейте в виду, если щелкнуть правой кнопкой в *иерархии* еще раз, чтобы создать дополнительные объекты, если у вас есть последнего выделенного объекта, выбранного объекта должен стать родительским нового объекта. Избегайте этого, щелчок левой кнопкой мыши в пустое место в иерархии, а затем щелкните правой кнопкой мыши.

3.  Повторите описанные выше действия, чтобы добавить следующие объекты:

    1. *Sphere*
    2. *Цилиндр*
    3. *Куб*
    4. *Трехмерный текст*

4.  Итоговый сцены *иерархии* должно быть, как показано на рисунке ниже:

    ![Настройка иерархии сцены.](images/AzureLabs-Lab3-36.png)
 
5.  Щелчок левой кнопкой на **Main Camera** для его выбора, рассмотрим *панели Инспектора* вы увидите объекта Camera со всеми его компонентов.
6.  Щелкните **добавить компонент** расположенную в нижней части *панели Инспектора*.

    ![Добавление аудио источника](images/AzureLabs-Lab3-37.png)
 
7.  Поиск компонента, который называется *источника аудио*, как показано выше.
8.  Также убедитесь, что *преобразования* компонент Main Camera присвоено (0,0,0), это можно сделать, нажав клавишу **шестеренки** значок рядом с камеры *преобразования* компонента и выбрав **сбросить**. *Преобразования* компонент должен выглядеть так:

    1.  *Позиция* присваивается **0, 0, 0**.
    2.  *Поворот* присваивается **0, 0, 0**.

    > [!NOTE] 
    > Для Microsoft HoloLens, необходимо также изменить следующим образом, являются частью **камеры** компонент, который находится на вашей **Main Camera**:
    > - **Очистите флаги:** Сплошным цветом.
    > - **Фон** "черная, альфа-канал 0" — Hex цвет: #00000000.

9.  Щелчок левой кнопкой на **плоскости** чтобы выбрать его. В *панели Инспектора* задать *преобразования* компонент со следующими значениями:

    |       | Преобразование - *позиции* |       |
    |:-----:|:----------------------:|:-----:|
    | **X** | **Y**                  | **Z** |
    | 0     | -1                     | 0     |


10. Щелчок левой кнопкой на **Sphere** чтобы выбрать его. В *панели Инспектора* задать *преобразования* компонент со следующими значениями:

    |       | Преобразование - *позиции* |       |
    |:-----:|:----------------------:|:-----:|
    | **X** | **Y**                  | **Z** |
    | 2     | 1                      | 2     |

11. Щелчок левой кнопкой на **цилиндра** чтобы выбрать его. В *панели Инспектора* задать *преобразования* компонент со следующими значениями:

    |       | Преобразование - *позиции* |       |
    |:-----:|:----------------------:|:-----:|
    | **X** | **Y**                  | **Z** |
    | -2    | 1                      | 2     |

12. Щелчок левой кнопкой на **куба** чтобы выбрать его. В *панели Инспектора* задать *преобразования* компонент со следующими значениями:

    |        | Преобразование - *позиции* |       |  \| |       | Преобразование - *поворота* |       |
    |:------:|:----------------------:|:-----:|:---:|:-----:|:----------------------:|:-----:|
    | **X** | **Y**                   | **Z** |  \| | **X** | **Y**                  | **Z** |
    | 0     | 1                       | 4     |  \| | 45    | 45                     | 0     | 

13. Щелчок левой кнопкой на **новый текст** объекта, чтобы выбрать его. В *панели Инспектора* задать *преобразования* компонент со следующими значениями:

    |       | Преобразование - *позиции* |       |  \| |       | Преобразование - *масштабирования* |       |
    |:-----:|:----------------------:|:-----:|:---:|:-----:|:-------------------:|:-----:|
    | **X** | **Y**                  | **Z** |  \| | **X** | **Y**               | **Z** |
    | -2    | 6                      | 9     |  \| | 0.1   | 0.1                 | 0.1   | 

14. Изменение **размер шрифта** в **Mesh текст** компонент **50**.
15. Изменение *имя* из **Mesh текст** объект **Диктовка текста**.

    ![Создание трехмерного объекта текста](images/AzureLabs-Lab3-38.png)
 
16. Структуры вашей иерархии панели теперь должна выглядеть так:

    ![текст mesh в представлении сцены](images/AzureLabs-Lab3-38b.png)


17. Окончательный сцены должен выглядеть как на следующем рисунке:

    ![Представление сцены.](images/AzureLabs-Lab3-39.png)
    
 
## <a name="chapter-5--create-the-microphonemanager-class"></a>Глава 5 – создать класс MicrophoneManager

Первый скрипт, который вы собираетесь создать *MicrophoneManager* класса. После этого вы создадите *LuisManager*, *поведений* класса и, наконец *помощи* класс (вы можете создать все эти now, то, что будет рассматриваться как связаться с каждой главы).

*MicrophoneManager* класс отвечает за:

-   Обнаружение записи устройству, подключенному к гарнитуры или machine (выбирается по умолчанию).
-   Запись звука (голос) и использовать режим диктовки сохранит их в виде строки.
-   После приостановлена голоса, отправки диктофон, чтобы *LuisManager* класса. 

Для создания этого класса: 

1.  Щелкните правой кнопкой мыши в *проекта панели*, **Создать > Папка**. Вызовите папке **сценариев**. 

    ![Создайте папку Scripts.](images/AzureLabs-Lab3-40.png)
 
2.  С помощью **сценариев** папка создана, дважды щелкните его, чтобы открыть. Затем, внутри этой папки, щелкните правой кнопкой мыши **Создать > C# сценарий**. Назовите сценарий *MicrophoneManager*. 

3.  Дважды щелкните *MicrophoneManager* чтобы открыть его с *Visual Studio*.
4.  Добавьте следующие пространства имен в начало файла:

    ```csharp
        using UnityEngine;
        using UnityEngine.Windows.Speech;
    ```

5.  Затем добавьте следующие переменные внутри *MicrophoneManager* класса:

    ```csharp
        public static MicrophoneManager instance; //help to access instance of this object
        private DictationRecognizer dictationRecognizer;  //Component converting speech to text
        public TextMesh dictationText; //a UI object used to debug dictation result
    ``` 

6.  Код для *Awake()* и *Start()* методы теперь должен быть добавлен. Это будет вызываться при инициализации класса.

    ```csharp
        private void Awake()
        {
            // allows this class instance to behave like a singleton
            instance = this;
        }

        void Start()
        {
            if (Microphone.devices.Length > 0)
            {
                StartCapturingAudio();
                Debug.Log("Mic Detected");
            }
        }
    ```
 
7.  Теперь вам потребуется метод, который приложение использует для запуска и остановки записи голоса и передать его в *LuisManager* класса, который вы создадите в ближайшее время. 

    ```csharp
        /// <summary>
        /// Start microphone capture, by providing the microphone as a continual audio source (looping),
        /// then initialise the DictationRecognizer, which will capture spoken words
        /// </summary>
        public void StartCapturingAudio()
        {
            if (dictationRecognizer == null)
            {
                dictationRecognizer = new DictationRecognizer
                {
                    InitialSilenceTimeoutSeconds = 60,
                    AutoSilenceTimeoutSeconds = 5
                };

                dictationRecognizer.DictationResult += DictationRecognizer_DictationResult;
                dictationRecognizer.DictationError += DictationRecognizer_DictationError;
            }
            dictationRecognizer.Start();
            Debug.Log("Capturing Audio...");
        }

        /// <summary>
        /// Stop microphone capture
        /// </summary>
        public void StopCapturingAudio()
        {
            dictationRecognizer.Stop();
            Debug.Log("Stop Capturing Audio...");
        }
    ```

8.  Добавить *обработчик диктовки* , будет вызываться при приостановке голоса. Этот метод передает текст, диктовки *LuisManager* класса.

    ```csharp
        /// <summary>
        /// This handler is called every time the Dictation detects a pause in the speech. 
        /// This method will stop listening for audio, send a request to the LUIS service 
        /// and then start listening again.
        /// </summary>
        private void DictationRecognizer_DictationResult(string dictationCaptured, ConfidenceLevel confidence)
        {
            StopCapturingAudio();
            StartCoroutine(LuisManager.instance.SubmitRequestToLuis(dictationCaptured, StartCapturingAudio));
            Debug.Log("Dictation: " + dictationCaptured);
            dictationText.text = dictationCaptured;
        }

        private void DictationRecognizer_DictationError(string error, int hresult)
        {
            Debug.Log("Dictation exception: " + error);
        }
    ```
 
    > [!IMPORTANT]
    > Удалить *Update()* метод, так как этот класс не будет его использовать.

9.  Не забудьте сохранить изменения в *Visual Studio* перед возвратом *Unity*.

    > [!NOTE]
    > На этом этапе вы заметите ошибку в *панель консоли редактора Unity*. Это так, как код ссылается на *LuisManager* класс, который будет создан в следующей главе.

## <a name="chapter-6--create-the-luismanager-class"></a>Глава 6 – создать класс LUISManager

Пришло время для создания *LuisManager* класс, который сделает вызов службы Azure LUIS. 

Этот класс предназначен для получения текста диктовки из *MicrophoneManager* класса и отправьте ее по адресу *API понимания языка Azure* для анализа.

Этот класс будет десериализовать *JSON* ответа и вызывать соответствующие методы *поведений* класс запускает действие.

Для создания этого класса: 

1.  Дважды щелкните **сценариев** папки, чтобы открыть его. 
2.  Щелкните правой кнопкой мыши внутри **сценарии** папку, нажмите кнопку **Создать > C# сценарий**. Назовите сценарий *LuisManager*. 
3.  Дважды щелкните сценарий, чтобы открыть его с помощью Visual Studio.
4.  Добавьте следующие пространства имен в начало файла:

    ```csharp
        using System;
        using System.Collections;
        using System.Collections.Generic;
        using System.IO;
        using UnityEngine;
        using UnityEngine.Networking;
    ```

5.  Сначала путем создания трех классов **внутри** *LuisManager* класса (в файле сценария, выше *Start()* метод), представляющие десериализованный Ответ JSON от Azure.

    ```csharp
        [Serializable] //this class represents the LUIS response
        public class AnalysedQuery
        {
            public TopScoringIntentData topScoringIntent;
            public EntityData[] entities;
            public string query;
        }

        // This class contains the Intent LUIS determines 
        // to be the most likely
        [Serializable]
        public class TopScoringIntentData
        {
            public string intent;
            public float score;
        }

        // This class contains data for an Entity
        [Serializable]
        public class EntityData
        {
            public string entity;
            public string type;
            public int startIndex;
            public int endIndex;
            public float score;
        }
    ```

6.  Добавьте следующие переменные внутри *LuisManager* класса:
 
    ```csharp
        public static LuisManager instance;

        //Substitute the value of luis Endpoint with your own End Point
        string luisEndpoint = "https://westus.api.cognitive... add your endpoint from the Luis Portal";
    ```

7.  Убедитесь, что теперь поместите конечной точке LUIS на (которая будет иметь через портал LUIS).

8.  Код для *Awake()* теперь необходимо добавить метод. Этот метод будет вызываться при инициализации класса.

    ```csharp
        private void Awake()
        {
            // allows this class instance to behave like a singleton
            instance = this;
        }
    ```

9.  Теперь это приложение использует для отправки диктовки, полученные от методов *MicrophoneManager* класс *LUIS*и затем проверить и десериализировать ответа. 
10. После определения значение Intent, и связанные сущности, они передаются в экземпляр *поведений* класс для активации требуемое действие.

    ```csharp
        /// <summary>
        /// Call LUIS to submit a dictation result.
        /// The done Action is called at the completion of the method.
        /// </summary>
        public IEnumerator SubmitRequestToLuis(string dictationResult, Action done)
        {
            string queryString = string.Concat(Uri.EscapeDataString(dictationResult));

            using (UnityWebRequest unityWebRequest = UnityWebRequest.Get(luisEndpoint + queryString))
            {
                yield return unityWebRequest.SendWebRequest();

                if (unityWebRequest.isNetworkError || unityWebRequest.isHttpError)
                {
                    Debug.Log(unityWebRequest.error);
                }
                else
                {
                    try
                    {
                        AnalysedQuery analysedQuery = JsonUtility.FromJson<AnalysedQuery>(unityWebRequest.downloadHandler.text);

                        //analyse the elements of the response 
                        AnalyseResponseElements(analysedQuery);
                    }
                    catch (Exception exception)
                    {
                        Debug.Log("Luis Request Exception Message: " + exception.Message);
                    }
                }

                done();
                yield return null;
            }
        }
    ```
 
11. Создайте новый метод с именем *AnalyseResponseElements()* , будет считывать итоговый *AnalysedQuery* и определять сущности. После определения этих сущностей, они будут передаваться экземпляру *поведений* класс для использования в действиях.

    ```csharp
        private void AnalyseResponseElements(AnalysedQuery aQuery)
        {
            string topIntent = aQuery.topScoringIntent.intent;

            // Create a dictionary of entities associated with their type
            Dictionary<string, string> entityDic = new Dictionary<string, string>();

            foreach (EntityData ed in aQuery.entities)
            {
                entityDic.Add(ed.type, ed.entity);
            }

            // Depending on the topmost recognised intent, read the entities name
            switch (aQuery.topScoringIntent.intent)
            {
                case "ChangeObjectColor":
                    string targetForColor = null;
                    string color = null;

                    foreach (var pair in entityDic)
                    {
                        if (pair.Key == "target")
                        {
                            targetForColor = pair.Value;
                        }
                        else if (pair.Key == "color")
                        {
                            color = pair.Value;
                        }
                    }

                    Behaviours.instance.ChangeTargetColor(targetForColor, color);
                    break;

                case "ChangeObjectSize":
                    string targetForSize = null;
                    foreach (var pair in entityDic)
                    {
                        if (pair.Key == "target")
                        {
                            targetForSize = pair.Value;
                        }
                    }

                    if (entityDic.ContainsKey("upsize") == true)
                    {
                        Behaviours.instance.UpSizeTarget(targetForSize);
                    }
                    else if (entityDic.ContainsKey("downsize") == true)
                    {
                        Behaviours.instance.DownSizeTarget(targetForSize);
                    }
                    break;
            }
        }
    ```
 
    > [!IMPORTANT]
    > Удалить *Start()* и *Update()* методы, так как этот класс не будет использовать их.

12. Не забудьте сохранить изменения в *Visual Studio* перед возвратом *Unity*.

> [!NOTE]
> На этом этапе можно заметить несколько ошибок, появляющихся в *панель консоли редактора Unity*. Это так, как код ссылается на *поведений* класс, который будет создан в следующей главе.

## <a name="chapter-7--create-the-behaviours-class"></a>Глава 7 – создать класс поведений

*Поведений* класс будет активировать действия, в которых используются сущности, предоставляемые *LuisManager* класса.

Для создания этого класса: 

1.  Дважды щелкните **сценариев** папки, чтобы открыть его. 
2.  Щелкните правой кнопкой мыши внутри **сценарии** папку, нажмите кнопку **Создать > C# сценарий**. Назовите сценарий *поведений*. 
3.  Дважды щелкните сценарий, чтобы открыть его с *Visual Studio*.
4.  Затем добавьте следующие переменные внутри *поведений* класса:

    ```csharp
        public static Behaviours instance;

        // the following variables are references to possible targets
        public GameObject sphere;
        public GameObject cylinder;
        public GameObject cube;
        internal GameObject gazedTarget;
    ```
 
5.  Добавить *Awake()* код метода. Этот метод будет вызываться при инициализации класса.

    ```csharp
        void Awake()
        {
            // allows this class instance to behave like a singleton
            instance = this;
        }
    ```
 
6.  Следующие методы вызываются *LuisManager* класс (который вы создали ранее) чтобы определить, какой объект является целевым объектом запроса и затем активировать соответствующее действие.

    ```csharp
        /// <summary>
        /// Changes the color of the target GameObject by providing the name of the object
        /// and the name of the color
        /// </summary>
        public void ChangeTargetColor(string targetName, string colorName)
        {
            GameObject foundTarget = FindTarget(targetName);
            if (foundTarget != null)
            {
                Debug.Log("Changing color " + colorName + " to target: " + foundTarget.name);

                switch (colorName)
                {
                    case "blue":
                        foundTarget.GetComponent<Renderer>().material.color = Color.blue;
                        break;

                    case "red":
                        foundTarget.GetComponent<Renderer>().material.color = Color.red;
                        break;

                    case "yellow":
                        foundTarget.GetComponent<Renderer>().material.color = Color.yellow;
                        break;

                    case "green":
                        foundTarget.GetComponent<Renderer>().material.color = Color.green;
                        break;

                    case "white":
                        foundTarget.GetComponent<Renderer>().material.color = Color.white;
                        break;

                    case "black":
                        foundTarget.GetComponent<Renderer>().material.color = Color.black;
                        break;
                }          
            }
        }

        /// <summary>
        /// Reduces the size of the target GameObject by providing its name
        /// </summary>
        public void DownSizeTarget(string targetName)
        {
            GameObject foundTarget = FindTarget(targetName);
            foundTarget.transform.localScale -= new Vector3(0.5F, 0.5F, 0.5F);
        }

        /// <summary>
        /// Increases the size of the target GameObject by providing its name
        /// </summary>
        public void UpSizeTarget(string targetName)
        {
            GameObject foundTarget = FindTarget(targetName);
            foundTarget.transform.localScale += new Vector3(0.5F, 0.5F, 0.5F);
        }
    ```
 
7.  Добавить *FindTarget()* метод, чтобы определить, какие *объекты Gameobject* является целевым объектом текущей цели. Этот метод по умолчанию целевой объект для *GameObject* «gazed» Если нет явной целевой объект определен в сущностях.

    ```csharp
        /// <summary>
        /// Determines which obejct reference is the target GameObject by providing its name
        /// </summary>
        private GameObject FindTarget(string name)
        {
            GameObject targetAsGO = null;

            switch (name)
            {
                case "sphere":
                    targetAsGO = sphere;
                    break;

                case "cylinder":
                    targetAsGO = cylinder;
                    break;

                case "cube":
                    targetAsGO = cube;
                    break;

                case "this": // as an example of target words that the user may use when looking at an object
                case "it":  // as this is the default, these are not actually needed in this example
                case "that":
                default: // if the target name is none of those above, check if the user is looking at something
                    if (gazedTarget != null) 
                    {
                        targetAsGO = gazedTarget;
                    }
                    break;
            }
            return targetAsGO;
        }
    ```
 
    > [!IMPORTANT]
    > Удалить *Start()* и *Update()* методы, так как этот класс не будет использовать их.

8.  Не забудьте сохранить изменения в *Visual Studio* перед возвратом *Unity*.

## <a name="chapter-8--create-the-gaze-class"></a>Глава 8 – создать класс взглядом

Последний класс, который будет необходимо выполнить действия этого приложения является *помощи* класса. Этот класс обновляет ссылку *GameObject* в настоящее время в визуальные указатели фокуса пользователя.

Для создания данного класса: 

1.  Дважды щелкните **сценариев** папки, чтобы открыть его. 
2.  Щелкните правой кнопкой мыши внутри **сценарии** папку, нажмите кнопку **Создать > C# сценарий**. Назовите сценарий *помощи*. 
3.  Дважды щелкните сценарий, чтобы открыть его с *Visual Studio*.
4.  Вставьте следующий код для данного класса:

    ```csharp
        using UnityEngine;

        public class Gaze : MonoBehaviour
        {        
            internal GameObject gazedObject;
            public float gazeMaxDistance = 300;

            void Update()
            {
                // Uses a raycast from the Main Camera to determine which object is gazed upon.
                Vector3 fwd = gameObject.transform.TransformDirection(Vector3.forward);
                Ray ray = new Ray(Camera.main.transform.position, fwd);
                RaycastHit hit;
                Debug.DrawRay(Camera.main.transform.position, fwd);

                if (Physics.Raycast(ray, out hit, gazeMaxDistance) && hit.collider != null)
                {
                    if (gazedObject == null)
                    {
                        gazedObject = hit.transform.gameObject;

                        // Set the gazedTarget in the Behaviours class
                        Behaviours.instance.gazedTarget = gazedObject;
                    }
                }
                else
                {
                    ResetGaze();
                }         
            }

            // Turn the gaze off, reset the gazeObject in the Behaviours class.
            public void ResetGaze()
            {
                if (gazedObject != null)
                {
                    Behaviours.instance.gazedTarget = null;
                    gazedObject = null;
                }
            }
        }
    ```
 
5.  Не забудьте сохранить изменения в *Visual Studio* перед возвратом *Unity*.

## <a name="chapter-9--completing-the-scene-setup"></a>Глава 9-завершения установки сцены

1.  Чтобы завершить установку сцены, перетащите каждый скрипт, созданный из папки скриптов для **Main Camera** объекта в *панели иерархии*.
2.  Выберите **Main Camera** и просмотрите *панели Инспектора*, можно увидеть каждый скрипт, который присоединен, и вы заметите, что существуют параметры для каждого сценария, которые будут устанавливаться.

    ![Задание целей ссылку камеры.](images/AzureLabs-Lab3-41.png)

3.  Чтобы правильно задать эти параметры, выполните следующие действия:

    1. *MicrophoneManager*:

        - Из *панели иерархии*, перетащите **Диктовка текста** в коллекцию **Диктовка текста** поле значений параметров.

    2. *Поведений*, из *панели иерархии*:

        - Перетащите **Sphere** в коллекцию *Sphere* "целевой объект ссылки".
        - Перетащите **цилиндра** в *цилиндра* "целевой объект ссылки".
        - Перетащите **куба** в *куба* "целевой объект ссылки".

    3. *Помощи*:

        - Задайте *помощи максимальное расстояние* для **300** (если это еще не сделано). 

4.  Результат должен выглядеть как на следующем рисунке:

    ![Теперь отображается ссылка камеры целевые объекты, задайте.](images/AzureLabs-Lab3-42.png)
 
## <a name="chapter-10--test-in-the-unity-editor"></a>Глава 10 – тест в редакторе Unity

Проверьте, что установки сцены реализуется надлежащим образом.

Убедитесь, что:

-   Все сценарии, присоединяются к **Main Camera** объекта. 
-   Все поля в *главной панели Инспектора камеры* назначаются должным образом.

1.  Нажмите клавишу **воспроизведение** кнопку *редактора Unity*. Приложения должны быть запущены в подключенных иммерсивных гарнитуры.

2.  Попробуйте выполните несколько фразы, например:

    ```
    make the cylinder red

    change the cube to yellow

    I want the sphere blue

    make this to green

    change it to white
    ```

    > [!NOTE]
    > Если появится сообщение об ошибке, в консоли Unity о аудиоустройства по умолчанию изменение, сцены может не работать должным образом. Это из-за способа на портале смешанной реальности имеет дело с встроенные микрофоны применяется, в которых они имеются. Если эта ошибка возникает, просто остановить сцены и запустить снова и вещи должны работать как ожидалось.

## <a name="chapter-11--build-and-sideload-the-uwp-solution"></a>Глава 11 – сборки и передайте решение универсальной платформы Windows

Когда вы убедились, что приложение работает в редакторе Unity, все готово для создания и развертывания.

Для сборки:

1.  Сохранить текущую сцену, щелкнув **файл > Сохранить**.
2.  Перейдите к **файл > Параметры сборки**.
3.  Установка флажка поле, называемое **Unity C# проекты** (полезно для просмотра и отладки кода после создания проекта универсальной платформы Windows.
4.  Щелкните **добавьте откройте сцены**, затем нажмите кнопку **построения**.

    ![Создать окно "Параметры"](images/AzureLabs-Lab3-43.png)

4.  Вам будет предложено выбрать папку, где требуется выполнить сборку решения. 

5.  Создание *ПОСТРОЕНИЯ* папку и в этой папке создайте другую папку с соответствующим именем, по своему усмотрению. 
6.  Нажмите кнопку **Выбор папки** для начала сборки в этом расположении.
 
    ![Создайте папку Builds](images/AzureLabs-Lab3-44.png)
    ![фрагмент создаст папку](images/AzureLabs-Lab3-45.png)
 
7.  Один раз Unity завершил построение (может занять некоторое время), его следует открыть **проводнике** окно в папке построения.

Для развертывания на локальном компьютере:

1.  В *Visual Studio*, откройте файл решения, созданной в [предыдущей главе](#chapter-10--test-in-the-unity-editor).
2.  В **платформа решения**выберите **x86**, **локальный компьютер**.
3.  В **конфигурации решения** выберите **Отладка**.

    > Для Microsoft HoloLens, может быть проще устанавливать равным *удаленный компьютер*, таким образом, не связанном устройстве на компьютер. Однако необходимо будет выполнить следующее:
    > - Знать **IP-адрес** из HoloLens, которую можно найти в *параметры > сеть и Интернет > Wi-Fi > Дополнительно*; IPv4 — это адрес, следует использовать. 
    > - Убедитесь, **режим разработчика** — **на**; найдено в *параметры > обновление и безопасность > для разработчиков*.

    ![Развертывание приложения](images/AzureLabs-Lab3-46.png)
 
4.  Перейдите к **меню "сборка"** и щелкнуть **развернуть решение** для загрузки неопубликованных приложений на компьютер.
5.  Приложения должны появиться в списке установленных приложений, Готово к запуску!
6.  После запуска приложения будет предложено авторизовать доступ к _"микрофон"_. Используйте *контроллеров движения*, или *голосовой ввод*, или *клавиатуры* клавишу **Да** кнопки. 

## <a name="chapter-12--improving-your-luis-service"></a>Глава 12 – улучшение службе LUIS

>[!IMPORTANT] 
> В этой главе чрезвычайно важна и может потребоваться быть просмотрен на несколько раз, так как это поможет повысить точность службе LUIS: Убедитесь, завершения этой операции.

Чтобы повысить уровень понимания, предоставляемые LUIS, вам потребуется записать новый фразы и использовать их для повторного обучения приложением LUIS.

Например может обучения LUIS для понимания «Increase» и «Преобразования», но не требуется знать слова, такие как «Увеличить» приложение?

После использования приложения несколько раз, все, что вы сказали будут собраны LUIS и доступны на ПОРТАЛЕ LUIS.

1.  Перейдите к приложению портала следуя инструкциям из этого [ССЫЛКУ](https://www.luis.ai/home)и вход в систему.
2.  Когда вы выполняете вход с использованием учетных данных MS, нажмите кнопку вашей *имя_приложения*.
3.  Нажмите кнопку **просмотрите фразы конечной точки** кнопка в левой части страницы.

    ![Просмотрите фразы](images/AzureLabs-Lab3-47.png)
 
4.  Будет показан список фразы, которые были отправлены в LUIS в смешанной реальности приложения.

    ![Список фразы](images/AzureLabs-Lab3-48.png)
 
Обратите внимание, некоторые выделенные *сущностей*. 

Навести указатель мыши на каждый выделенное слово, можно просмотреть каждый Utterance и определить, какие сущности был распознан правильно, что сущности — это не так, а какие сущности будут отсутствовать.

В приведенном выше примере он найден, что слово «spear» были выделены как целевой объект, поэтому ее необходимо исправить ошибку, что можно сделать, наведя word с помощью мыши и выбрав **удалить метку**.

![Проверьте фразы](images/AzureLabs-Lab3-49.png)
![удалить изображения подписи](images/AzureLabs-Lab3-50.png)
 
5.  Если вы нашли фразы, которые полностью неверны, их можно удалить с помощью **удалить** кнопку в правой части экрана.

    ![Удалите неправильный фразы](images/AzureLabs-Lab3-51.png)

6.  Или если вы считаете, что LUIS Utterance правильную интерпретацию, можно проверить с помощью его основные сведения о **добавить к краю намерение** кнопки.

    ![Добавьте в выровненных намерения](images/AzureLabs-Lab3-52.png)

7.  После сортировки всех отображаемых фразы, попробуйте и перезагрузите страницу, чтобы увидеть, если сведения доступны.
8.  Очень важно повторите эту процедуру столько раз, как можно ближе к Углубленное освоение приложения. 

**Веселитесь!**

## <a name="your-finished-luis-integrated-application"></a>Встроенная LUIS готового приложения

Поздравляем, вы создали приложение смешанной реальности, использующем присоединение к Azure интеллектуальная служба анализа языка, чтобы понять, что говорит пользователь и act на основе этих данных.

![Результат лаборатории](images/AzureLabs-Lab3-000.png)

## <a name="bonus-exercises"></a>Упражнения премии

### <a name="exercise-1"></a>Упражнение 1

При использовании этого приложения вы можете заметить, что при помощи в объекте, Floor и попросите изменить его цвет, она сделает это. Можно работать как остановить выполнение приложения изменения цвета Floor?

### <a name="exercise-2"></a>Упражнение 2

Попробуйте расширение возможностей приложения и LUIS, добавив дополнительные функциональные возможности для объектов в сцене; Например создайте новые объекты в взглядом точку нажатия, в зависимости от того, пользователь говорит, а затем смогут использовать эти объекты вместе с текущей объектов сцены, с помощью существующих команд. 
