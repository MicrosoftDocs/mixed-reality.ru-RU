---
title: Направление головы и фиксация
description: Общие сведения о модели направления головы и фиксации
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
keywords: Смешанная реальность, взгляд, нацеливание взглядом, взаимодействие, проектирование
ms.openlocfilehash: aeca5ceacf5ae350aa06cb58cc68162f885f6d78
ms.sourcegitcommit: b0b1b8e1182cce93929d409706cdaa99ff24fdee
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/23/2019
ms.locfileid: "68387677"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="557e2-104">Направление головы и фиксация</span><span class="sxs-lookup"><span data-stu-id="557e2-104">Head-gaze and commit</span></span>
<span data-ttu-id="557e2-105">Элемент head-взгляд и фиксация — это входная модель, включающая в себя объект с направлением, указывающим на передний план (головное), и последующим действием с ним с помощью вторичного ввода, например руки жеста в воздухе или команды Voice SELECT.</span><span class="sxs-lookup"><span data-stu-id="557e2-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input, such as the hand gesture air tap or the voice command Select.</span></span> <span data-ttu-id="557e2-106">Она считается дальней моделью ввода с косвенной манипуляцией, то есть лучше использовать ее для взаимодействия с содержимым, которое выходит за рамки руки.</span><span class="sxs-lookup"><span data-stu-id="557e2-106">It is considered a far input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="557e2-107">Поддержка устройств</span><span class="sxs-lookup"><span data-stu-id="557e2-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="557e2-108"><strong>Модель ввода</strong></span><span class="sxs-lookup"><span data-stu-id="557e2-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="557e2-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1-го поколения)</strong></a></span><span class="sxs-lookup"><span data-stu-id="557e2-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="557e2-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="557e2-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="557e2-111"><a href="immersive-headset-hardware-details.md"><strong>Иммерсивные гарнитуры</strong></a></span><span class="sxs-lookup"><span data-stu-id="557e2-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="557e2-112">Направление головы и фиксация</span><span class="sxs-lookup"><span data-stu-id="557e2-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="557e2-113">✔️ Рекомендуется</span><span class="sxs-lookup"><span data-stu-id="557e2-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="557e2-114">✔ Рекомендуется (третий вариант <a href="interaction-fundamentals.md">см. в разделе других возможностей</a>)</span><span class="sxs-lookup"><span data-stu-id="557e2-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="557e2-115">➕ Альтернативный вариант</span><span class="sxs-lookup"><span data-stu-id="557e2-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="557e2-116">Направление головы</span><span class="sxs-lookup"><span data-stu-id="557e2-116">Head-gaze</span></span>
<span data-ttu-id="557e2-117">Гарнитура смешанной реальности использует положение и ориентацию головы пользователя для определения вектора направления головы.</span><span class="sxs-lookup"><span data-stu-id="557e2-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="557e2-118">Ее можно представить как лазер, который указывает прямо вперед из точки между глаз пользователя.</span><span class="sxs-lookup"><span data-stu-id="557e2-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="557e2-119">Это довольно приблизительная оценка того, куда смотрит пользователь.</span><span class="sxs-lookup"><span data-stu-id="557e2-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="557e2-120">Приложение может пересекать этот луч с виртуальными или реальными объектами и нарисовать курсор в этом расположении, чтобы сообщить пользователю о том, что в настоящее время нацелено на них.</span><span class="sxs-lookup"><span data-stu-id="557e2-120">Your application can intersect this ray with virtual or real-world objects, and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="557e2-121">Помимо головного взгляда, некоторые гарнитуры смешанной реальности, например HoloLens 2, включают системы отслеживания взглядов, которые создают вектор взгляда.</span><span class="sxs-lookup"><span data-stu-id="557e2-121">In addition to head gaze, some mixed reality headsets, like HoloLens 2, include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="557e2-122">Это обеспечивает высокоточное измерение направления взгляда пользователя.</span><span class="sxs-lookup"><span data-stu-id="557e2-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="557e2-123">Можно создавать взаимодействия с помощью взгляда и фиксации, используя глаза.</span><span class="sxs-lookup"><span data-stu-id="557e2-123">It is possible to build gaze and commit interactions using eye gaze.</span></span> <span data-ttu-id="557e2-124">Но это имеет очень разный набор ограничений проектирования, которые будут рассматриваться отдельно в [статье взгляда](eye-tracking.md).</span><span class="sxs-lookup"><span data-stu-id="557e2-124">But this comes with a very different set of design constraints, which will be covered separately in the [eye-gaze article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="557e2-125">Фиксация</span><span class="sxs-lookup"><span data-stu-id="557e2-125">Commit</span></span>
<span data-ttu-id="557e2-126">После нацеливания на объект или элемент пользовательского интерфейса пользователь может взаимодействовать с ним или щелкать его, используя Вторичный вход.</span><span class="sxs-lookup"><span data-stu-id="557e2-126">After targeting an object or UI element, the user can interact or click on it using a secondary input.</span></span> <span data-ttu-id="557e2-127">В этой модели это называется шагом фиксации.</span><span class="sxs-lookup"><span data-stu-id="557e2-127">This is known as the commit step of the model.</span></span> <span data-ttu-id="557e2-128">Поддерживаются следующие методы фиксации:</span><span class="sxs-lookup"><span data-stu-id="557e2-128">The following commit methods are supported:</span></span>

- <span data-ttu-id="557e2-129">Жест касания в воздухе</span><span class="sxs-lookup"><span data-stu-id="557e2-129">Air tap gesture</span></span>
- <span data-ttu-id="557e2-130">Говорите голосовую команду, выберите или одну из целевых голосовых команд</span><span class="sxs-lookup"><span data-stu-id="557e2-130">Speak the voice command, Select, or one of the targeted voice commands</span></span>
- <span data-ttu-id="557e2-131">Нажатие одной кнопки на кнопке [HoloLens](hardware-accessories.md#hololens-clicker)</span><span class="sxs-lookup"><span data-stu-id="557e2-131">Press a single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="557e2-132">Нажмите кнопку "A" на игровом планшете Xbox</span><span class="sxs-lookup"><span data-stu-id="557e2-132">Press the 'A' button on an Xbox gamepad</span></span>
- <span data-ttu-id="557e2-133">Нажмите кнопку "A" на адаптивном контроллере Xbox</span><span class="sxs-lookup"><span data-stu-id="557e2-133">Press the 'A' button on an Xbox adaptive controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="557e2-134">Направление головы и жест касания</span><span class="sxs-lookup"><span data-stu-id="557e2-134">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="557e2-135">Касание — это жест касания с положением руки вертикально.</span><span class="sxs-lookup"><span data-stu-id="557e2-135">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="557e2-136">Чтобы выполнить касание, поднимите указатель пальца до позиции готовности, затем проведите сжатие с помощью бегунка, а затем поднимите палец пальца до выпуска.</span><span class="sxs-lookup"><span data-stu-id="557e2-136">To perform an air tap, raise your index finger to the ready position, then pinch with your thumb, and raise your index finger back up to release.</span></span> <span data-ttu-id="557e2-137">В HoloLens (1-й общий) поток касания является наиболее распространенным вторичным входом.</span><span class="sxs-lookup"><span data-stu-id="557e2-137">On HoloLens (1st Gen), air tap is the most common secondary input.</span></span>

![Палец в положении готовности, а затем движения касания или щелчка](images/readyandpress.jpg)<br>

<span data-ttu-id="557e2-139">В HoloLens 2 также доступен воздушный нажим.</span><span class="sxs-lookup"><span data-stu-id="557e2-139">Air tap is also available on HoloLens 2.</span></span> <span data-ttu-id="557e2-140">Она была ослаблена от исходной версии.</span><span class="sxs-lookup"><span data-stu-id="557e2-140">It has been relaxed from the original version.</span></span> <span data-ttu-id="557e2-141">Теперь поддерживаются почти все типы сжатий, если рука по-прежнему находится в вертикальном и удерживаемом виде.</span><span class="sxs-lookup"><span data-stu-id="557e2-141">Nearly all types of pinches are now supported as long as the hand is upright and holding still.</span></span> <span data-ttu-id="557e2-142">Это значительно упрощает для пользователей знакомство с жестом и его использование.</span><span class="sxs-lookup"><span data-stu-id="557e2-142">This makes it much easier for users to learn and perform the gesture.</span></span> <span data-ttu-id="557e2-143">Новое касание Air заменяет старое, используя тот же API, поэтому существующие приложения будут автоматически создавать новое поведение после повторной компиляции для HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="557e2-143">This new air tap replaces the old one through the same API, so existing applications will have the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="557e2-144">Направление головы и голосовая команда "Выбрать"</span><span class="sxs-lookup"><span data-stu-id="557e2-144">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="557e2-145">Речевая команда — один из основных методов взаимодействия в смешанной реальности.</span><span class="sxs-lookup"><span data-stu-id="557e2-145">Voice commanding is one of the primary interaction methods in mixed reality.</span></span> <span data-ttu-id="557e2-146">Он предоставляет мощный механизм для управления системой.</span><span class="sxs-lookup"><span data-stu-id="557e2-146">It provides a very powerful hands-free mechanism to control the system.</span></span> <span data-ttu-id="557e2-147">Существуют разные типы моделей голосового взаимодействия:</span><span class="sxs-lookup"><span data-stu-id="557e2-147">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="557e2-148">Универсальная команда SELECT, которая выполняет нажатие или фиксацию в качестве вторичного входа.</span><span class="sxs-lookup"><span data-stu-id="557e2-148">The generic command Select that performs a click actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="557e2-149">Команды объекта, такие как Close или, делают его больше выполняемых и фиксируются в действии в качестве вторичного входа.</span><span class="sxs-lookup"><span data-stu-id="557e2-149">Object commands like Close or Make it bigger performs and commits to an action as a secondary input.</span></span>
- <span data-ttu-id="557e2-150">Для глобального коммнадс, например Go, не требуется целевой объект.</span><span class="sxs-lookup"><span data-stu-id="557e2-150">Global commnads like Go to start don't require a target.</span></span>
- <span data-ttu-id="557e2-151">Пользовательские интерфейсы или сущности диалога, такие как Кортана, имеют естественный язык AI.</span><span class="sxs-lookup"><span data-stu-id="557e2-151">Conversation user interfaces or entities like Cortana have an AI natural language capability.</span></span>
- <span data-ttu-id="557e2-152">пользовательские команды.</span><span class="sxs-lookup"><span data-stu-id="557e2-152">Custom commnads</span></span>

<span data-ttu-id="557e2-153">Для получения дополнительных сведений, а также компренхесиве списка доступных команд и способов их использования ознакомьтесь с руководством по [голосовым командам](voice-design.md) .</span><span class="sxs-lookup"><span data-stu-id="557e2-153">To find more details as well as a comprenhesive list of available commands and how to use them, check out our [voice commanding](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="557e2-154">Направление головы и HoloLens Clicker (Датчик HoloLens)</span><span class="sxs-lookup"><span data-stu-id="557e2-154">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="557e2-155">Щелчок HoloLens — это первое периферийное устройство, созданное специально для HoloLens.</span><span class="sxs-lookup"><span data-stu-id="557e2-155">The HoloLens Clicker is the first peripheral device built specifically for HoloLens.</span></span> <span data-ttu-id="557e2-156">Он входит в состав выпуска HoloLens (1-го поколения) разработки.</span><span class="sxs-lookup"><span data-stu-id="557e2-156">It is included with HoloLens (1st Gen) Development Edition.</span></span> <span data-ttu-id="557e2-157">Щелчок HoloLens позволяет пользователю щелкнуть с минимальным движением руки и зафиксировать его как Вторичный вход.</span><span class="sxs-lookup"><span data-stu-id="557e2-157">The HoloLens Clicker lets a user click with minimal hand motion, and commit as a secondary input.</span></span> <span data-ttu-id="557e2-158">Щелчок HoloLens подключается к HoloLens (1-го поколения) или HoloLens 2 с помощью Bluetooth низкого энергопотребления (БТЛЕ).</span><span class="sxs-lookup"><span data-stu-id="557e2-158">The HoloLens Clicker connects to HoloLens (1st Gen) or HoloLens 2 using Bluetooth Low Energy (BTLE).</span></span>

<span data-ttu-id="557e2-159">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span><span class="sxs-lookup"><span data-stu-id="557e2-159">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span></span><br>
<span data-ttu-id="557e2-160">*HoloLens Clicker*</span><span class="sxs-lookup"><span data-stu-id="557e2-160">*HoloLens Clicker*</span></span>

<span data-ttu-id="557e2-161">Дополнительные сведения и инструкции по связыванию устройства см. [здесь](hardware-accessories.md#pairing-bluetooth-accessories).</span><span class="sxs-lookup"><span data-stu-id="557e2-161">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="557e2-162">Направление головы и беспроводной контроллер Xbox</span><span class="sxs-lookup"><span data-stu-id="557e2-162">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="557e2-163">Контроллер беспроводной связи Xbox выполняет нажатие кнопки как Вторичный вход, используя кнопку "A".</span><span class="sxs-lookup"><span data-stu-id="557e2-163">The Xbox Wireless Controller performs a click actuation as a secondary input by using the 'A' button.</span></span> <span data-ttu-id="557e2-164">Устройство связано с набором действий по умолчанию, которые помогают переходить по системе и управлять ей.</span><span class="sxs-lookup"><span data-stu-id="557e2-164">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="557e2-165">Если вы хотите настроить контроллер, используйте приложение Xbox Акцесориес для настройки контроллера беспроводной сети Xbox.</span><span class="sxs-lookup"><span data-stu-id="557e2-165">If you want to customize the controller, use the Xbox Accesories application to configure your Xbox Wireless Controller.</span></span>

<span data-ttu-id="557e2-166">![Беспроводной контроллер Xbox](images/xboxcontroller.jpg)</span><span class="sxs-lookup"><span data-stu-id="557e2-166">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span></span><br>
<span data-ttu-id="557e2-167">*Беспроводной контроллер Xbox*</span><span class="sxs-lookup"><span data-stu-id="557e2-167">*Xbox Wireless Controller*</span></span>

[<span data-ttu-id="557e2-168">Связывание контроллера Xbox с компьютером</span><span class="sxs-lookup"><span data-stu-id="557e2-168">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="557e2-169">Направление головы и адаптивный контроллер Xbox</span><span class="sxs-lookup"><span data-stu-id="557e2-169">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="557e2-170">Адаптивный контроллер Xbox, разработанный в основном для удовлетворения потребностей игр с ограниченным мобильным доступом, является единым концентратором для устройств, которые помогают сделать смешанную реальность более доступной.</span><span class="sxs-lookup"><span data-stu-id="557e2-170">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make mixed reality more accessible.</span></span>

<span data-ttu-id="557e2-171">Адаптивный контроллер Xbox выполняет нажатие кнопки как Вторичный вход, используя кнопку "A".</span><span class="sxs-lookup"><span data-stu-id="557e2-171">The Xbox Adaptive Controller performs a click actuation as a secondary input by using the 'A' button.</span></span> <span data-ttu-id="557e2-172">Устройство сопоставляется с набором действий по умолчанию, которые помогают перемещаться по системе и управлять ей.</span><span class="sxs-lookup"><span data-stu-id="557e2-172">The device is mapped to a default set of actions that help navigate and control the system.</span></span> <span data-ttu-id="557e2-173">Если вы хотите настроить контроллер, используйте приложение Xbox Акцесориес для настройки адаптивного контроллера Xbox.</span><span class="sxs-lookup"><span data-stu-id="557e2-173">If you want to customize the controller, use the Xbox Accesories application to configure your Xbox Adaptive Controller.</span></span>

<span data-ttu-id="557e2-174">![Адаптивный контроллер Xbox](images/xbox-adaptive-controller-devices.jpg)</span><span class="sxs-lookup"><span data-stu-id="557e2-174">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span></span><br>
<span data-ttu-id="557e2-175">*Адаптивный контроллер Xbox*</span><span class="sxs-lookup"><span data-stu-id="557e2-175">*Xbox Adaptive Controller*</span></span>

<span data-ttu-id="557e2-176">Подключите внешние устройства, такие как коммутаторы, кнопки, подключения и джойстики, чтобы создать пользовательский интерфейс контроллера, который является уникальным.</span><span class="sxs-lookup"><span data-stu-id="557e2-176">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controller experience that is uniquely yours.</span></span> <span data-ttu-id="557e2-177">Входные данные кнопки, аналогового стика и триггера контролируются с помощью вспомогательных устройств, подключенных через разъемы 3,5 мм и порты USB.</span><span class="sxs-lookup"><span data-stu-id="557e2-177">Button, thumbstick, and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

<span data-ttu-id="557e2-178">![Порты адаптивного контроллера Xbox](images/xbox-adaptive-controller-ports.jpg)</span><span class="sxs-lookup"><span data-stu-id="557e2-178">![Xbox Adaptive Controller ports](images/xbox-adaptive-controller-ports.jpg)</span></span><br>
<span data-ttu-id="557e2-179">*Порты адаптивного контроллера Xbox*</span><span class="sxs-lookup"><span data-stu-id="557e2-179">*Xbox Adaptive Controller ports*</span></span>

[<span data-ttu-id="557e2-180">Инструкции по связыванию устройства</span><span class="sxs-lookup"><span data-stu-id="557e2-180">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="557e2-181"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Дополнительные сведения доступны на сайте Xbox</a></span><span class="sxs-lookup"><span data-stu-id="557e2-181"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


## <a name="design-guidelines"></a><span data-ttu-id="557e2-182">Рекомендации по проектированию</span><span class="sxs-lookup"><span data-stu-id="557e2-182">Design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="557e2-183">[В ближайшее время](index.md) появятся дополнительные руководства, касающиеся дизайна механизма отслеживания взгляда.</span><span class="sxs-lookup"><span data-stu-id="557e2-183">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="557e2-184">Нацеливание направлением головы</span><span class="sxs-lookup"><span data-stu-id="557e2-184">Head-gaze targeting</span></span>
<span data-ttu-id="557e2-185">Все взаимодействия построены на базе возможности пользователя нацеливаться на элемент, с которым они хотят взаимодействовать, независимо от модальности ввода.</span><span class="sxs-lookup"><span data-stu-id="557e2-185">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="557e2-186">В Windows Mixed Reality это обычно делается с помощью взгляда пользователя.</span><span class="sxs-lookup"><span data-stu-id="557e2-186">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="557e2-187">Чтобы обеспечить успешное взаимодействие с пользователем, вычисленное системой понимание намерений пользователя и фактической цели пользователя должна быть максимально согласованной.</span><span class="sxs-lookup"><span data-stu-id="557e2-187">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent and the user's actual intent must align as closely as possible.</span></span> <span data-ttu-id="557e2-188">Удовлетворенность пользователя возрастает и производительность повышается настолько, насколько система правильно распознает намерения пользователя.</span><span class="sxs-lookup"><span data-stu-id="557e2-188">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="557e2-189">Изменение размера цели и обратная связь</span><span class="sxs-lookup"><span data-stu-id="557e2-189">Target sizing and feedback</span></span>
<span data-ttu-id="557e2-190">Вектор взгляда показан повторно, чтобы его можно было использовать для тонкого нацеливания, но он, как правило, лучше всего подходит для валовой нацеливания — получая несколько более крупные целевые объекты.</span><span class="sxs-lookup"><span data-stu-id="557e2-190">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting--acquiring somewhat larger targets.</span></span> <span data-ttu-id="557e2-191">Минимальный размер целевого объекта (от 1 до 1,5 градусов) позволяет успешно выполнять действия пользователя в большинстве сценариев, хотя целевые объекты с 3 градусами часто обеспечивают более высокую скорость.</span><span class="sxs-lookup"><span data-stu-id="557e2-191">Minimum target sizes of 1 to 1.5 degrees allows successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="557e2-192">Обратите внимание, что пользовательские цели — это фактически двумерная область, даже если это трехмерный элемент: проекция, которая обращена к пользователю, будет областью, на которую можно нацелиться.</span><span class="sxs-lookup"><span data-stu-id="557e2-192">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="557e2-193">Очень полезно указать ключевые, что элемент является "активным" (то есть он предназначен для пользователя).</span><span class="sxs-lookup"><span data-stu-id="557e2-193">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful.</span></span> <span data-ttu-id="557e2-194">Это может включать использование, такие как видимые эффекты наведения указателя, звуковые элементы или щелчки, а также четкое выравнивание курсора с помощью элемента.</span><span class="sxs-lookup"><span data-stu-id="557e2-194">This can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="557e2-195">![Оптимальный размер целевого объекта на расстоянии 2 метра](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="557e2-195">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="557e2-196">*Оптимальный размер целевого объекта на расстоянии 2 метра*</span><span class="sxs-lookup"><span data-stu-id="557e2-196">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="557e2-197">![Пример выделения выбранного взглядом целевого объекта](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="557e2-197">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="557e2-198">*Пример выделения выбранного взглядом целевого объекта*</span><span class="sxs-lookup"><span data-stu-id="557e2-198">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="557e2-199">Размещение цели</span><span class="sxs-lookup"><span data-stu-id="557e2-199">Target placement</span></span>
<span data-ttu-id="557e2-200">Пользователям часто не удается найти элементы пользовательского интерфейса, которые находятся очень высоко или очень низкы в своем поле зрения. основное внимание уделяется вопросам, связанным с областями вокруг основного фокусирования.</span><span class="sxs-lookup"><span data-stu-id="557e2-200">Users often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus, which is approximately at eye level.</span></span> <span data-ttu-id="557e2-201">Размещение большинства целей в приемлемом диапазоне примерно на уровне глаз может исправить ситуацию.</span><span class="sxs-lookup"><span data-stu-id="557e2-201">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="557e2-202">Учитывая склонность пользователей в любой момент фокусироваться на относительно небольшой визуальной области (область фокусировки внимания в поле зрения составляет приблизительно 10 градусов), группирование элементов интерфейса в такой мере, чтобы они были концептуально связаны, может задействовать поведение, связанное с перемещением внимания с объекта на объект, по мере перемещения взгляда пользователя по области.</span><span class="sxs-lookup"><span data-stu-id="557e2-202">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="557e2-203">При разработке интерфейса учитывайте возможные значительные отклонения в поле зрения HoloLens и иммерсивной гарнитуры.</span><span class="sxs-lookup"><span data-stu-id="557e2-203">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="557e2-204">![Пример сгруппированных элементов интерфейса для упрощения нацеливания взглядом в Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="557e2-204">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="557e2-205">*Пример сгруппированных элементов интерфейса для упрощения нацеливания взглядом в Galaxy Explorer*</span><span class="sxs-lookup"><span data-stu-id="557e2-205">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="557e2-206">Улучшение поведения выбора цели</span><span class="sxs-lookup"><span data-stu-id="557e2-206">Improving targeting behaviors</span></span>
<span data-ttu-id="557e2-207">Если цель пользователя может быть определена (или приблизительно точнее), может оказаться полезной возможность принятия практических попыток взаимодействия, как если бы они были нацелены правильно.</span><span class="sxs-lookup"><span data-stu-id="557e2-207">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept near miss attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="557e2-208">Вот несколько успешных методов, которые могут быть включены в возможности смешанной реальности:</span><span class="sxs-lookup"><span data-stu-id="557e2-208">Here are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="557e2-209">Стабилизация направления головы ("колодцы гравитации")</span><span class="sxs-lookup"><span data-stu-id="557e2-209">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="557e2-210">Этот параметр должен быть включен в большую часть времени или полностью.</span><span class="sxs-lookup"><span data-stu-id="557e2-210">This should be turned on most or all of the time.</span></span> <span data-ttu-id="557e2-211">Эта методика позволяет устранить естественные колебания и колебании горловины, которые пользователи могут иметь в качестве хорошей передвижения из-за поведения при оформлении и распознавании речи.</span><span class="sxs-lookup"><span data-stu-id="557e2-211">This technique removes the natural head and neck jitters that users might have as well movement due to looking and speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="557e2-212">Алгоритмы ближайшего звена</span><span class="sxs-lookup"><span data-stu-id="557e2-212">Closest link algorithms</span></span>
<span data-ttu-id="557e2-213">Они лучше всего работают в областях с разреженным интерактивным содержимым.</span><span class="sxs-lookup"><span data-stu-id="557e2-213">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="557e2-214">Если есть высокая вероятность того, что вы можете определить, с чем пользователь пытался взаимодействовать, можно дополнить его возможностями нацеливания, предполагая определенный уровень намерения.</span><span class="sxs-lookup"><span data-stu-id="557e2-214">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by assuming some level of intent.</span></span>

### <a name="backdating-and-postdating-actions"></a><span data-ttu-id="557e2-215">Действия баккдатинг и постдатинг</span><span class="sxs-lookup"><span data-stu-id="557e2-215">Backdating and postdating actions</span></span>
<span data-ttu-id="557e2-216">Этот механизм полезен для задач, требующих скорости.</span><span class="sxs-lookup"><span data-stu-id="557e2-216">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="557e2-217">Когда пользователь перемещается по ряду нацеливания и манеуверс на скорости, целесообразно предположить, что он имеет некоторую намерение, и позволить пропущенным действиям работать с целевыми объектами, на которые пользователь находился в фокусе немного раньше или немного после 50 того, как в EA Тестирование РЛИ).</span><span class="sxs-lookup"><span data-stu-id="557e2-217">When a user is moving through a series of targeting and activation maneuvers at speed, it is useful to assume some intent, and allow missed steps to act upon targets that the user had in focus slightly before or slightly after the tap (50 ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="557e2-218">Сглаживание</span><span class="sxs-lookup"><span data-stu-id="557e2-218">Smoothing</span></span>
<span data-ttu-id="557e2-219">Этот механизм полезен при перемещении путем перемещения, уменьшая незначительные колебания и качающуюся из-за особенностей естественных головных перемещений.</span><span class="sxs-lookup"><span data-stu-id="557e2-219">This mechanism is useful for pathing movements, reducing the slight jitter and wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="557e2-220">При смягчении по контуру движения, плавное изменение размера и расстояния движений, а не со временем.</span><span class="sxs-lookup"><span data-stu-id="557e2-220">When smoothing over pathing motions, smooth by the size and distance of movements rather than over time.</span></span>

### <a name="magnetism"></a><span data-ttu-id="557e2-221">Магнитность</span><span class="sxs-lookup"><span data-stu-id="557e2-221">Magnetism</span></span>
<span data-ttu-id="557e2-222">Этот механизм можно рассматривать как более общую версию ближайших алгоритмов связи — Рисование курсора на целевую платформу или простое увеличение хитбоксес, как видимых, так и незаметного, так как пользователи, вероятнее всего, используют знания интерактивного макета, чтобы лучше подход к намерениям пользователя.</span><span class="sxs-lookup"><span data-stu-id="557e2-222">This mechanism can be thought of as a more general version of closest link algorithms--drawing a cursor toward a target or simply increasing hitboxes, whether visibly or not, as users approach likely targets by using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="557e2-223">Это может быть особенно эффективно для небольших целей.</span><span class="sxs-lookup"><span data-stu-id="557e2-223">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="557e2-224">Закрепление фокуса</span><span class="sxs-lookup"><span data-stu-id="557e2-224">Focus stickiness</span></span>
<span data-ttu-id="557e2-225">При определении соседних интерактивных элементов, на которые передаются фокус, фокус прикрепления обеспечивает сдвиг к элементу, который в настоящий момент находится в фокусе.</span><span class="sxs-lookup"><span data-stu-id="557e2-225">When determining which nearby interactive elements to give focus to, focus stickiness provides a bias to the element that is currently focused.</span></span> <span data-ttu-id="557e2-226">Это помогает сократить число неустойчивых переключений фокуса при плавающей точке между двумя элементами с естественным шум.</span><span class="sxs-lookup"><span data-stu-id="557e2-226">This helps reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="557e2-227">Составные жесты</span><span class="sxs-lookup"><span data-stu-id="557e2-227">Composite gestures</span></span>

### <a name="air-tap"></a><span data-ttu-id="557e2-228">Жест касания</span><span class="sxs-lookup"><span data-stu-id="557e2-228">Air tap</span></span>
<span data-ttu-id="557e2-229">Жест касания воздуха (а также другие жесты ниже) реагирует только на определенное касание.</span><span class="sxs-lookup"><span data-stu-id="557e2-229">The air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="557e2-230">Для обнаружения других касаний, таких как меню или распознавать, приложение должно напрямую использовать взаимодействия нижнего уровня, описанные в разделе «жесты двух ключевых компонентов» выше.</span><span class="sxs-lookup"><span data-stu-id="557e2-230">To detect other taps, such as Menu or Grasp, your application must directly use the lower-level interactions described in the two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="557e2-231">Tap and hold</span><span class="sxs-lookup"><span data-stu-id="557e2-231">Tap and hold</span></span>
<span data-ttu-id="557e2-232">Удерживание — это просто удержание пальца в опущенном положении после касания.</span><span class="sxs-lookup"><span data-stu-id="557e2-232">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="557e2-233">Сочетание воздушного касания и удержания позволяет использовать множество более сложных взаимодействий "щелчок и перетаскивание" при сочетании с движением ARM, например выборка объекта вместо активации или MouseDown вторичных взаимодействий, таких как отображение контекстного меню.</span><span class="sxs-lookup"><span data-stu-id="557e2-233">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or mousedown secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="557e2-234">Однако при разработке этого жеста следует соблюдать осторожность, поскольку пользователи могут быть склонны к расслаблению позы рук во время любого расширенного жеста.</span><span class="sxs-lookup"><span data-stu-id="557e2-234">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="557e2-235">Управление</span><span class="sxs-lookup"><span data-stu-id="557e2-235">Manipulation</span></span>
<span data-ttu-id="557e2-236">Жесты манипуляции можно использовать для перемещения, изменения размера или поворота голограммы, когда нужно, чтобы голограмма реагировала на 1:1 в руки пользователя.</span><span class="sxs-lookup"><span data-stu-id="557e2-236">Manipulation gestures can be used to move, resize, or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="557e2-237">Одно из применений таких движений 1:1 позволяет пользователю только рисовать или вписывать красками.</span><span class="sxs-lookup"><span data-stu-id="557e2-237">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="557e2-238">Первоначальное нацеливание для жеста управления должно быть исполнено взглядом или указанием.</span><span class="sxs-lookup"><span data-stu-id="557e2-238">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="557e2-239">После того как касание и удержание начинается, любая манипуляция объекта обрабатывается перемещениями вручную, освобождая пользователя на то время, когда они манипулируют.</span><span class="sxs-lookup"><span data-stu-id="557e2-239">Once the tap and hold starts, any manipulation of the object is handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="557e2-240">Навигация</span><span class="sxs-lookup"><span data-stu-id="557e2-240">Navigation</span></span>
<span data-ttu-id="557e2-241">Жесты навигации работают как виртуальный джойстик и могут использоваться для навигации по мини-приложениям пользовательского интерфейса, таким как радиальные меню.</span><span class="sxs-lookup"><span data-stu-id="557e2-241">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="557e2-242">Вы касаетесь и удерживаете, чтобы начать жест, а затем двигаете рукой в нормализованном трехмерном кубе, центрированном вокруг начального нажатия.</span><span class="sxs-lookup"><span data-stu-id="557e2-242">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="557e2-243">Вы можете перемещать руку вдоль оси X, Y или Z от значения –1 до 1, где 0 является начальной точкой.</span><span class="sxs-lookup"><span data-stu-id="557e2-243">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="557e2-244">Навигация может использоваться для создания жестов непрерывной прокрутки или масштабирования на основе скорости, аналогично прокрутке 2D-интерфейса путем нажатия средней кнопки мыши и последующего перемещения мыши вверх и вниз.</span><span class="sxs-lookup"><span data-stu-id="557e2-244">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="557e2-245">Переход с границами означает возможность распознавания движений на определенной оси до тех пор, пока на этой оси не будет достигнуто определенное пороговое значение.</span><span class="sxs-lookup"><span data-stu-id="557e2-245">Navigation with rails refers to the ability of recognizing movements in certain axis until a certain threshold is reached on that axis.</span></span> <span data-ttu-id="557e2-246">Это полезно только в том случае, если в приложении разработчику разрешено перемещение нескольких осей, например, если приложение настроено на распознавание жестов навигации по оси X, Y, но также задается по оси X с границами.</span><span class="sxs-lookup"><span data-stu-id="557e2-246">This is only useful when movement in more than one axis is enabled in an application by the developer, such as if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="557e2-247">В этом случае система распознает перемещения руки по оси X, пока они остаются в мнимых шинах (направляющие) на оси X, если движение руки также выполняется на оси Y.</span><span class="sxs-lookup"><span data-stu-id="557e2-247">In this case the system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on the X axis, if hand movement also occurs on the Y axis.</span></span>

<span data-ttu-id="557e2-248">В 2D-приложениях пользователи могут использовать жесты вертикальной навигации для прокрутки, масштабирования или перетаскивания внутри приложения.</span><span class="sxs-lookup"><span data-stu-id="557e2-248">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="557e2-249">Это вводит в приложение виртуальные касания пальцем, чтобы имитировать сенсорные жесты того же типа.</span><span class="sxs-lookup"><span data-stu-id="557e2-249">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="557e2-250">Пользователи могут выбирать, какие из этих действий выполняются, переключаясь между инструментами на панели над приложением, нажимая кнопку или произнося «< Scroll/rezoom > Tool».</span><span class="sxs-lookup"><span data-stu-id="557e2-250">Users can select which of these actions take place by toggling between the tools on the bar above the application, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="557e2-251">Дополнительные сведения о составных жестах</span><span class="sxs-lookup"><span data-stu-id="557e2-251">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="557e2-252">Распознаватели жестов</span><span class="sxs-lookup"><span data-stu-id="557e2-252">Gesture recognizers</span></span>

<span data-ttu-id="557e2-253">Одно из преимуществ использования распознавания жестов заключается в том, что вы можете настроить распознаватель жестов только для жестов, которые может принимать текущая Целевая голограмма.</span><span class="sxs-lookup"><span data-stu-id="557e2-253">One benefit of using gesture recognition is that you can configure a gesture recognizer only for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="557e2-254">Платформа делает только неоднозначность по мере необходимости для различения определенных поддерживаемых жестов.</span><span class="sxs-lookup"><span data-stu-id="557e2-254">The platform only does disambiguation as necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="557e2-255">Таким образом, голограмма, которая просто поддерживает воздушный нажим, может принимать любое время между нажатием и выпуском, а голограмма, поддерживающая нажатие и удержание, может повысить уровень касания до удержания после порогового значения времени удержания.</span><span class="sxs-lookup"><span data-stu-id="557e2-255">In this way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="557e2-256">Распознавание рук</span><span class="sxs-lookup"><span data-stu-id="557e2-256">Hand recognition</span></span>
<span data-ttu-id="557e2-257">HoloLens распознает жесты рук, отслеживая положение одной или обеих рук, которые видимые устройству.</span><span class="sxs-lookup"><span data-stu-id="557e2-257">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="557e2-258">Руки видны для HoloLens, когда они находятся в состоянии готовности (задняя часть руки обращена к вам указательным пальцем вверх) или в нажатом состоянии (задняя часть руки обращена к вам указательным пальцем вниз).</span><span class="sxs-lookup"><span data-stu-id="557e2-258">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="557e2-259">Когда руки находятся в других случаях, HoloLens игнорирует СЕМЗ.</span><span class="sxs-lookup"><span data-stu-id="557e2-259">When hands are in other poses, HoloLens ignore themz.</span></span>
<span data-ttu-id="557e2-260">Для каждой руки, которую обнаруживает HoloLens, можно получить доступ к его положению без ориентации и нажатого состояния.</span><span class="sxs-lookup"><span data-stu-id="557e2-260">For each hand that HoloLens detects, you can access its position without orientation and its pressed state.</span></span> <span data-ttu-id="557e2-261">Когда рука приближается к краю рамки жеста, вам также предоставляется вектор направления, который вы можете показать пользователю. Так он узнает, как переместить руку, чтобы вернуть ее туда, где она будет видна для HoloLens.</span><span class="sxs-lookup"><span data-stu-id="557e2-261">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="557e2-262">Рамка жестов</span><span class="sxs-lookup"><span data-stu-id="557e2-262">Gesture frame</span></span>
<span data-ttu-id="557e2-263">Для жестов в HoloLens необходимо находиться в пределах рамки жеста, в диапазоне, в котором камеры с сенсорным входом могут видеть соответствующим образом, от нос до уши и между плечи.</span><span class="sxs-lookup"><span data-stu-id="557e2-263">For gestures on HoloLens, the hand must be within a gesture frame, in a range that the gesture-sensing cameras can see appropriately,  from nose to waist and between the shoulders.</span></span> <span data-ttu-id="557e2-264">Пользователи должны быть обучены в этой области распознавания как для успеха, так и для собственной работы.</span><span class="sxs-lookup"><span data-stu-id="557e2-264">Users need to be trained on this area of recognition both for success of action and for their own comfort.</span></span> <span data-ttu-id="557e2-265">Многие пользователи изначально предполагают, что рамка жеста должна находиться в пределах своего представления через HoloLens и держать свои руки некомфортными для взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="557e2-265">Many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact.</span></span> <span data-ttu-id="557e2-266">При использовании щелчка HoloLens необязательно, чтобы руки находящихся внутри рамки жеста.</span><span class="sxs-lookup"><span data-stu-id="557e2-266">When using the HoloLens Clicker, it's not necessary for hands to be within the gesture frame.</span></span>

<span data-ttu-id="557e2-267">В частности, в случае с непрерывными жестами пользователь может переместить свои руки за пределы рамки жеста при перемещении holographic-объекта, например, и потерять предполагаемый результат.</span><span class="sxs-lookup"><span data-stu-id="557e2-267">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture when moving a holographic object, for example, and losing their intended outcome.</span></span>

<span data-ttu-id="557e2-268">Есть три вещи, которые необходимо рассмотреть:</span><span class="sxs-lookup"><span data-stu-id="557e2-268">There are three things that you should consider:</span></span>

- <span data-ttu-id="557e2-269">Обучение пользователей на существовании и приблизительных границах рамки жеста.</span><span class="sxs-lookup"><span data-stu-id="557e2-269">User education on the gesture frame's existence and approximate boundaries.</span></span> <span data-ttu-id="557e2-270">Это научилось во время установки HoloLens.</span><span class="sxs-lookup"><span data-stu-id="557e2-270">This is taught during HoloLens setup.</span></span>

- <span data-ttu-id="557e2-271">Уведомление пользователей о том, что их жесты близки или нарушают границы кадра жестов в пределах приложения до степени, в которой потерянный жест ведет к нежелательным результатам.</span><span class="sxs-lookup"><span data-stu-id="557e2-271">Notifying users when their gestures are nearing or breaking the gesture frame boundaries within an application to the degree that a lost gesture leads to undesired outcomes.</span></span> <span data-ttu-id="557e2-272">Исследование показало Ключевые качества такой системы уведомлений.</span><span class="sxs-lookup"><span data-stu-id="557e2-272">Research has shown the key qualities of such a notification system.</span></span> <span data-ttu-id="557e2-273">Оболочка HoloLens предоставляет хороший пример такого типа уведомления — визуальный элемент, расположенный в центральном курсоре, указывающий направление пересечения границ.</span><span class="sxs-lookup"><span data-stu-id="557e2-273">The HoloLens shell provides a good example of this type of notification--visual, on the central cursor, indicating the direction in which boundary crossing is taking place.</span></span>

- <span data-ttu-id="557e2-274">Последствия нарушения границ рамки жеста должны быть сведены к минимуму.</span><span class="sxs-lookup"><span data-stu-id="557e2-274">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="557e2-275">В общем случае это означает, что результат жеста должен быть остановлен на границе, а не на противоположный.</span><span class="sxs-lookup"><span data-stu-id="557e2-275">In general, this means that the outcome of a gesture should be stopped at the boundary, and not reversed.</span></span> <span data-ttu-id="557e2-276">Например, если пользователь перемещает несколько holographic объектов в комнате, перемещение должно прерываться при нарушении рамки жеста и не возвращаться к начальной точке.</span><span class="sxs-lookup"><span data-stu-id="557e2-276">For example, if a user is moving some holographic object across a room, the movement should stop when the gesture frame is breached, and not returned to the starting point.</span></span> <span data-ttu-id="557e2-277">Пользователь может столкнуться с неудовлетворенностью, но может более быстро понять границы и не должен каждый раз перезапускать все запланированные действия.</span><span class="sxs-lookup"><span data-stu-id="557e2-277">The user might experience some frustration, but might more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="557e2-278">См. также</span><span class="sxs-lookup"><span data-stu-id="557e2-278">See also</span></span>
* [<span data-ttu-id="557e2-279">Непосредственное манипулирование с использованием рук</span><span class="sxs-lookup"><span data-stu-id="557e2-279">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="557e2-280">Наведение и фиксация с использованием рук</span><span class="sxs-lookup"><span data-stu-id="557e2-280">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="557e2-281">Инстинктивное взаимодействие</span><span class="sxs-lookup"><span data-stu-id="557e2-281">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="557e2-282">Направление головы и остановка</span><span class="sxs-lookup"><span data-stu-id="557e2-282">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="557e2-283">Голосовые команды</span><span class="sxs-lookup"><span data-stu-id="557e2-283">Voice commanding</span></span>](voice-design.md)





