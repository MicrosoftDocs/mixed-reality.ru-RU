---
title: Направление головы и фиксация
description: Общие сведения о модели направления головы и фиксации
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: Смешанная реальность, взгляд, нацеливание взглядом, взаимодействие, проектирование
ms.openlocfilehash: d9eae3c0cfceba7c2c31425941dfce865f3aa609
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/05/2019
ms.locfileid: "66692310"
---
# <a name="head-gaze-and-commit"></a>Направление головы и фиксация
"Направление головы и фиксация" — это модель ввода данных, которая включает в себя нацеливание на объект, направляя голову вперед, (направление головы) и выполнение с объектом действия с помощью вторичного ввода, например с помощью жеста касания или голосовой команды "Выбрать". Она считается моделью "дальнего" ввода с косвенным манипулированием. Это означает, что ее лучше всего использовать для взаимодействия с содержимым, которое находится за пределами досягаемости.

## <a name="device-support"></a>Поддержка устройств

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>Модель ввода</strong></td>
        <td><a href="hololens-hardware-details.md"><strong>HoloLens (1-го поколения)</strong></a></td>
        <td><strong>HoloLens 2</strong></td>
        <td><a href="immersive-headset-hardware-details.md"><strong>Иммерсивные гарнитуры</strong></a></td>
    </tr>
     <tr>
        <td>Направление головы и фиксация</td>
        <td>✔️ Рекомендуется</td>
        <td>✔ Рекомендуется (третий вариант <a href="interaction-fundamentals.md">см. в разделе других возможностей</a>)</td>
        <td>➕ Альтернативный вариант</td>
    </tr>
</table>

## <a name="head-gaze"></a>Направление головы
Гарнитура смешанной реальности использует положение и ориентацию головы пользователя для определения вектора направления головы. Ее можно представить как лазер, который указывает прямо вперед из точки между глаз пользователя. Это довольно приблизительная оценка того, куда смотрит пользователь. Приложение может скрещивать этот луч с виртуальными или реальными объектами и переводить курсор в это положение, чтобы сообщить пользователю, на что он сейчас нацелен.

В дополнение к направлению головы некоторые гарнитуры смешанной реальности, например HoloLens 2, содержат в себе системы отслеживания, которые создают вектор направления глаз. Это обеспечивает высокоточное измерение направления взгляда пользователя. Создавать направления и фиксировать взаимодействия с помощью взгляда возможно, но это подразумевает совершенно другой ряд ограничений дизайна, который рассматривается отдельно в [статье об отслеживании глаз](eye-tracking.md).

## <a name="commit"></a>Фиксация
Нацелившись на объект или элемент интерфейса, пользователь может взаимодействовать с ним или "щелкнуть" по нему с помощью вторичного ввода. В этой модели это называется шагом фиксации. Поддерживаются следующие методы фиксации:

- жест касания;
- произнесение голосовой команды "Выбрать" или одной из целевых голосовых команд;
- нажатие отдельной клавиши на [HoloLens Clicker](hardware-accessories.md#hololens-clicker) (Датчик HoloLens);
- нажатие кнопки "А" на геймпаде Xbox;
- нажатие кнопки "А" на адаптивном контроллере Xbox.

### <a name="head-gaze-and-air-tap-gesture"></a>Направление головы и жест касания
Касание — это жест касания с положением руки вертикально. Чтобы выполнить жест касания, поднимите указательный палец в положение готовности, затем соедините его с большим пальцем и снова поднимите указательный палец. На HoloLens 1 касание — наиболее распространенный вид вторичного ввода.

![Палец в положении готовности, а затем движения касания или щелчка](images/readyandpress.jpg)<br>

Касание также доступно в HoloLens 2. Оно было "ослаблено" относительно изначальной версии. Сейчас поддерживаются практически все типы жестов сжатия, если только рука расположена вертикально в фиксированном положении. Это значительно упрощает для пользователей знакомство с жестом и его использование.  Новый жест касания заменяет предыдущий по тому же API, поэтому новое поведение появится в существующих приложениях автоматически после перекомпиляции под HoloLens 2.

### <a name="head-gaze-and-select-voice-command"></a>Направление головы и голосовая команда "Выбрать"
Голосовые команды — это один из основных методов взаимодействия в смешанной реальности. Он предоставляет достаточно мощный механизм работы "без рук" для контроля системы. Существуют разные типы моделей голосового взаимодействия:

- общая команда "Выбрать", которая позволяет выполнить "щелчок" или фиксацию в качестве вторичного ввода;
- объектные команды, например "Закрыть" или "Сделайте крупнее", которые позволяют выполнять и фиксировать действия в качестве вторичного ввода;
- глобальные команды, например "Перейти к началу", которые не требуют цели;
- диалоговые пользовательские интерфейсы или такие сущности, как "Кортана", которые содержат ИИ-возможность естественного языка;
- пользовательские команды.

Дополнительные сведения и исчерпывающий список доступных команд, а также инструкции по их использованию см. в руководстве по [голосовым командам](voice-design.md).


### <a name="head-gaze-and-hololens-clicker"></a>Направление головы и HoloLens Clicker (Датчик HoloLens)
HoloLens Clicker (Датчик HoloLens) — это первое периферийное устройство, созданное специально для HoloLens, которое включено в выпуск Development Edition HoloLens 1. HoloLens Clicker позволяет пользователю выполнять "щелчки" с минимальным количеством движений рукой и осуществлять фиксацию в качестве вторичного ввода. HoloLens Clicker подключается к HoloLens 1 или 2 с помощью Bluetooth с низким энергопотреблением (BTLE).

![HoloLens Clicker](images/hololens-clicker-500px.jpg)<br>
*HoloLens Clicker*

Дополнительные сведения и инструкции по связыванию устройства см. [здесь](hardware-accessories.md#pairing-bluetooth-accessories).




### <a name="head-gaze-and-xbox-wireless-controller"></a>Направление головы и беспроводной контроллер Xbox
Беспроводной контроллер Xbox позволяет выполнять действие "щелчок" в качестве вторичного ввода с помощью кнопки "A". Устройство связано с набором действий по умолчанию, которые помогают переходить по системе и управлять ей. Если вы хотите настроить контроллер, используйте приложение Xbox Accesories, чтобы настроить свой беспроводной контроллер Xbox.

![Беспроводной контроллер Xbox](images/xboxcontroller.jpg)<br>
*Беспроводной контроллер Xbox*

[Связывание контроллера Xbox с компьютером](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a>Направление головы и адаптивный контроллер Xbox
Адаптивный контроллер Xbox — это унифицированный концентратор для устройств, помогающий сделать смешанную реальность более доступной, который разработан преимущественно для геймеров с ограниченной подвижностью.

Адаптивный контроллер Xbox позволяет выполнять действие "щелчок" в качестве вторичного ввода с помощью кнопки "A". Устройство связано с набором действий по умолчанию, которые помогают переходить по системе и управлять ей. Если вы хотите настроить контроллер, используйте приложение Xbox Accesories, чтобы настроить свой адаптивный контроллер Xbox.

![Адаптивный контроллер Xbox](images/xbox-adaptive-controller-devices.jpg)<br>
*Адаптивный контроллер Xbox*

Подключайте внешние устройства, например переключатели, кнопки, держатели и джойстики, чтобы создать уникальный интерфейс контроллера, который идеально соответствует вашим требованиям. Ввод с помощью кнопки, аналогового стика и триггера контролируется вспомогательными устройствами, подключенными через разъемы 3,5 мм и USB-порты.

![Порты адаптивного контроллера Xbox](images/xbox-adaptive-controller-ports.jpg)<br>
*Порты адаптивного контроллера Xbox*

[Инструкции по связыванию устройства](hardware-accessories.md#pairing-bluetooth-accessories)

<a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Дополнительные сведения доступны на сайте Xbox</a>


## <a name="design-guidelines"></a>Рекомендации по проектированию
> [!NOTE]
> [В ближайшее время](index.md) появятся дополнительные руководства, касающиеся дизайна механизма отслеживания взгляда.

## <a name="head-gaze-targeting"></a>Нацеливание направлением головы
Все взаимодействия построены на базе возможности пользователя нацеливаться на элемент, с которым они хотят взаимодействовать, независимо от модальности ввода. В Windows Mixed Reality это обычно делается с помощью взгляда пользователя.
Чтобы пользователь получил возможность успешно работать с интерфейсом, рассчитанное понимание системой намерения пользователя и действительное намерение пользователя должны совпадать как можно точнее. Удовлетворенность пользователя возрастает и производительность повышается настолько, насколько система правильно распознает намерения пользователя.


## <a name="target-sizing-and-feedback"></a>Изменение размера цели и обратная связь
Вектор взгляда многократно успешно срабатывал при нацеливании на мелкие объекты, но зачастую он работает наилучшим образом при крупноразмерном нацеливании (определении в качестве цели больших объектов). Минимальные размеры цели 1–1,5 градуса позволяют пользователю успешно выполнять действия в большинстве случаев, однако цели размером 3 градуса зачастую обеспечивают большую скорость. Обратите внимание, что пользовательские цели — это фактически двумерная область, даже если это трехмерный элемент: проекция, которая обращена к пользователю, будет областью, на которую можно нацелиться. Предоставление явного указания того, что элемент "активен" (пользователь нацелен на него), крайне полезно. Таким указанием может быть видимый эффект "зависания", аудио подсказки или щелчки, а также четкое выравнивание курсора по элементу.

![Оптимальный размер целевого объекта на расстоянии 2 метра](images/gazetargeting-size-1000px.jpg)<br>
*Оптимальный размер целевого объекта на расстоянии 2 метра*

![Пример выделения выбранного взглядом целевого объекта](images/gazetargeting-highlighting-640px.jpg)<br>
*Пример выделения выбранного взглядом целевого объекта*

## <a name="target-placement"></a>Размещение цели
У пользователей часто не получается найти элементы интерфейса, расположенные очень высоко или очень низко в поле зрения, поскольку они фокусируют большую часть своего внимания на областях вокруг своей основной цели (обычно приблизительно на уровне глаз). Размещение большинства целей в приемлемом диапазоне примерно на уровне глаз может исправить ситуацию. Учитывая склонность пользователей в любой момент фокусироваться на относительно небольшой визуальной области (область фокусировки внимания в поле зрения составляет приблизительно 10 градусов), группирование элементов интерфейса в такой мере, чтобы они были концептуально связаны, может задействовать поведение, связанное с перемещением внимания с объекта на объект, по мере перемещения взгляда пользователя по области. При разработке интерфейса учитывайте возможные значительные отклонения в поле зрения HoloLens и иммерсивной гарнитуры.

![Пример сгруппированных элементов интерфейса для упрощения нацеливания взглядом в Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)<br>
*Пример сгруппированных элементов интерфейса для упрощения нацеливания взглядом в Galaxy Explorer*

## <a name="improving-targeting-behaviors"></a>Улучшение поведения выбора цели
Если намерение пользователя нацелиться на что-либо можно определить (или оценить с достаточной точностью), может быть полезно принимать попытки взаимодействия с "близким прохождением" за такие, что были нацелены правильно. Существует несколько успешных методов, которые можно внедрить в интерфейсы смешанной реальности.

### <a name="head-gaze-stabilization-gravity-wells"></a>Стабилизация направления головы ("колодцы гравитации")
Это должно быть включено большую часть времени или все время. Эта технология позволяет исключить естественные подергивания головы и шеи, которые могут возникать у пользователей. Также движения из-за перемещения взгляда или говорения.

### <a name="closest-link-algorithms"></a>Алгоритмы ближайшего звена
Они лучше всего работают в областях с разреженным интерактивным содержимым. Если существует высокая вероятность того, что вы можете определить, с чем пользователь намеревался взаимодействовать, вы можете дополнить его возможности нацеливания с помощью простого взятия на себя определенного уровня намерения.

### <a name="backdatingpostdating-actions"></a>Датирование действий прошлым/будущим числом
Этот механизм полезен для задач, требующих скорости. Когда пользователь осуществляет ряд маневров по нацеливанию/активации на высокой скорости, может быть полезно взять на себя часть намерения и позволить пропущенным шагам быть примененными к целям, которые были в фокусе пользователя немного раньше или немного позже нажатия (при раннем тестировании эффективным показателем было 50 мс).

### <a name="smoothing"></a>Сглаживание
Этот механизм полезен для создания пути движений с уменьшением незначительных подергиваний/качаний, вызванных естественными характеристиками движений головы. При сглаживании движений создания пути сглаживайте по размеру/расстоянию движения, а не по времени.

### <a name="magnetism"></a>Магнитность
Этот механизм можно рассматривать как более общую версию алгоритмов ближайшего звена: подведение курсора к цели и простое увеличение области задействования (как видимой, так и невидимой) при приближении пользователя к вероятной цели, использование определенных знаний о структуре для улучшения определения намерения пользователя. Это может быть особенно эффективно для небольших целей.

### <a name="focus-stickiness"></a>Закрепление фокуса
Предоставьте текущему элементу в фокусе преимущество при определении, на какой ближайший интерактивный элемент перевести фокус. Это поможет снизить уровень хаотичной смены фокуса при остановке посередине между двумя элементами с естественным шумом.


## <a name="composite-gestures"></a>Составные жесты
Приложения могут распознавать не только отдельные касания. Более сложные составные жесты можно выполнять, комбинируя нажатие, удерживание и высвобождение с движением руки. Эти составные или высокоуровневые жесты основываются на низкоуровневых данных пространственного ввода (например, касание и раскрытие ладони), к которым у разработчиков есть доступ.

### <a name="air-tap"></a>Жест касания
Жест касания (а также другие жесты, приведенные ниже) реагирует только на определенное касание. Для определения других касаний, таких как "Меню" или "Захват", приложение должно непосредственно использовать взаимодействия более низкого уровня, описанные в разделе о двух ключевых жестах компонентов выше.

### <a name="tap-and-hold"></a>Tap and hold
Удерживание — это просто удержание пальца в опущенном положении после касания. Различные более сложные взаимодействия "щелкнуть и перетянуть" можно выполнять благодаря комбинации жеста касания и удерживания в сочетании с движением руки, таким как поднятие объекта вместо активации или вторичные взаимодействия "клацанье мышью", например открытие контекстного меню.
Однако при разработке этого жеста следует соблюдать осторожность, поскольку пользователи могут быть склонны к расслаблению позы рук во время любого расширенного жеста.

### <a name="manipulation"></a>Управление
Управление жестами можно использовать для перемещения, изменения размера или поворота голограммы, когда вы хотите, чтобы голограмма реагировала 1:1 на движения руки пользователя. Одно из применений таких движений 1:1 позволяет пользователю только рисовать или вписывать красками.
Первоначальное нацеливание для жеста управления должно быть исполнено взглядом или указанием. Как только начинается касание и удерживание, любые операции с объектом обрабатываются движениями руки, позволяя пользователю в это время осмотреться.

### <a name="navigation"></a>Навигация
Жесты навигации работают как виртуальный джойстик и могут использоваться для навигации по мини-приложениям пользовательского интерфейса, таким как радиальные меню. Вы касаетесь и удерживаете, чтобы начать жест, а затем двигаете рукой в нормализованном трехмерном кубе, центрированном вокруг начального нажатия. Вы можете перемещать руку вдоль оси X, Y или Z от значения –1 до 1, где 0 является начальной точкой.
Навигация может использоваться для создания жестов непрерывной прокрутки или масштабирования на основе скорости, аналогично прокрутке 2D-интерфейса путем нажатия средней кнопки мыши и последующего перемещения мыши вверх и вниз.

Навигация с направляющими относится к способности распознавать движения по определенной оси, пока на этой оси не будет достигнут определенный порог. Это полезно только тогда, когда разработчиком разрешено перемещение по нескольким осям в приложении, например если приложение настроено на распознавание жестов навигации по оси X, Y, а также по оси X с направляющими. В этом случае система будет распознавать движения рук по оси X, пока они находятся на воображаемых направляющих по оси X, если руки также двигаются по оси Y.

В 2D-приложениях пользователи могут использовать жесты вертикальной навигации для прокрутки, масштабирования или перетаскивания внутри приложения. Это вводит в приложение виртуальные касания пальцем, чтобы имитировать сенсорные жесты того же типа. Пользователи могут выбрать любое из этих действий, переключаясь между инструментами на панели над приложением, либо нажимая кнопку, либо говоря "<Прокрутить/Перетащить/Увеличить> инструмент".

[Дополнительные сведения о составных жестах](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a>Распознаватели жестов

Одно из преимуществ использования распознавания жестов состоит в том, что вы можете настроить распознаватель жестов только для тех жестов, которые может принять намеченная голограмма. Платформа будет выполнять только устранение неоднозначности, необходимое для различения этих конкретных поддерживаемых жестов. Таким образом, голограмма, которая просто поддерживает касание, может допускать любой промежуток времени между нажатием и высвобождением. В то же время голограмма, которая поддерживает как нажатие, так и высвобождение, может переводить нажатие на удерживание после порога времени удержания.

## <a name="hand-recognition"></a>Распознавание рук
HoloLens распознает жесты рук, отслеживая положение одной или обеих рук, которые видимые устройству. Руки видны для HoloLens, когда они находятся в состоянии готовности (задняя часть руки обращена к вам указательным пальцем вверх) или в нажатом состоянии (задняя часть руки обращена к вам указательным пальцем вниз). Когда руки находятся в других позах, они будут проигнорированные HoloLens.
Вы можете получить доступ к положению (без ориентации) и нажатому состоянию каждой руки, обнаруженной HoloLens. Когда рука приближается к краю рамки жеста, вам также предоставляется вектор направления, который вы можете показать пользователю. Так он узнает, как переместить руку, чтобы вернуть ее туда, где она будет видна для HoloLens.

## <a name="gesture-frame"></a>Рамка жестов
Чтобы сделать жест на HoloLens, рука должна находиться в "рамке жестов", в диапазоне, который могут воспринимать чувствительные к жестам камеры (очень приблизительно от носа до талии и между плечами). Пользователи должны быть обучены в этой области распознавания как для успешных действий, так и для их собственного комфорта (многие пользователи изначально предполагают, что рамка жестов должна быть в пределах их видения в HoloLens, и неудобно держат руки при взаимодействиях). При использовании HoloLens Clicker ваши руки не должны находиться в рамке жеста.

В частности, в случае непрерывных жестов существует некоторый риск того, что пользователи переместят свои руки за пределы рамки жеста, находясь в середине жеста (например, при перемещении какого-либо голографического объекта), и потеряют ожидаемый результат.

Есть три вещи, которые необходимо рассмотреть:

- Обучение пользователей существованию рамки жестов и приблизительным границам (этому учат во время установки HoloLens).

- Уведомление пользователям, когда их жесты приближаются/нарушают границы рамки жестов в приложении в той степени, в которой неправильный жест приведет к нежелательным результатам. Исследования показали ключевые качества такой системы уведомлений. Оболочка HoloLens представляет собой наглядный пример такого типа уведомлений (визуального, на центральном курсоре, указывающем направление, в котором происходит пересечение границы).

- Последствия нарушения границ рамки жеста должны быть сведены к минимуму. В общем, это означает, что результат жеста должен быть остановлен на границе, а не возвращен в начальную точку. Например, если пользователь перемещает некий голографический объект по комнате, движение должно прекратиться, когда будет пересечена рамка жеста, а не возвращено в начальную точку. В этом случае пользователь может испытывать некоторое разочарование, но может быстрее усвоить границы, и ему не придется каждый раз начинать сначала все свои предполагаемые действия.


## <a name="see-also"></a>См. также статью
* [Непосредственное манипулирование с использованием рук](direct-manipulation.md)
* [Наведение и фиксация с использованием рук](point-and-commit.md)
* [Инстинктивное взаимодействие](interaction-fundamentals.md)
* [Направление головы и остановка](gaze-and-dwell.md)
* [Голосовые команды](voice-design.md)





