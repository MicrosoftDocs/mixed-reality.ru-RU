---
title: Направление головы и фиксация
description: Общие сведения о модели направления головы и фиксации
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: Смешанная реальность, взгляд, нацеливание взглядом, взаимодействие, проектирование
ms.openlocfilehash: d9eae3c0cfceba7c2c31425941dfce865f3aa609
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/05/2019
ms.locfileid: "66692310"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="1bedd-104">Направление головы и фиксация</span><span class="sxs-lookup"><span data-stu-id="1bedd-104">Head-gaze and commit</span></span>
<span data-ttu-id="1bedd-105">"Направление головы и фиксация" — это модель ввода данных, которая включает в себя нацеливание на объект, направляя голову вперед, (направление головы) и выполнение с объектом действия с помощью вторичного ввода, например с помощью жеста касания или голосовой команды "Выбрать".</span><span class="sxs-lookup"><span data-stu-id="1bedd-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input such as the hand gesture Air Tap or the voice command “Select”.</span></span> <span data-ttu-id="1bedd-106">Она считается моделью "дальнего" ввода с косвенным манипулированием. Это означает, что ее лучше всего использовать для взаимодействия с содержимым, которое находится за пределами досягаемости.</span><span class="sxs-lookup"><span data-stu-id="1bedd-106">It is considered a "far" input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="1bedd-107">Поддержка устройств</span><span class="sxs-lookup"><span data-stu-id="1bedd-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="1bedd-108"><strong>Модель ввода</strong></span><span class="sxs-lookup"><span data-stu-id="1bedd-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="1bedd-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1-го поколения)</strong></a></span><span class="sxs-lookup"><span data-stu-id="1bedd-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="1bedd-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="1bedd-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="1bedd-111"><a href="immersive-headset-hardware-details.md"><strong>Иммерсивные гарнитуры</strong></a></span><span class="sxs-lookup"><span data-stu-id="1bedd-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="1bedd-112">Направление головы и фиксация</span><span class="sxs-lookup"><span data-stu-id="1bedd-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="1bedd-113">✔️ Рекомендуется</span><span class="sxs-lookup"><span data-stu-id="1bedd-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="1bedd-114">✔ Рекомендуется (третий вариант <a href="interaction-fundamentals.md">см. в разделе других возможностей</a>)</span><span class="sxs-lookup"><span data-stu-id="1bedd-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="1bedd-115">➕ Альтернативный вариант</span><span class="sxs-lookup"><span data-stu-id="1bedd-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="1bedd-116">Направление головы</span><span class="sxs-lookup"><span data-stu-id="1bedd-116">Head-gaze</span></span>
<span data-ttu-id="1bedd-117">Гарнитура смешанной реальности использует положение и ориентацию головы пользователя для определения вектора направления головы.</span><span class="sxs-lookup"><span data-stu-id="1bedd-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="1bedd-118">Ее можно представить как лазер, который указывает прямо вперед из точки между глаз пользователя.</span><span class="sxs-lookup"><span data-stu-id="1bedd-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="1bedd-119">Это довольно приблизительная оценка того, куда смотрит пользователь.</span><span class="sxs-lookup"><span data-stu-id="1bedd-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="1bedd-120">Приложение может скрещивать этот луч с виртуальными или реальными объектами и переводить курсор в это положение, чтобы сообщить пользователю, на что он сейчас нацелен.</span><span class="sxs-lookup"><span data-stu-id="1bedd-120">Your application can intersect this ray with virtual or real-world objects and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="1bedd-121">В дополнение к направлению головы некоторые гарнитуры смешанной реальности, например HoloLens 2, содержат в себе системы отслеживания, которые создают вектор направления глаз.</span><span class="sxs-lookup"><span data-stu-id="1bedd-121">In addition to head gaze, some mixed reality headsets like the HoloLens 2 include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="1bedd-122">Это обеспечивает высокоточное измерение направления взгляда пользователя.</span><span class="sxs-lookup"><span data-stu-id="1bedd-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="1bedd-123">Создавать направления и фиксировать взаимодействия с помощью взгляда возможно, но это подразумевает совершенно другой ряд ограничений дизайна, который рассматривается отдельно в [статье об отслеживании глаз](eye-tracking.md).</span><span class="sxs-lookup"><span data-stu-id="1bedd-123">It is possible to build gaze and commit interactions using eye gaze, but this comes with a very different set of design constraints, which will be covered separately in the [eye tracking article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="1bedd-124">Фиксация</span><span class="sxs-lookup"><span data-stu-id="1bedd-124">Commit</span></span>
<span data-ttu-id="1bedd-125">Нацелившись на объект или элемент интерфейса, пользователь может взаимодействовать с ним или "щелкнуть" по нему с помощью вторичного ввода.</span><span class="sxs-lookup"><span data-stu-id="1bedd-125">After targeting an object or UI element, the user can interact or "click" on it using a secondary input.</span></span> <span data-ttu-id="1bedd-126">В этой модели это называется шагом фиксации.</span><span class="sxs-lookup"><span data-stu-id="1bedd-126">This is known as the commit step of the model.</span></span> <span data-ttu-id="1bedd-127">Поддерживаются следующие методы фиксации:</span><span class="sxs-lookup"><span data-stu-id="1bedd-127">The following commit methods are supported:</span></span>

- <span data-ttu-id="1bedd-128">жест касания;</span><span class="sxs-lookup"><span data-stu-id="1bedd-128">Air Tap gesture</span></span>
- <span data-ttu-id="1bedd-129">произнесение голосовой команды "Выбрать" или одной из целевых голосовых команд;</span><span class="sxs-lookup"><span data-stu-id="1bedd-129">Speak the voice command "Select" or one of the targeted voice commands</span></span>
- <span data-ttu-id="1bedd-130">нажатие отдельной клавиши на [HoloLens Clicker](hardware-accessories.md#hololens-clicker) (Датчик HoloLens);</span><span class="sxs-lookup"><span data-stu-id="1bedd-130">Press the single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="1bedd-131">нажатие кнопки "А" на геймпаде Xbox;</span><span class="sxs-lookup"><span data-stu-id="1bedd-131">Press the 'A' button on an Xbox Gamepad</span></span>
- <span data-ttu-id="1bedd-132">нажатие кнопки "А" на адаптивном контроллере Xbox.</span><span class="sxs-lookup"><span data-stu-id="1bedd-132">Press the 'A' button on an Xbox Adaptive Controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="1bedd-133">Направление головы и жест касания</span><span class="sxs-lookup"><span data-stu-id="1bedd-133">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="1bedd-134">Касание — это жест касания с положением руки вертикально.</span><span class="sxs-lookup"><span data-stu-id="1bedd-134">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="1bedd-135">Чтобы выполнить жест касания, поднимите указательный палец в положение готовности, затем соедините его с большим пальцем и снова поднимите указательный палец.</span><span class="sxs-lookup"><span data-stu-id="1bedd-135">To perform an Air tap, raise your index finger to the ready position, then pinch with your thumb and raise your index finger back up to release.</span></span> <span data-ttu-id="1bedd-136">На HoloLens 1 касание — наиболее распространенный вид вторичного ввода.</span><span class="sxs-lookup"><span data-stu-id="1bedd-136">On HoloLens 1, Air tap is the most common secondary input.</span></span>

![Палец в положении готовности, а затем движения касания или щелчка](images/readyandpress.jpg)<br>

<span data-ttu-id="1bedd-138">Касание также доступно в HoloLens 2. Оно было "ослаблено" относительно изначальной версии.</span><span class="sxs-lookup"><span data-stu-id="1bedd-138">Air tap is also available on HoloLens 2, and it has been relaxed from the original version.</span></span> <span data-ttu-id="1bedd-139">Сейчас поддерживаются практически все типы жестов сжатия, если только рука расположена вертикально в фиксированном положении.</span><span class="sxs-lookup"><span data-stu-id="1bedd-139">Nearly all types of pinches are now supported, as long as the hand is upright and holding still.</span></span> <span data-ttu-id="1bedd-140">Это значительно упрощает для пользователей знакомство с жестом и его использование.</span><span class="sxs-lookup"><span data-stu-id="1bedd-140">This makes it much easier for users to learn and perform the gesture.</span></span>  <span data-ttu-id="1bedd-141">Новый жест касания заменяет предыдущий по тому же API, поэтому новое поведение появится в существующих приложениях автоматически после перекомпиляции под HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="1bedd-141">This new Air tap replaces the old one through the same API, so existing applications will get the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="1bedd-142">Направление головы и голосовая команда "Выбрать"</span><span class="sxs-lookup"><span data-stu-id="1bedd-142">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="1bedd-143">Голосовые команды — это один из основных методов взаимодействия в смешанной реальности.</span><span class="sxs-lookup"><span data-stu-id="1bedd-143">Voice commanding is one of the primary interaction methods on Mixed Reality.</span></span> <span data-ttu-id="1bedd-144">Он предоставляет достаточно мощный механизм работы "без рук" для контроля системы.</span><span class="sxs-lookup"><span data-stu-id="1bedd-144">It provides a very powerful "Hands Free" mechanism to control the system.</span></span> <span data-ttu-id="1bedd-145">Существуют разные типы моделей голосового взаимодействия:</span><span class="sxs-lookup"><span data-stu-id="1bedd-145">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="1bedd-146">общая команда "Выбрать", которая позволяет выполнить "щелчок" или фиксацию в качестве вторичного ввода;</span><span class="sxs-lookup"><span data-stu-id="1bedd-146">The generic command "Select" that allows to perform a "click" actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="1bedd-147">объектные команды, например "Закрыть" или "Сделайте крупнее", которые позволяют выполнять и фиксировать действия в качестве вторичного ввода;</span><span class="sxs-lookup"><span data-stu-id="1bedd-147">Object commands like "Close" or "Make it bigger" that allow to perform and commit to an action as a secondary input.</span></span>
- <span data-ttu-id="1bedd-148">глобальные команды, например "Перейти к началу", которые не требуют цели;</span><span class="sxs-lookup"><span data-stu-id="1bedd-148">Global commnads like "Go to start" that don't require a target.</span></span>
- <span data-ttu-id="1bedd-149">диалоговые пользовательские интерфейсы или такие сущности, как "Кортана", которые содержат ИИ-возможность естественного языка;</span><span class="sxs-lookup"><span data-stu-id="1bedd-149">Conversation user interfaces or entities like Cortana that have an AI Natural Language capability.</span></span>
- <span data-ttu-id="1bedd-150">пользовательские команды.</span><span class="sxs-lookup"><span data-stu-id="1bedd-150">Custom commnads</span></span>

<span data-ttu-id="1bedd-151">Дополнительные сведения и исчерпывающий список доступных команд, а также инструкции по их использованию см. в руководстве по [голосовым командам](voice-design.md).</span><span class="sxs-lookup"><span data-stu-id="1bedd-151">To find more details and a comprenhesive list of available commands and how to use, check out our [voice commanding](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="1bedd-152">Направление головы и HoloLens Clicker (Датчик HoloLens)</span><span class="sxs-lookup"><span data-stu-id="1bedd-152">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="1bedd-153">HoloLens Clicker (Датчик HoloLens) — это первое периферийное устройство, созданное специально для HoloLens, которое включено в выпуск Development Edition HoloLens 1.</span><span class="sxs-lookup"><span data-stu-id="1bedd-153">The HoloLens Clicker is the first peripheral device built specifically for HoloLens and is included with the HoloLens 1 Development Edition.</span></span> <span data-ttu-id="1bedd-154">HoloLens Clicker позволяет пользователю выполнять "щелчки" с минимальным количеством движений рукой и осуществлять фиксацию в качестве вторичного ввода.</span><span class="sxs-lookup"><span data-stu-id="1bedd-154">The HoloLens Clicker allows a user to click with minimal hand motion and commit as a secondary input.</span></span> <span data-ttu-id="1bedd-155">HoloLens Clicker подключается к HoloLens 1 или 2 с помощью Bluetooth с низким энергопотреблением (BTLE).</span><span class="sxs-lookup"><span data-stu-id="1bedd-155">The HoloLens clicker connects to the HoloLens 1 or 2 using Bluetooth Low Energy (BTLE).</span></span>

<span data-ttu-id="1bedd-156">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span><span class="sxs-lookup"><span data-stu-id="1bedd-156">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span></span><br>
<span data-ttu-id="1bedd-157">*HoloLens Clicker*</span><span class="sxs-lookup"><span data-stu-id="1bedd-157">*HoloLens Clicker*</span></span>

<span data-ttu-id="1bedd-158">Дополнительные сведения и инструкции по связыванию устройства см. [здесь](hardware-accessories.md#pairing-bluetooth-accessories).</span><span class="sxs-lookup"><span data-stu-id="1bedd-158">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="1bedd-159">Направление головы и беспроводной контроллер Xbox</span><span class="sxs-lookup"><span data-stu-id="1bedd-159">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="1bedd-160">Беспроводной контроллер Xbox позволяет выполнять действие "щелчок" в качестве вторичного ввода с помощью кнопки "A".</span><span class="sxs-lookup"><span data-stu-id="1bedd-160">The Xbox Wireless Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="1bedd-161">Устройство связано с набором действий по умолчанию, которые помогают переходить по системе и управлять ей.</span><span class="sxs-lookup"><span data-stu-id="1bedd-161">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="1bedd-162">Если вы хотите настроить контроллер, используйте приложение Xbox Accesories, чтобы настроить свой беспроводной контроллер Xbox.</span><span class="sxs-lookup"><span data-stu-id="1bedd-162">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Wireless Controller.</span></span>

<span data-ttu-id="1bedd-163">![Беспроводной контроллер Xbox](images/xboxcontroller.jpg)</span><span class="sxs-lookup"><span data-stu-id="1bedd-163">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span></span><br>
<span data-ttu-id="1bedd-164">*Беспроводной контроллер Xbox*</span><span class="sxs-lookup"><span data-stu-id="1bedd-164">*Xbox Wireless Controller*</span></span>

[<span data-ttu-id="1bedd-165">Связывание контроллера Xbox с компьютером</span><span class="sxs-lookup"><span data-stu-id="1bedd-165">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="1bedd-166">Направление головы и адаптивный контроллер Xbox</span><span class="sxs-lookup"><span data-stu-id="1bedd-166">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="1bedd-167">Адаптивный контроллер Xbox — это унифицированный концентратор для устройств, помогающий сделать смешанную реальность более доступной, который разработан преимущественно для геймеров с ограниченной подвижностью.</span><span class="sxs-lookup"><span data-stu-id="1bedd-167">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make Mixed Reality more accessible.</span></span>

<span data-ttu-id="1bedd-168">Адаптивный контроллер Xbox позволяет выполнять действие "щелчок" в качестве вторичного ввода с помощью кнопки "A".</span><span class="sxs-lookup"><span data-stu-id="1bedd-168">The Xbox Adaptive Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="1bedd-169">Устройство связано с набором действий по умолчанию, которые помогают переходить по системе и управлять ей.</span><span class="sxs-lookup"><span data-stu-id="1bedd-169">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="1bedd-170">Если вы хотите настроить контроллер, используйте приложение Xbox Accesories, чтобы настроить свой адаптивный контроллер Xbox.</span><span class="sxs-lookup"><span data-stu-id="1bedd-170">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Adaptive Controller.</span></span>

<span data-ttu-id="1bedd-171">![Адаптивный контроллер Xbox](images/xbox-adaptive-controller-devices.jpg)</span><span class="sxs-lookup"><span data-stu-id="1bedd-171">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span></span><br>
<span data-ttu-id="1bedd-172">*Адаптивный контроллер Xbox*</span><span class="sxs-lookup"><span data-stu-id="1bedd-172">*Xbox Adaptive Controller*</span></span>

<span data-ttu-id="1bedd-173">Подключайте внешние устройства, например переключатели, кнопки, держатели и джойстики, чтобы создать уникальный интерфейс контроллера, который идеально соответствует вашим требованиям.</span><span class="sxs-lookup"><span data-stu-id="1bedd-173">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controllers experience that is uniquely yours.</span></span> <span data-ttu-id="1bedd-174">Ввод с помощью кнопки, аналогового стика и триггера контролируется вспомогательными устройствами, подключенными через разъемы 3,5 мм и USB-порты.</span><span class="sxs-lookup"><span data-stu-id="1bedd-174">Button, thumbstick and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

<span data-ttu-id="1bedd-175">![Порты адаптивного контроллера Xbox](images/xbox-adaptive-controller-ports.jpg)</span><span class="sxs-lookup"><span data-stu-id="1bedd-175">![Xbox Adaptive Controller ports](images/xbox-adaptive-controller-ports.jpg)</span></span><br>
<span data-ttu-id="1bedd-176">*Порты адаптивного контроллера Xbox*</span><span class="sxs-lookup"><span data-stu-id="1bedd-176">*Xbox Adaptive Controller ports*</span></span>

[<span data-ttu-id="1bedd-177">Инструкции по связыванию устройства</span><span class="sxs-lookup"><span data-stu-id="1bedd-177">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="1bedd-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Дополнительные сведения доступны на сайте Xbox</a></span><span class="sxs-lookup"><span data-stu-id="1bedd-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


## <a name="design-guidelines"></a><span data-ttu-id="1bedd-179">Рекомендации по проектированию</span><span class="sxs-lookup"><span data-stu-id="1bedd-179">Design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="1bedd-180">[В ближайшее время](index.md) появятся дополнительные руководства, касающиеся дизайна механизма отслеживания взгляда.</span><span class="sxs-lookup"><span data-stu-id="1bedd-180">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="1bedd-181">Нацеливание направлением головы</span><span class="sxs-lookup"><span data-stu-id="1bedd-181">Head-gaze targeting</span></span>
<span data-ttu-id="1bedd-182">Все взаимодействия построены на базе возможности пользователя нацеливаться на элемент, с которым они хотят взаимодействовать, независимо от модальности ввода.</span><span class="sxs-lookup"><span data-stu-id="1bedd-182">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="1bedd-183">В Windows Mixed Reality это обычно делается с помощью взгляда пользователя.</span><span class="sxs-lookup"><span data-stu-id="1bedd-183">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="1bedd-184">Чтобы пользователь получил возможность успешно работать с интерфейсом, рассчитанное понимание системой намерения пользователя и действительное намерение пользователя должны совпадать как можно точнее.</span><span class="sxs-lookup"><span data-stu-id="1bedd-184">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent, and the user's actual intent, must align as closely as possible.</span></span> <span data-ttu-id="1bedd-185">Удовлетворенность пользователя возрастает и производительность повышается настолько, насколько система правильно распознает намерения пользователя.</span><span class="sxs-lookup"><span data-stu-id="1bedd-185">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="1bedd-186">Изменение размера цели и обратная связь</span><span class="sxs-lookup"><span data-stu-id="1bedd-186">Target sizing and feedback</span></span>
<span data-ttu-id="1bedd-187">Вектор взгляда многократно успешно срабатывал при нацеливании на мелкие объекты, но зачастую он работает наилучшим образом при крупноразмерном нацеливании (определении в качестве цели больших объектов).</span><span class="sxs-lookup"><span data-stu-id="1bedd-187">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting (acquiring somewhat larger targets).</span></span> <span data-ttu-id="1bedd-188">Минимальные размеры цели 1–1,5 градуса позволяют пользователю успешно выполнять действия в большинстве случаев, однако цели размером 3 градуса зачастую обеспечивают большую скорость.</span><span class="sxs-lookup"><span data-stu-id="1bedd-188">Minimum target sizes of 1 to 1.5 degrees should allow successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="1bedd-189">Обратите внимание, что пользовательские цели — это фактически двумерная область, даже если это трехмерный элемент: проекция, которая обращена к пользователю, будет областью, на которую можно нацелиться.</span><span class="sxs-lookup"><span data-stu-id="1bedd-189">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="1bedd-190">Предоставление явного указания того, что элемент "активен" (пользователь нацелен на него), крайне полезно. Таким указанием может быть видимый эффект "зависания", аудио подсказки или щелчки, а также четкое выравнивание курсора по элементу.</span><span class="sxs-lookup"><span data-stu-id="1bedd-190">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful - this can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="1bedd-191">![Оптимальный размер целевого объекта на расстоянии 2 метра](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="1bedd-191">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="1bedd-192">*Оптимальный размер целевого объекта на расстоянии 2 метра*</span><span class="sxs-lookup"><span data-stu-id="1bedd-192">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="1bedd-193">![Пример выделения выбранного взглядом целевого объекта](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="1bedd-193">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="1bedd-194">*Пример выделения выбранного взглядом целевого объекта*</span><span class="sxs-lookup"><span data-stu-id="1bedd-194">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="1bedd-195">Размещение цели</span><span class="sxs-lookup"><span data-stu-id="1bedd-195">Target placement</span></span>
<span data-ttu-id="1bedd-196">У пользователей часто не получается найти элементы интерфейса, расположенные очень высоко или очень низко в поле зрения, поскольку они фокусируют большую часть своего внимания на областях вокруг своей основной цели (обычно приблизительно на уровне глаз).</span><span class="sxs-lookup"><span data-stu-id="1bedd-196">Users will often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus (usually roughly eye level).</span></span> <span data-ttu-id="1bedd-197">Размещение большинства целей в приемлемом диапазоне примерно на уровне глаз может исправить ситуацию.</span><span class="sxs-lookup"><span data-stu-id="1bedd-197">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="1bedd-198">Учитывая склонность пользователей в любой момент фокусироваться на относительно небольшой визуальной области (область фокусировки внимания в поле зрения составляет приблизительно 10 градусов), группирование элементов интерфейса в такой мере, чтобы они были концептуально связаны, может задействовать поведение, связанное с перемещением внимания с объекта на объект, по мере перемещения взгляда пользователя по области.</span><span class="sxs-lookup"><span data-stu-id="1bedd-198">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="1bedd-199">При разработке интерфейса учитывайте возможные значительные отклонения в поле зрения HoloLens и иммерсивной гарнитуры.</span><span class="sxs-lookup"><span data-stu-id="1bedd-199">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="1bedd-200">![Пример сгруппированных элементов интерфейса для упрощения нацеливания взглядом в Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="1bedd-200">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="1bedd-201">*Пример сгруппированных элементов интерфейса для упрощения нацеливания взглядом в Galaxy Explorer*</span><span class="sxs-lookup"><span data-stu-id="1bedd-201">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="1bedd-202">Улучшение поведения выбора цели</span><span class="sxs-lookup"><span data-stu-id="1bedd-202">Improving targeting behaviors</span></span>
<span data-ttu-id="1bedd-203">Если намерение пользователя нацелиться на что-либо можно определить (или оценить с достаточной точностью), может быть полезно принимать попытки взаимодействия с "близким прохождением" за такие, что были нацелены правильно.</span><span class="sxs-lookup"><span data-stu-id="1bedd-203">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept "near miss" attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="1bedd-204">Существует несколько успешных методов, которые можно внедрить в интерфейсы смешанной реальности.</span><span class="sxs-lookup"><span data-stu-id="1bedd-204">There are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="1bedd-205">Стабилизация направления головы ("колодцы гравитации")</span><span class="sxs-lookup"><span data-stu-id="1bedd-205">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="1bedd-206">Это должно быть включено большую часть времени или все время.</span><span class="sxs-lookup"><span data-stu-id="1bedd-206">This should be turned on most/all of the time.</span></span> <span data-ttu-id="1bedd-207">Эта технология позволяет исключить естественные подергивания головы и шеи, которые могут возникать у пользователей.</span><span class="sxs-lookup"><span data-stu-id="1bedd-207">This technique removes the natural head/neck jitters that users may have.</span></span> <span data-ttu-id="1bedd-208">Также движения из-за перемещения взгляда или говорения.</span><span class="sxs-lookup"><span data-stu-id="1bedd-208">Also movement due to looking/speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="1bedd-209">Алгоритмы ближайшего звена</span><span class="sxs-lookup"><span data-stu-id="1bedd-209">Closest link algorithms</span></span>
<span data-ttu-id="1bedd-210">Они лучше всего работают в областях с разреженным интерактивным содержимым.</span><span class="sxs-lookup"><span data-stu-id="1bedd-210">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="1bedd-211">Если существует высокая вероятность того, что вы можете определить, с чем пользователь намеревался взаимодействовать, вы можете дополнить его возможности нацеливания с помощью простого взятия на себя определенного уровня намерения.</span><span class="sxs-lookup"><span data-stu-id="1bedd-211">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by simply assuming some level of intent.</span></span>

### <a name="backdatingpostdating-actions"></a><span data-ttu-id="1bedd-212">Датирование действий прошлым/будущим числом</span><span class="sxs-lookup"><span data-stu-id="1bedd-212">Backdating/postdating actions</span></span>
<span data-ttu-id="1bedd-213">Этот механизм полезен для задач, требующих скорости.</span><span class="sxs-lookup"><span data-stu-id="1bedd-213">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="1bedd-214">Когда пользователь осуществляет ряд маневров по нацеливанию/активации на высокой скорости, может быть полезно взять на себя часть намерения и позволить пропущенным шагам быть примененными к целям, которые были в фокусе пользователя немного раньше или немного позже нажатия (при раннем тестировании эффективным показателем было 50 мс).</span><span class="sxs-lookup"><span data-stu-id="1bedd-214">When a user is moving through a series of targeting/activation maneuvers at speed, it can be useful to assume some intent and allow missed steps to act upon targets which the user had in focus slightly before or slightly after the tap (50ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="1bedd-215">Сглаживание</span><span class="sxs-lookup"><span data-stu-id="1bedd-215">Smoothing</span></span>
<span data-ttu-id="1bedd-216">Этот механизм полезен для создания пути движений с уменьшением незначительных подергиваний/качаний, вызванных естественными характеристиками движений головы.</span><span class="sxs-lookup"><span data-stu-id="1bedd-216">This mechanism is useful for pathing movements, reducing the slight jitter/wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="1bedd-217">При сглаживании движений создания пути сглаживайте по размеру/расстоянию движения, а не по времени.</span><span class="sxs-lookup"><span data-stu-id="1bedd-217">When smoothing over pathing motions, smooth by size/distance of movements rather than over time</span></span>

### <a name="magnetism"></a><span data-ttu-id="1bedd-218">Магнитность</span><span class="sxs-lookup"><span data-stu-id="1bedd-218">Magnetism</span></span>
<span data-ttu-id="1bedd-219">Этот механизм можно рассматривать как более общую версию алгоритмов ближайшего звена: подведение курсора к цели и простое увеличение области задействования (как видимой, так и невидимой) при приближении пользователя к вероятной цели, использование определенных знаний о структуре для улучшения определения намерения пользователя.</span><span class="sxs-lookup"><span data-stu-id="1bedd-219">This mechanism can be thought of as a more general version of "Closest link" algorithms - drawing a cursor toward a target, or simply increasing hitboxes (whether visibly or not) as users approach likely targets, using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="1bedd-220">Это может быть особенно эффективно для небольших целей.</span><span class="sxs-lookup"><span data-stu-id="1bedd-220">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="1bedd-221">Закрепление фокуса</span><span class="sxs-lookup"><span data-stu-id="1bedd-221">Focus stickiness</span></span>
<span data-ttu-id="1bedd-222">Предоставьте текущему элементу в фокусе преимущество при определении, на какой ближайший интерактивный элемент перевести фокус.</span><span class="sxs-lookup"><span data-stu-id="1bedd-222">When determining which nearby interactive elements to give focus to, provide a bias to the element that is currently focused.</span></span> <span data-ttu-id="1bedd-223">Это поможет снизить уровень хаотичной смены фокуса при остановке посередине между двумя элементами с естественным шумом.</span><span class="sxs-lookup"><span data-stu-id="1bedd-223">This will help reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="1bedd-224">Составные жесты</span><span class="sxs-lookup"><span data-stu-id="1bedd-224">Composite gestures</span></span>
<span data-ttu-id="1bedd-225">Приложения могут распознавать не только отдельные касания.</span><span class="sxs-lookup"><span data-stu-id="1bedd-225">Apps can recognize more than just individual taps.</span></span> <span data-ttu-id="1bedd-226">Более сложные составные жесты можно выполнять, комбинируя нажатие, удерживание и высвобождение с движением руки.</span><span class="sxs-lookup"><span data-stu-id="1bedd-226">By combining tap, hold and release with the movement of the hand, more complex composite gestures can be performed.</span></span> <span data-ttu-id="1bedd-227">Эти составные или высокоуровневые жесты основываются на низкоуровневых данных пространственного ввода (например, касание и раскрытие ладони), к которым у разработчиков есть доступ.</span><span class="sxs-lookup"><span data-stu-id="1bedd-227">These composite or high-level gestures build on the low-level spatial input data (from Air tap and Bloom) that developers have access to.</span></span>

### <a name="air-tap"></a><span data-ttu-id="1bedd-228">Жест касания</span><span class="sxs-lookup"><span data-stu-id="1bedd-228">Air tap</span></span>
<span data-ttu-id="1bedd-229">Жест касания (а также другие жесты, приведенные ниже) реагирует только на определенное касание.</span><span class="sxs-lookup"><span data-stu-id="1bedd-229">The Air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="1bedd-230">Для определения других касаний, таких как "Меню" или "Захват", приложение должно непосредственно использовать взаимодействия более низкого уровня, описанные в разделе о двух ключевых жестах компонентов выше.</span><span class="sxs-lookup"><span data-stu-id="1bedd-230">To detect other taps, such as Menu or Grasp, your app must directly use the lower-level interactions described in two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="1bedd-231">Tap and hold</span><span class="sxs-lookup"><span data-stu-id="1bedd-231">Tap and hold</span></span>
<span data-ttu-id="1bedd-232">Удерживание — это просто удержание пальца в опущенном положении после касания.</span><span class="sxs-lookup"><span data-stu-id="1bedd-232">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="1bedd-233">Различные более сложные взаимодействия "щелкнуть и перетянуть" можно выполнять благодаря комбинации жеста касания и удерживания в сочетании с движением руки, таким как поднятие объекта вместо активации или вторичные взаимодействия "клацанье мышью", например открытие контекстного меню.</span><span class="sxs-lookup"><span data-stu-id="1bedd-233">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or "mousedown" secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="1bedd-234">Однако при разработке этого жеста следует соблюдать осторожность, поскольку пользователи могут быть склонны к расслаблению позы рук во время любого расширенного жеста.</span><span class="sxs-lookup"><span data-stu-id="1bedd-234">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="1bedd-235">Управление</span><span class="sxs-lookup"><span data-stu-id="1bedd-235">Manipulation</span></span>
<span data-ttu-id="1bedd-236">Управление жестами можно использовать для перемещения, изменения размера или поворота голограммы, когда вы хотите, чтобы голограмма реагировала 1:1 на движения руки пользователя.</span><span class="sxs-lookup"><span data-stu-id="1bedd-236">Manipulation gestures can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="1bedd-237">Одно из применений таких движений 1:1 позволяет пользователю только рисовать или вписывать красками.</span><span class="sxs-lookup"><span data-stu-id="1bedd-237">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="1bedd-238">Первоначальное нацеливание для жеста управления должно быть исполнено взглядом или указанием.</span><span class="sxs-lookup"><span data-stu-id="1bedd-238">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="1bedd-239">Как только начинается касание и удерживание, любые операции с объектом обрабатываются движениями руки, позволяя пользователю в это время осмотреться.</span><span class="sxs-lookup"><span data-stu-id="1bedd-239">Once the tap and hold starts, any manipulation of the object is then handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="1bedd-240">Навигация</span><span class="sxs-lookup"><span data-stu-id="1bedd-240">Navigation</span></span>
<span data-ttu-id="1bedd-241">Жесты навигации работают как виртуальный джойстик и могут использоваться для навигации по мини-приложениям пользовательского интерфейса, таким как радиальные меню.</span><span class="sxs-lookup"><span data-stu-id="1bedd-241">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="1bedd-242">Вы касаетесь и удерживаете, чтобы начать жест, а затем двигаете рукой в нормализованном трехмерном кубе, центрированном вокруг начального нажатия.</span><span class="sxs-lookup"><span data-stu-id="1bedd-242">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="1bedd-243">Вы можете перемещать руку вдоль оси X, Y или Z от значения –1 до 1, где 0 является начальной точкой.</span><span class="sxs-lookup"><span data-stu-id="1bedd-243">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="1bedd-244">Навигация может использоваться для создания жестов непрерывной прокрутки или масштабирования на основе скорости, аналогично прокрутке 2D-интерфейса путем нажатия средней кнопки мыши и последующего перемещения мыши вверх и вниз.</span><span class="sxs-lookup"><span data-stu-id="1bedd-244">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="1bedd-245">Навигация с направляющими относится к способности распознавать движения по определенной оси, пока на этой оси не будет достигнут определенный порог.</span><span class="sxs-lookup"><span data-stu-id="1bedd-245">Navigation with rails refers to the ability of recognizing movements in certain axis until certain threshold is reached on that axis.</span></span> <span data-ttu-id="1bedd-246">Это полезно только тогда, когда разработчиком разрешено перемещение по нескольким осям в приложении, например если приложение настроено на распознавание жестов навигации по оси X, Y, а также по оси X с направляющими.</span><span class="sxs-lookup"><span data-stu-id="1bedd-246">This is only useful, when movement in more than one axis is enabled in an application by the developer, e.g. if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="1bedd-247">В этом случае система будет распознавать движения рук по оси X, пока они находятся на воображаемых направляющих по оси X, если руки также двигаются по оси Y.</span><span class="sxs-lookup"><span data-stu-id="1bedd-247">In this case system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on X axis, if hand movement also occurs Y axis.</span></span>

<span data-ttu-id="1bedd-248">В 2D-приложениях пользователи могут использовать жесты вертикальной навигации для прокрутки, масштабирования или перетаскивания внутри приложения.</span><span class="sxs-lookup"><span data-stu-id="1bedd-248">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="1bedd-249">Это вводит в приложение виртуальные касания пальцем, чтобы имитировать сенсорные жесты того же типа.</span><span class="sxs-lookup"><span data-stu-id="1bedd-249">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="1bedd-250">Пользователи могут выбрать любое из этих действий, переключаясь между инструментами на панели над приложением, либо нажимая кнопку, либо говоря "<Прокрутить/Перетащить/Увеличить> инструмент".</span><span class="sxs-lookup"><span data-stu-id="1bedd-250">Users can select which of these actions take place by toggling between the tools on the bar above the app, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="1bedd-251">Дополнительные сведения о составных жестах</span><span class="sxs-lookup"><span data-stu-id="1bedd-251">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="1bedd-252">Распознаватели жестов</span><span class="sxs-lookup"><span data-stu-id="1bedd-252">Gesture recognizers</span></span>

<span data-ttu-id="1bedd-253">Одно из преимуществ использования распознавания жестов состоит в том, что вы можете настроить распознаватель жестов только для тех жестов, которые может принять намеченная голограмма.</span><span class="sxs-lookup"><span data-stu-id="1bedd-253">One benefit of using gesture recognition is that you can configure a gesture recognizer just for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="1bedd-254">Платформа будет выполнять только устранение неоднозначности, необходимое для различения этих конкретных поддерживаемых жестов.</span><span class="sxs-lookup"><span data-stu-id="1bedd-254">The platform will do only the disambiguation necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="1bedd-255">Таким образом, голограмма, которая просто поддерживает касание, может допускать любой промежуток времени между нажатием и высвобождением. В то же время голограмма, которая поддерживает как нажатие, так и высвобождение, может переводить нажатие на удерживание после порога времени удержания.</span><span class="sxs-lookup"><span data-stu-id="1bedd-255">That way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="1bedd-256">Распознавание рук</span><span class="sxs-lookup"><span data-stu-id="1bedd-256">Hand recognition</span></span>
<span data-ttu-id="1bedd-257">HoloLens распознает жесты рук, отслеживая положение одной или обеих рук, которые видимые устройству.</span><span class="sxs-lookup"><span data-stu-id="1bedd-257">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="1bedd-258">Руки видны для HoloLens, когда они находятся в состоянии готовности (задняя часть руки обращена к вам указательным пальцем вверх) или в нажатом состоянии (задняя часть руки обращена к вам указательным пальцем вниз).</span><span class="sxs-lookup"><span data-stu-id="1bedd-258">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="1bedd-259">Когда руки находятся в других позах, они будут проигнорированные HoloLens.</span><span class="sxs-lookup"><span data-stu-id="1bedd-259">When hands are in other poses, the HoloLens will ignore them.</span></span>
<span data-ttu-id="1bedd-260">Вы можете получить доступ к положению (без ориентации) и нажатому состоянию каждой руки, обнаруженной HoloLens.</span><span class="sxs-lookup"><span data-stu-id="1bedd-260">For each hand that HoloLens detects, you can access its position (without orientation) and its pressed state.</span></span> <span data-ttu-id="1bedd-261">Когда рука приближается к краю рамки жеста, вам также предоставляется вектор направления, который вы можете показать пользователю. Так он узнает, как переместить руку, чтобы вернуть ее туда, где она будет видна для HoloLens.</span><span class="sxs-lookup"><span data-stu-id="1bedd-261">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="1bedd-262">Рамка жестов</span><span class="sxs-lookup"><span data-stu-id="1bedd-262">Gesture frame</span></span>
<span data-ttu-id="1bedd-263">Чтобы сделать жест на HoloLens, рука должна находиться в "рамке жестов", в диапазоне, который могут воспринимать чувствительные к жестам камеры (очень приблизительно от носа до талии и между плечами).</span><span class="sxs-lookup"><span data-stu-id="1bedd-263">For gestures on HoloLens, the hand must be within a “gesture frame”, in a range that the gesture-sensing cameras can see appropriately (very roughly from nose to waist, and between the shoulders).</span></span> <span data-ttu-id="1bedd-264">Пользователи должны быть обучены в этой области распознавания как для успешных действий, так и для их собственного комфорта (многие пользователи изначально предполагают, что рамка жестов должна быть в пределах их видения в HoloLens, и неудобно держат руки при взаимодействиях).</span><span class="sxs-lookup"><span data-stu-id="1bedd-264">Users need to be trained on this area of recognition both for success of action and for their own comfort (many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact).</span></span> <span data-ttu-id="1bedd-265">При использовании HoloLens Clicker ваши руки не должны находиться в рамке жеста.</span><span class="sxs-lookup"><span data-stu-id="1bedd-265">When using the HoloLens Clicker, your hands do not need to be within the gesture frame.</span></span>

<span data-ttu-id="1bedd-266">В частности, в случае непрерывных жестов существует некоторый риск того, что пользователи переместят свои руки за пределы рамки жеста, находясь в середине жеста (например, при перемещении какого-либо голографического объекта), и потеряют ожидаемый результат.</span><span class="sxs-lookup"><span data-stu-id="1bedd-266">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture (while moving some holographic object, for example), and losing their intended outcome.</span></span>

<span data-ttu-id="1bedd-267">Есть три вещи, которые необходимо рассмотреть:</span><span class="sxs-lookup"><span data-stu-id="1bedd-267">There are three things that you should consider:</span></span>

- <span data-ttu-id="1bedd-268">Обучение пользователей существованию рамки жестов и приблизительным границам (этому учат во время установки HoloLens).</span><span class="sxs-lookup"><span data-stu-id="1bedd-268">User education on the gesture frame's existence and approximate boundaries (this is taught during HoloLens setup).</span></span>

- <span data-ttu-id="1bedd-269">Уведомление пользователям, когда их жесты приближаются/нарушают границы рамки жестов в приложении в той степени, в которой неправильный жест приведет к нежелательным результатам.</span><span class="sxs-lookup"><span data-stu-id="1bedd-269">Notifying users when their gestures are nearing/breaking the gesture frame boundaries within an application, to the degree that a lost gesture will lead to undesired outcomes.</span></span> <span data-ttu-id="1bedd-270">Исследования показали ключевые качества такой системы уведомлений. Оболочка HoloLens представляет собой наглядный пример такого типа уведомлений (визуального, на центральном курсоре, указывающем направление, в котором происходит пересечение границы).</span><span class="sxs-lookup"><span data-stu-id="1bedd-270">Research has shown the key qualities of such a notification system, and the HoloLens shell provides a good example of this type of notification (visual, on the central cursor, indicating the direction in which boundary crossing is taking place).</span></span>

- <span data-ttu-id="1bedd-271">Последствия нарушения границ рамки жеста должны быть сведены к минимуму.</span><span class="sxs-lookup"><span data-stu-id="1bedd-271">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="1bedd-272">В общем, это означает, что результат жеста должен быть остановлен на границе, а не возвращен в начальную точку.</span><span class="sxs-lookup"><span data-stu-id="1bedd-272">In general, this means that the outcome of a gesture should be stopped at the boundary, but not reversed.</span></span> <span data-ttu-id="1bedd-273">Например, если пользователь перемещает некий голографический объект по комнате, движение должно прекратиться, когда будет пересечена рамка жеста, а не возвращено в начальную точку.</span><span class="sxs-lookup"><span data-stu-id="1bedd-273">For example, if a user is moving some holographic object across a room, movement should stop when the gesture frame is breached, but not be returned to the starting point.</span></span> <span data-ttu-id="1bedd-274">В этом случае пользователь может испытывать некоторое разочарование, но может быстрее усвоить границы, и ему не придется каждый раз начинать сначала все свои предполагаемые действия.</span><span class="sxs-lookup"><span data-stu-id="1bedd-274">The user may experience some frustration then, but may more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="1bedd-275">См. также статью</span><span class="sxs-lookup"><span data-stu-id="1bedd-275">See also</span></span>
* [<span data-ttu-id="1bedd-276">Непосредственное манипулирование с использованием рук</span><span class="sxs-lookup"><span data-stu-id="1bedd-276">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="1bedd-277">Наведение и фиксация с использованием рук</span><span class="sxs-lookup"><span data-stu-id="1bedd-277">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="1bedd-278">Инстинктивное взаимодействие</span><span class="sxs-lookup"><span data-stu-id="1bedd-278">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="1bedd-279">Направление головы и остановка</span><span class="sxs-lookup"><span data-stu-id="1bedd-279">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="1bedd-280">Голосовые команды</span><span class="sxs-lookup"><span data-stu-id="1bedd-280">Voice commanding</span></span>](voice-design.md)





