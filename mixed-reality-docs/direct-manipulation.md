---
title: Прямые манипуляции
description: Общие сведения о модели ввода непосредственной работы со
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/02/2019
ms.topic: article
keywords: Смешанный реальность, взглядом, взглядом, предназначенные для взаимодействия, проектирование
ms.openlocfilehash: d855955d44c1cf074849992e5dd7b36b54675fdd
ms.sourcegitcommit: f5c1dedb3b9e29f27f627025b9e7613931a7ce18
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/27/2019
ms.locfileid: "64581334"
---
# <a name="direct-manipulation"></a><span data-ttu-id="bff2f-104">Прямые манипуляции</span><span class="sxs-lookup"><span data-stu-id="bff2f-104">Direct manipulation</span></span>
<span data-ttu-id="bff2f-105">Прямого управления представляют собой входные модель, которая включает в себя касаясь голограммы прямо с рук.</span><span class="sxs-lookup"><span data-stu-id="bff2f-105">Direct manipulation is an input model that involves touching holograms directly with your hands.</span></span> <span data-ttu-id="bff2f-106">Цель с помощью прямого управления — объекты ведут себя так же, как и в реальном мире.</span><span class="sxs-lookup"><span data-stu-id="bff2f-106">The goal with direct manipulation is that objects behave just as they do in the real world.</span></span> <span data-ttu-id="bff2f-107">Кнопки можно активировать, просто нажав их и объектов, могут быть получены, взяв их двухмерное содержимое ведет себя как виртуальный сенсорного экрана.</span><span class="sxs-lookup"><span data-stu-id="bff2f-107">Buttons can be activated simply by pressing them, objects can be picked up by grabbing them, and 2D content behaves like a virtual touchscreen.</span></span>  <span data-ttu-id="bff2f-108">По этой причине прямые манипуляции прост для пользователей узнать, оно также прошло fun слишком.</span><span class="sxs-lookup"><span data-stu-id="bff2f-108">Because of this, direct manipulation is easy for users to learn, and it's fun too.</span></span>  <span data-ttu-id="bff2f-109">Он считается «рядом с» модель ввода, это означает, что лучше всего подходит для взаимодействия с содержимым, которое находится в руки достичь.</span><span class="sxs-lookup"><span data-stu-id="bff2f-109">It is considered a "near" input model, meaning it is best used for interacting with content that is within arms reach.</span></span>

<span data-ttu-id="bff2f-110">Это ключевой, позволяет легко узнать прямого управления — это основе affordance.</span><span class="sxs-lookup"><span data-stu-id="bff2f-110">A key ingredient that makes direct manipulation easy to learn is that it is affordance-based.</span></span> <span data-ttu-id="bff2f-111">Существуют не символические жесты, чтобы обучить пользователей.</span><span class="sxs-lookup"><span data-stu-id="bff2f-111">There are no symbolic gestures to teach users.</span></span> <span data-ttu-id="bff2f-112">Все взаимодействия должен быть построен вокруг визуальный элемент, который может быть затронутых или взял.</span><span class="sxs-lookup"><span data-stu-id="bff2f-112">All interactions should be built around a visual element that can be touched or grabbed.</span></span>

## <a name="device-support"></a><span data-ttu-id="bff2f-113">Поддержка устройств</span><span class="sxs-lookup"><span data-stu-id="bff2f-113">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="bff2f-114"><strong>Модель ввода</strong></span><span class="sxs-lookup"><span data-stu-id="bff2f-114"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="bff2f-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1-го поколения)</strong></a></span><span class="sxs-lookup"><span data-stu-id="bff2f-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="bff2f-116"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="bff2f-116"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="bff2f-117"><a href="immersive-headset-hardware-details.md"><strong>Иммерсивную</strong></a></span><span class="sxs-lookup"><span data-stu-id="bff2f-117"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="bff2f-118">Прямые манипуляции (рядом с правым взаимодействия вручную)</span><span class="sxs-lookup"><span data-stu-id="bff2f-118">Direct manipulation (Near hand interaction)</span></span></td>
        <td><span data-ttu-id="bff2f-119">❌ Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="bff2f-119">❌ Not supported</span></span></td>
        <td><span data-ttu-id="bff2f-120">Рекомендуется ✔️</span><span class="sxs-lookup"><span data-stu-id="bff2f-120">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="bff2f-121">➕ Альтернативным вариантом, но <a href="point-and-commit.md">точки и фиксации (дальней взаимодействия)</a> рекомендуется</span><span class="sxs-lookup"><span data-stu-id="bff2f-121">➕ An alternate option but <a href="point-and-commit.md">Point and commit (far interaction)</a> is recommended</span></span></td>
    </tr>
</table>

<span data-ttu-id="bff2f-122">Непосредственной работы со является основной модели ввода на 2 HoloLens, использование нового ясно сформулированные Рука системы отслеживания.</span><span class="sxs-lookup"><span data-stu-id="bff2f-122">Direct manipulation is a primary input model on HoloLens 2, utilizing the new articulated hand tracking system.</span></span> <span data-ttu-id="bff2f-123">Модель ввода также можно найти в иммерсивную при помощи движения контроллеров, но не рекомендуется основного средства взаимодействия за пределами объектами.</span><span class="sxs-lookup"><span data-stu-id="bff2f-123">The input model is also available on immersive headsets through the use of motion controllers, but is not recommended a primary means of interaction outside of object manipulation.</span></span>  <span data-ttu-id="bff2f-124">Прямой manipluation недоступна на HoloLens v1.</span><span class="sxs-lookup"><span data-stu-id="bff2f-124">Direct manipluation is not available on HoloLens v1.</span></span>

## <a name="collidable-fingertip"></a><span data-ttu-id="bff2f-125">Collidable срезах</span><span class="sxs-lookup"><span data-stu-id="bff2f-125">Collidable fingertip</span></span>
<span data-ttu-id="bff2f-126">На 2 HoloLens реальные руки пользователя распознаются и интерпретируются как левой и правой руки базовой модели.</span><span class="sxs-lookup"><span data-stu-id="bff2f-126">On HoloLens 2, user's real hands are recognized and interpreted as left and right hand skeletal models.</span></span> <span data-ttu-id="bff2f-127">В идеале, чтобы реализовать идея касаясь голограммы прямо в руки, 5 colliders можно подключить к 5 распоряжение каждой стороны базовой модели.</span><span class="sxs-lookup"><span data-stu-id="bff2f-127">To implement the idea of touching holograms directly with hands, ideally, 5 colliders could be attached to 5 fingertips of each hand skeletal model.</span></span> <span data-ttu-id="bff2f-128">Однако на практике, из-за отсутствия tactile обратной связи, 10 collidable руках вызвать массу Непредвиденная и непредсказуемые конфликтов с голограммы.</span><span class="sxs-lookup"><span data-stu-id="bff2f-128">However, practically, due to the lack of tactile feedback, 10 collidable fingertips cause lots of unexpected and unpredictable collisions with holograms.</span></span> <span data-ttu-id="bff2f-129">Таким образом мы советуем использовать только разместить collider на каждый вытянутым указательным пальцем.</span><span class="sxs-lookup"><span data-stu-id="bff2f-129">Hence, we suggest to only put a collider on each index finger.</span></span> <span data-ttu-id="bff2f-130">Коснитесь collidable индекс, который уже сейчас по-прежнему можно использовать в качестве активного сенсорного точки для различных сенсорные жесты, включающие другие соединители, такие как press палец 1, 1 палец, 2 нажмите пальца и нажмите клавишу 5 палец.</span><span class="sxs-lookup"><span data-stu-id="bff2f-130">The collidable index fingertips can still serve as active touch points for diverse touch gestures involving other fingers, such as 1 finger press, 1 finger tap, 2 finger press and 5 finger press.</span></span>

![Изображение collidable срезах](images/Collidable-Fingertip-720px.jpg)<br>

### <a name="sphere-collider"></a><span data-ttu-id="bff2f-132">Сфера collider</span><span class="sxs-lookup"><span data-stu-id="bff2f-132">Sphere collider</span></span>
<span data-ttu-id="bff2f-133">Вместо случайных обычную форму, мы рекомендуем использовать sphere collider и визуально их для предоставления подсказок лучше практически разрабатывать приложения для вывода.</span><span class="sxs-lookup"><span data-stu-id="bff2f-133">Instead of using random generic shape, we suggest to use a sphere collider and to visually render it to provide better cues for near targeting.</span></span> <span data-ttu-id="bff2f-134">Диаметр сферы должен соответствовать толщина указательный палец для повышения точности распознавания сенсорного ввода.</span><span class="sxs-lookup"><span data-stu-id="bff2f-134">The sphere's diameter should match the thickness of the index finger to increase touch accuracy.</span></span> <span data-ttu-id="bff2f-135">Его будет легко получить, вызвав API Рука переменной толщины палец.</span><span class="sxs-lookup"><span data-stu-id="bff2f-135">It will be easy to retrieve the variable of finger thickness by calling the hand API.</span></span>

<br>

### <a name="fingertip-cursor"></a><span data-ttu-id="bff2f-136">Срезах курсора</span><span class="sxs-lookup"><span data-stu-id="bff2f-136">Fingertip cursor</span></span>
<span data-ttu-id="bff2f-137">Дополнение к отображению collidable шар на срезах индекса, мы создадим решение advance, срезах курсор, чтобы добиться повышения рядом с выбора цели в интерактивном режиме.</span><span class="sxs-lookup"><span data-stu-id="bff2f-137">In addition to rendering a collidable sphere on the index fingertip, we create an advance solution, fingertip cursor, to achieve better near targeting experience interactively.</span></span> <span data-ttu-id="bff2f-138">Это кольцевой курсора фигуры, прикрепить к срезах индекса.</span><span class="sxs-lookup"><span data-stu-id="bff2f-138">It is a donut shape cursor attached on the index fingertip.</span></span> <span data-ttu-id="bff2f-139">В соответствии с с учетом расположения он динамически реагирует на целевой объект в перспективе, ориентация и размер, как показано ниже:</span><span class="sxs-lookup"><span data-stu-id="bff2f-139">According to proximity, it dynamically reacts to a target in term of orientation and size as below:</span></span>
* <span data-ttu-id="bff2f-140">Если указательный палец перемещается к голограмма, курсор всегда параллельных на поверхность голограмма и постепенно уменьшается размер соответствующим образом.</span><span class="sxs-lookup"><span data-stu-id="bff2f-140">When an index finger moves toward a hologram, the cursor is always parallel to the surface of the hologram and gradually shrinks its size accordingly.</span></span> 
* <span data-ttu-id="bff2f-141">Как только прикоснитесь палец, курсор сжимается в точку и генерирует событие сенсорного ввода.</span><span class="sxs-lookup"><span data-stu-id="bff2f-141">As soon as the finger touch the surface, the cursor shrinks into a dot and emits a touch event.</span></span>

<br> <span data-ttu-id="bff2f-142">С помощью интерактивных обратной связи пользователей можно добиться высокой точности практически предназначенные для задач, таких как запуск гиперссылку на веб-содержимого или нажатии кнопки.</span><span class="sxs-lookup"><span data-stu-id="bff2f-142">With the interactive feedback, users can achieve high precision near targeting tasks, such as triggering a hyperlink on a web content or pressing a button.</span></span> <br>

![Изображение курсора срезах](images/Fingertip-Cursor-720px.jpg)<br>

## <a name="bounding-box-with-proximity-shader"></a><span data-ttu-id="bff2f-144">Ограничивающий прямоугольник с шейдера с учетом расположения</span><span class="sxs-lookup"><span data-stu-id="bff2f-144">Bounding box with proximity shader</span></span>
<span data-ttu-id="bff2f-145">Голограмма, сам также требуется для предоставления отзывов visual и аудио компенсировать отсутствие tactile обратной связи.</span><span class="sxs-lookup"><span data-stu-id="bff2f-145">The hologram itself also requires to provide both visual and audio feedbacks to compensate the lack of tactile feedback.</span></span> <span data-ttu-id="bff2f-146">Для этого мы создаем концепцию ограничивающий прямоугольник с шейдера с учетом расположения.</span><span class="sxs-lookup"><span data-stu-id="bff2f-146">For that, we generate the concept of bounding box with proximity shader.</span></span> <span data-ttu-id="bff2f-147">Ограничивающий прямоугольник имеет минимальный объемные область, включающую трехмерного объекта.</span><span class="sxs-lookup"><span data-stu-id="bff2f-147">A bounding box is a minimun volumetric area that encloses a 3D object.</span></span> <span data-ttu-id="bff2f-148">Ограничивающий прямоугольник имеет механизм интерактивной подготовки к просмотру вызывается шейдера с учетом расположения.</span><span class="sxs-lookup"><span data-stu-id="bff2f-148">The bounding box has an interactive rendering mechanism called proximity shader.</span></span> <span data-ttu-id="bff2f-149">Выражение с учетом шейдера ведет себя следующим образом:</span><span class="sxs-lookup"><span data-stu-id="bff2f-149">The proximity shader behaves as below:</span></span>

* <span data-ttu-id="bff2f-150">Если указательный палец в пределах диапазона, spotlight срезах приводится на поверхности ограничивающий прямоугольник.</span><span class="sxs-lookup"><span data-stu-id="bff2f-150">When the index finger is within a range, a fingertip spotlight is cast on the surface of bounding box.</span></span> 
* <span data-ttu-id="bff2f-151">При получении срезах ближе к рабочей области, полезные сведения, объединяя соответствующим образом.</span><span class="sxs-lookup"><span data-stu-id="bff2f-151">When the fingertip gets closer to the surface, the spotlight condenses accordingly.</span></span> 
* <span data-ttu-id="bff2f-152">Как только прикоснитесь срезах, весь ограничивающий прямоугольник изменяет цвет или создать визуальный эффект для отражения состояния сенсорного ввода.</span><span class="sxs-lookup"><span data-stu-id="bff2f-152">As soon as the fingertip touch the surface, the whole bounding box changes the color or generate visual effect to reflect the touch state.</span></span> 
* <span data-ttu-id="bff2f-153">В то же время звуковой эффект может быть активирован для улучшения visual сенсорного.</span><span class="sxs-lookup"><span data-stu-id="bff2f-153">Meanwhile, a sound effect can be activated to enhance the visual touch feedback.</span></span>

![Ограничивающий прямоугольник с изображением шейдера с учетом расположения](images/Bounding-Box-With-Proximity-Shader-720px.jpg)<br>

## <a name="pressable-button"></a><span data-ttu-id="bff2f-155">Pressable кнопки</span><span class="sxs-lookup"><span data-stu-id="bff2f-155">Pressable button</span></span>
<span data-ttu-id="bff2f-156">С помощью collidable срезах пользователи теперь готовы для взаимодействия с фундаментальнейшего holographic компонента пользовательского интерфейса, pressable кнопку.</span><span class="sxs-lookup"><span data-stu-id="bff2f-156">With a collidable fingertip, users are now ready to interact with the very fundamental holographic UI component, pressable button.</span></span> <span data-ttu-id="bff2f-157">Pressable кнопки — это holographic кнопка, специально предназначенные для прямого палец press.</span><span class="sxs-lookup"><span data-stu-id="bff2f-157">A pressable button is a holographic button tailored for direct finger press.</span></span> <span data-ttu-id="bff2f-158">Опять же, из-за отсутствия tactile обратной связи, pressable кнопки обеспечивает несколько механизмов для решения tactile отзывы проблемы, связанные с.</span><span class="sxs-lookup"><span data-stu-id="bff2f-158">Again, due to the lack of tactile feedback, a pressable button equips a couple mechanisms to tackle tactile feedback related issues.</span></span> 
* <span data-ttu-id="bff2f-159">Первый механизм ограничивающий прямоугольник с шейдера с учетом расположения, который уже была устранена в вышеупомянутый абзац.</span><span class="sxs-lookup"><span data-stu-id="bff2f-159">The first mechanism is bounding box with proximity shader, which has already been addressed in the foregoing paragraph.</span></span> <span data-ttu-id="bff2f-160">Он служит для предоставления понятно, с учетом расположения для пользователей подходов и сделать контакта с кнопкой.</span><span class="sxs-lookup"><span data-stu-id="bff2f-160">It serves to provide better sense of proximity for users to approach and make contact with a button.</span></span> 
* <span data-ttu-id="bff2f-161">Второй — depression.</span><span class="sxs-lookup"><span data-stu-id="bff2f-161">The second one is depression.</span></span> <span data-ttu-id="bff2f-162">Он создает смысле нажать после срезах обращается кнопки.</span><span class="sxs-lookup"><span data-stu-id="bff2f-162">It creates sense of press, after a fingertip contacts the button.</span></span> <span data-ttu-id="bff2f-163">Представляет собой механизм, что кнопка перемещается тесно с срезах вдоль оси глубины.</span><span class="sxs-lookup"><span data-stu-id="bff2f-163">The mechanism is that the button tightly moves with the fingertip along the depth axis.</span></span> <span data-ttu-id="bff2f-164">Кнопки можно активировать как можно скорее достижения заданного глубины (на материалах издательства press) или оставить глубина (на выпуск) после передачи через него.</span><span class="sxs-lookup"><span data-stu-id="bff2f-164">The button can be triggered as soon as reaching a designated depth (on press) or leaving the depth (on release) after passing through it.</span></span> 
* <span data-ttu-id="bff2f-165">Звуковой должны быть добавлены для повышения обратной связи, в том случае, когда активирована кнопка.</span><span class="sxs-lookup"><span data-stu-id="bff2f-165">The sound effect should be added to enhance feedback, when the button is triggered.</span></span> 

![Изображение кнопки pressable](images/Pressable-Button-720px.jpg)<br>

## <a name="2d-slate-interaction"></a><span data-ttu-id="bff2f-167">2D баннера взаимодействия</span><span class="sxs-lookup"><span data-stu-id="bff2f-167">2D slate interaction</span></span>
<span data-ttu-id="bff2f-168">2D Сланец является holographic содержимого 2D приложения, такие как веб-браузер для размещения контейнеров.</span><span class="sxs-lookup"><span data-stu-id="bff2f-168">A 2D slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="bff2f-169">Концепции проектирования для взаимодействия с 2D листа с помощью непосредственной работы со является использовать ментальной модели взаимодействия с физической сенсорным экраном.</span><span class="sxs-lookup"><span data-stu-id="bff2f-169">The design concept for interacting with a 2D slate via direct manipulation is to leverage the mental model of interacting with a physical touch screen.</span></span><br> <br>
<span data-ttu-id="bff2f-170">Для взаимодействия с планшета контакта:</span><span class="sxs-lookup"><span data-stu-id="bff2f-170">For interacting with the slate contact:</span></span><br> 
* <span data-ttu-id="bff2f-171">Пользователи использовать вытянутым указательным пальцем на нажатие гиперссылки или кнопки.</span><span class="sxs-lookup"><span data-stu-id="bff2f-171">Users use an index finger to press a hyperlink or a button.</span></span> 
* <span data-ttu-id="bff2f-172">Пользователи использовать указательный палец для прокрутки баннера содержимого вверх и вниз.</span><span class="sxs-lookup"><span data-stu-id="bff2f-172">Users use an index finger to scroll a slate content up and down.</span></span> 
* <span data-ttu-id="bff2f-173">Для увеличения in и out баннера содержимое в соответствии с относительный движения пальцев, пользователям использовать двумя пальцами.</span><span class="sxs-lookup"><span data-stu-id="bff2f-173">Users use two index fingers to zoom in and out the slate content according to relative motion of fingers.</span></span> 
<span data-ttu-id="bff2f-174">![Двухмерное изображение баннера](images/2D-Slate-Interaction-720px.jpg)</span><span class="sxs-lookup"><span data-stu-id="bff2f-174">![2D slate image](images/2D-Slate-Interaction-720px.jpg)</span></span><br>

<br><span data-ttu-id="bff2f-175">Для управления 2D синевато самой:</span><span class="sxs-lookup"><span data-stu-id="bff2f-175">For manipulating the 2D slate itself:</span></span><br>
* <span data-ttu-id="bff2f-176">Пользователей можно будет перейти опускают руки к углы и ребра, чтобы отобразить ближайший читаемости манипуляции.</span><span class="sxs-lookup"><span data-stu-id="bff2f-176">Users can approach their hands toward corners and edges to reveal the closest manipulation affordances.</span></span> 
* <span data-ttu-id="bff2f-177">Получим читаемости манипуляции, пользователи могут выполнения универсальный код масштабирования через affordnaces угла и обратное течение через читаемости edge.</span><span class="sxs-lookup"><span data-stu-id="bff2f-177">By grabbing the manipulation affordances, users can perform uniform scaling through the corner affordnaces and reflow via the edge affordances.</span></span> 
* <span data-ttu-id="bff2f-178">Получения holobar в верхней части 2D Сланец пользователи перемещают весь лист.</span><span class="sxs-lookup"><span data-stu-id="bff2f-178">Grabbing the holobar at the top of the 2D slate can users move the whole slate.</span></span><br><br>

![Изображение баннера манипуляции](images/Manipulate-2d-slate-720px.jpg)


## <a name="3d-object-manipulation"></a><span data-ttu-id="bff2f-180">Манипуляции трехмерного объекта</span><span class="sxs-lookup"><span data-stu-id="bff2f-180">3D object manipulation</span></span>
<span data-ttu-id="bff2f-181">В 2 HoloLens пользователи могут использовать опускают руки для прямого управления объектами, 3D hologramphic, применяя к каждому трехмерному объекту ограничивающий прямоугольник.</span><span class="sxs-lookup"><span data-stu-id="bff2f-181">In HoloLens 2, users are enabled to use their hands to direct manipulate 3D hologramphic objects by applying a bounding box to each 3D object.</span></span> <span data-ttu-id="bff2f-182">Ограничивающий прямоугольник предоставляет более глубокой через его шейдера с учетом расположения.</span><span class="sxs-lookup"><span data-stu-id="bff2f-182">The bounding box provides better depth perception through its proximity shader.</span></span> <span data-ttu-id="bff2f-183">С помощью ограничивающего прямоугольника существует два подхода к проектированию для манипуляции трехмерного объекта:</span><span class="sxs-lookup"><span data-stu-id="bff2f-183">With the bounding box, there are two design approaches for 3D object manipulation:</span></span>      
### <a name="affordance-based-manipulation"></a><span data-ttu-id="bff2f-184">Affordance основе обработки:</span><span class="sxs-lookup"><span data-stu-id="bff2f-184">Affordance based manipulation:</span></span>
<span data-ttu-id="bff2f-185">Это позволяет пользователям управлять трехмерный объект через ограничивающий поле и читаемости манипуляции вокруг него.</span><span class="sxs-lookup"><span data-stu-id="bff2f-185">It is a way for users to manipulate the 3D object through bounding box and the manipulation affordances around it.</span></span> <span data-ttu-id="bff2f-186">Как только руку пользователя близок к трехмерного объекта, ограничивающий прямоугольник и ближайшего affordance открываются.</span><span class="sxs-lookup"><span data-stu-id="bff2f-186">As soon as a user's hand is close to a 3D object, the bounding box and the nearest affordance are revealed.</span></span> <span data-ttu-id="bff2f-187">Пользователи могут получить ограничивающий прямоугольник для перемещения всего объекта читаемости edge для поворота и coner читаемости равномерно масштабировать.</span><span class="sxs-lookup"><span data-stu-id="bff2f-187">Users can grab the bounding box to move the whole object, the edge affordances to rotate and the coner affordances to scale uniformly.</span></span><br>

![Трехмерный объект обработки изображений](images/3D-Object-Manipulation-720px.jpg)<br>

### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="bff2f-189">Non-affordance основе обработки:</span><span class="sxs-lookup"><span data-stu-id="bff2f-189">Non-affordance based manipulation:</span></span>
<span data-ttu-id="bff2f-190">В этом mechanisom не affordance присоединяется к ограничивающего прямоугольника.</span><span class="sxs-lookup"><span data-stu-id="bff2f-190">In this mechanisom, no affordance is attached to the bounding box.</span></span> <span data-ttu-id="bff2f-191">Пользователи могут только Показать ограничивающий прямоугольник, а затем напрямую взаимодействовать с ним.</span><span class="sxs-lookup"><span data-stu-id="bff2f-191">Users can only reveal the bounding box, then directly interact with it.</span></span> <span data-ttu-id="bff2f-192">Если ограничивающий прямоугольник извлечен с одной стороны, перенос и поворот объекта связаны с движения и ориентации вручную.</span><span class="sxs-lookup"><span data-stu-id="bff2f-192">If the bounding box is grabbed with one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="bff2f-193">Когда объект извлечен с двумя руки, пользователям можно перевести, масштабировать и повернуть ее в соответствии с относительный движений две руки.</span><span class="sxs-lookup"><span data-stu-id="bff2f-193">When the object is grabbed with two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span><br><br> 

<br><br>
<span data-ttu-id="bff2f-194">Для обработки требуется точность, мы рекомендуем afforance основе манипуляции, обеспечивая высокую степень гранулярности.</span><span class="sxs-lookup"><span data-stu-id="bff2f-194">For manipulation requires precision, we recommend afforance based manipulation, providing high level of granularity.</span></span> <span data-ttu-id="bff2f-195">Гибко управлять манипуляции не affordance будет хорошим выбором, предложить пользователям мгновенного и игровой.</span><span class="sxs-lookup"><span data-stu-id="bff2f-195">For flexible manipulation, non-affordance manipulation will be a good choice, offering users instant and playful experiences.</span></span>


## <a name="instinctual-gestures"></a><span data-ttu-id="bff2f-196">Instinctual жесты</span><span class="sxs-lookup"><span data-stu-id="bff2f-196">Instinctual gestures</span></span>
<span data-ttu-id="bff2f-197">В отличие от HoloLens (1-го поколения), несколько стандартных пользователей саду жесты, например Блума и Air, коснитесь HoloLens 2, мы не просим пользователям запоминать все символьные жест.</span><span class="sxs-lookup"><span data-stu-id="bff2f-197">Unlike HoloLens (1st gen), teaching users a couple predefined gestures, such as Bloom and Air Tap, in HoloLens 2, we don't ask users to memorize any symbolic gesture.</span></span> <span data-ttu-id="bff2f-198">Все жесты, необходимых пользователям для взаимодействия с голограммы и содержимое instinctual.</span><span class="sxs-lookup"><span data-stu-id="bff2f-198">All gestures that users need for interacting with holograms and contents are instinctual.</span></span> <span data-ttu-id="bff2f-199">Руководства пользователям выполнять жесты до разработки пользовательского интерфейса читаемости — подробное описание instinctual жест.</span><span class="sxs-lookup"><span data-stu-id="bff2f-199">The way to achieve instinctual gesture is to guide users to perform gestures through the design of UI affordances.</span></span> <span data-ttu-id="bff2f-200">Например если мы рекомендуем пользователям захвата объект или точку управления с жестом сжатия два пальца, объект или точку управления необходимо небольшой.</span><span class="sxs-lookup"><span data-stu-id="bff2f-200">For example, if we encourage users to grab an object or a control point with two finger pinch, the object or the control point should be small.</span></span> <span data-ttu-id="bff2f-201">Если мы предлагаем пользователям возможность выполнять пять захвата палец, объекта или контрольная точка должно быть сравнительно большой.</span><span class="sxs-lookup"><span data-stu-id="bff2f-201">If we would like users to perform five finger grab, the object or the control point should be relatively big.</span></span> <span data-ttu-id="bff2f-202">Как кнопки, небольшая кнопка бы ограничить нажатия клавиш с одним пальцем, хотя огромные кнопки рекомендую пользователей нажать ее с их ладони.</span><span class="sxs-lookup"><span data-stu-id="bff2f-202">Similar to buttons, a tiny button would limit users to press it with a single finger, while a huge button would encourage users to press it with their palms.</span></span>
![](images/Instinctual-Gestures-720px.jpg)<br>

## <a name="symmetric-design-between-hands-and-6-dof-controllers"></a><span data-ttu-id="bff2f-203">Симметричный разработки от руки и контроллеров DoF 6</span><span class="sxs-lookup"><span data-stu-id="bff2f-203">Symmetric design between hands and 6 DoF controllers</span></span>
<span data-ttu-id="bff2f-204">Можно заметить, что теперь есть взаимодействия parallels, можно провести между руки в контроллеры AR и перемещения в виртуальной Реальности.</span><span class="sxs-lookup"><span data-stu-id="bff2f-204">You may have noticed that there are now interaction parallels we can draw between hands in AR and motion controllers in VR.</span></span> <span data-ttu-id="bff2f-205">Оба входа можно использовать для активации прямых манипуляций в соответствующих средах.</span><span class="sxs-lookup"><span data-stu-id="bff2f-205">Both inputs can be used to trigger direct manipulations in their respective environments.</span></span> <span data-ttu-id="bff2f-206">В 2 HoloLens перетаскивая с руки в works закрыть расстояние в так же, как кнопки захвата выполняет на контроллерах движения в WMR.</span><span class="sxs-lookup"><span data-stu-id="bff2f-206">In HoloLens 2, grabbing and dragging with hands at a close distance works much in the same way as the grab button does on the motion controllers in WMR.</span></span> <span data-ttu-id="bff2f-207">Это предоставляет пользователям с Знакомство взаимодействия между двумя платформами и может оказаться полезным следует вы решите размещать приложение от одного к другому.</span><span class="sxs-lookup"><span data-stu-id="bff2f-207">This provides your users with interaction familiarity between the two platforms and may prove useful should you ever decide to port your app from one to the other.</span></span>

## <a name="optimizing-with-eye-tracking"></a><span data-ttu-id="bff2f-208">Оптимизация с помощью отслеживания</span><span class="sxs-lookup"><span data-stu-id="bff2f-208">Optimizing with eye tracking</span></span>
<span data-ttu-id="bff2f-209">Непосредственной работы со почувствуют магического, если он работает должным образом, но также быстро может стать утомительным, если не удается переместить свои силы в любом больше не непреднамеренно активируя голограмма.</span><span class="sxs-lookup"><span data-stu-id="bff2f-209">Direct manipulation can feel magical if it works as intended, but can also quickly become frustrating if you can’t move your hand anywhere anymore without unintentionally triggering a hologram.</span></span>
<span data-ttu-id="bff2f-210">Отслеживания потенциально помогает лучше определить, что такое намерения пользователя.</span><span class="sxs-lookup"><span data-stu-id="bff2f-210">Eye tracking can potentially help in better identifying what the user’s intent is.</span></span> 

* <span data-ttu-id="bff2f-211">**Когда**: Уменьшите ошибочно активации обработки ответа.</span><span class="sxs-lookup"><span data-stu-id="bff2f-211">**When**: Reduce falsely triggering a manipulation response.</span></span> <span data-ttu-id="bff2f-212">Отслеживания позволяет лучше понять, что пользователь настоящее время участвует с.</span><span class="sxs-lookup"><span data-stu-id="bff2f-212">Eye tracking allows for better understanding what a user is currently engaged with.</span></span> <span data-ttu-id="bff2f-213">Например представьте, что вы читаете holographic (инструкции) текст при достижении более, чтобы скопировать вам средства работы в реальных условиях.</span><span class="sxs-lookup"><span data-stu-id="bff2f-213">For example, imagine you are reading through a holographic (instructional) text when reaching over to grab you real-world work tool.</span></span>
<span data-ttu-id="bff2f-214">Таким образом, вы случайно переместить свои силы на некоторые интерактивные holographic кнопки, вы даже не заметили перед (например, он даже за пределами пользователя поле зрения).</span><span class="sxs-lookup"><span data-stu-id="bff2f-214">By doing so, you accidently move your hand across some interactive holographic buttons that you hadn't even noticed before (maybe it even was outside of the user's Field-of-View).</span></span>
<span data-ttu-id="bff2f-215">Короче говоря: Если пользователь еще не рассматривали голограмма какое-то время, но для него обнаружено событие сенсорного ввода или коммерческих тайн, весьма вероятно, что пользователь не был вы собираетесь фактически для взаимодействия с этой голограмма.</span><span class="sxs-lookup"><span data-stu-id="bff2f-215">Long story short: If the user hasn't looked at a hologram for a while, yet a touch or grasp event has been detected for it, it is likely that the user wasn't actually intending to interact with that hologram.</span></span> 

* <span data-ttu-id="bff2f-216">**Какой из них**: Помимо адресации false положительное количество активаций, еще один пример включает в себя лучше идентификации какие голограммы взять или выполнить поиск as точку пересечения точно не может быть ясны из вашей точки зрения, особенно в том случае, если несколько голограммы расположены рядом друг другие.</span><span class="sxs-lookup"><span data-stu-id="bff2f-216">**Which one**: Aside from addressing false positive activations, another example includes better identifying which holograms to grab or poke as the precise intersection point may not be clear from your perspective especially if several holograms are positioned close to each other.</span></span> <span data-ttu-id="bff2f-217">Во время отслеживания глаза для HoloLens 2 имеет определенные ограничения о том, как точно выяснить глаз взглядом, это может по-прежнему быть весьма полезен для практически взаимодействия из-за глубины несоответствие при взаимодействии со стороны ввода.</span><span class="sxs-lookup"><span data-stu-id="bff2f-217">While eye tracking on HoloLens 2 has a certain limitation on how accurately it can determine you eye gaze, this can still be very helpful for near interactions due to depth disparity when interacting with hand input.</span></span> <span data-ttu-id="bff2f-218">Это означает, что иногда трудно определить, является ли Рука или позади голограмма, чтобы точно скопировать манипуляции мини-приложение, например.</span><span class="sxs-lookup"><span data-stu-id="bff2f-218">This means that it is sometimes difficult to determine whether your hand is behind or in front of a hologram to precisely grab a manipulation widget for example.</span></span>

 * <span data-ttu-id="bff2f-219">**Где**: Используйте сведения, что пользователь просматривает с быстрые жесты создает исключение.</span><span class="sxs-lookup"><span data-stu-id="bff2f-219">**Where to**: Use information about what a user is looking at with quick throwing gestures.</span></span> <span data-ttu-id="bff2f-220">Захватите голограмма и примерно отбросить его к вашей пункта назначения.</span><span class="sxs-lookup"><span data-stu-id="bff2f-220">Grab a hologram and roughly toss it toward your intended destination.</span></span> <span data-ttu-id="bff2f-221">Хотя это иногда может работать нормально, быстро выполнять жестами руками может привести к высокой неточные назначения.</span><span class="sxs-lookup"><span data-stu-id="bff2f-221">While this may sometimes work just fine, quickly performing hand gestures may result in highly inaccurate destinations.</span></span>
<span data-ttu-id="bff2f-222">Это где отслеживания может помочь персонального Рука генерации вектор обратно к в нужное положение.</span><span class="sxs-lookup"><span data-stu-id="bff2f-222">This is where eye tracking could help out to lean the hand throwing vector back to your intended position.</span></span>

## <a name="see-also"></a><span data-ttu-id="bff2f-223">См. также</span><span class="sxs-lookup"><span data-stu-id="bff2f-223">See also</span></span>
* [<span data-ttu-id="bff2f-224">Взглядом и фиксации</span><span class="sxs-lookup"><span data-stu-id="bff2f-224">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="bff2f-225">Точки и фиксации</span><span class="sxs-lookup"><span data-stu-id="bff2f-225">Point and commit</span></span>](point-and-commit.md)
* [<span data-ttu-id="bff2f-226">Основы взаимодействия</span><span class="sxs-lookup"><span data-stu-id="bff2f-226">Interaction fundamentals</span></span>](interaction-fundamentals.md)

