---
title: Учебники по службам речи Azure — 2. Добавление автономного режима для локального перевода речи в текст
description: Пройдите этот курс, чтобы узнать, как реализовать пакет SDK для службы распознавания речи Azure в приложении смешанной реальности.
author: jessemcculloch
ms.author: jemccull
ms.date: 06/27/2019
ms.topic: article
keywords: mixed reality, unity, tutorial, hololens
ms.openlocfilehash: 1dd6c01768ddf5dda954f50e0f7507022bd59c3b
ms.sourcegitcommit: af1602710c1ccb7ed870a491923350d387706129
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/01/2019
ms.locfileid: "68701861"
---
# <a name="2-adding-an-offline-mode-for-local-speech-to-text-translation"></a>2. Добавление автономного режима для локального перевода речи в текст

В этом руководстве мы добавим автономный режим, который позволяет выполнять локальные преобразования речи в текст, когда не удается подключиться к службе Azure. Кроме того, мы будем *имитировать* отключенное состояние.

## <a name="instructions"></a>Инструкция

1. Выберите объект Lunarcom_Base в иерархии и нажмите кнопку Добавить компонент на панели инспектора. Найдите и выберите автономное распознавание Лунарком.

![Module4Chapter2step1im](images/module4chapter2step1im.PNG)

2. Щелкните раскрывающийся список в Лунаркомоффлинерекогнизер и выберите включено. Этот проект будет работать так же, как у пользователя нет подключения. 

![Module4Chapter2step1im](images/module4chapter2step2im.PNG)

3. Теперь нажмите кнопку Воспроизведение в редакторе Unity и проверьте его. Нажмите микрофон в левом нижнем углу сцены и начните говорить. 

> [!NOTE]
> Так как мы отключены от сети, функции пробуждения слова недоступны. Вам придется физически щелкать микрофон каждый раз, когда вы хотите, чтобы распознавание речи было признано в автономном режиме. 

Ниже приведен пример того, как может выглядеть сцена.

![Module4Chapter2exampleim](images/module4chapter2exampleim.PNG)

## <a name="congratulations"></a>Поздравляем!

Автономный режим включен. Теперь, когда вы работаете в автономном режиме, вы по-прежнему можете работать над проектом с помощью Speech-SDK! 


[Следующий учебник: 3.  Добавление компонента перевода речи Azure Cognitive Services](mrlearning-speechSDK-ch3.md)

