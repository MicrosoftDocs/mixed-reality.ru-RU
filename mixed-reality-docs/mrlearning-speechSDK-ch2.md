---
title: Модуль Спичсдк с MR Learning — распознавание речи и транскрипция
description: Пройдите этот курс, чтобы узнать, как реализовать пакет SDK для службы распознавания речи Azure в приложении смешанной реальности.
author: jessemcculloch
ms.author: jemccull
ms.date: 06/27/2019
ms.topic: article
keywords: mixed reality, unity, tutorial, hololens
ms.openlocfilehash: b13b22fcdce2e7fa1319d241302b764f457aabba
ms.sourcegitcommit: b086d7a62ee0c7913aa8f66c90e9d2527f270264
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/25/2019
ms.locfileid: "68485601"
---
# <a name="2----adding-an-offline-mode-for-local-speech-to-text-translation"></a>2.    Добавление автономного режима для локального перевода речи в текст

В этом руководстве мы добавим автономный режим, который позволяет выполнять локальные преобразования речи в текст, когда не удается подключиться к службе Azure. Кроме того, мы будем *имитировать* отключенное состояние.

## <a name="instructions"></a>Инструкция

1. Выберите объект Lunarcom_Base в иерархии и нажмите кнопку Добавить компонент на панели инспектора. Найдите и выберите автономное распознавание Лунарком.

![Module4Chapter2step1im](images/module4chapter2step1im.PNG)

2. Щелкните раскрывающийся список в Лунаркомоффлинерекогнизер и выберите включено. Этот проект будет работать так же, как у пользователя нет подключения. 

![Module4Chapter2step1im](images/module4chapter2step2im.PNG)

3. Теперь нажмите кнопку Воспроизведение в редакторе Unity и проверьте его. Нажмите микрофон в левом нижнем углу сцены и начните говорить. 

> [!NOTE]
> Так как мы отключены от сети, функции пробуждения слова недоступны. Вам придется физически щелкать микрофон каждый раз, когда вы хотите, чтобы распознавание речи было признано в автономном режиме. 

Ниже приведен пример того, как может выглядеть сцена.

![Module4Chapter2exampleim](images/module4chapter2exampleim.PNG)

## <a name="congratulations"></a>Поздравляем!

Автономный режим включен. Теперь, когда вы работаете в автономном режиме, вы по-прежнему можете работать над проектом с помощью Speech-SDK! 


[Следующий учебник: 3.  Добавление компонента перевода речи Azure Cognitive Services](mrlearning-speechSDK-ch3.md)

