---
title: Точки и фиксации
description: Общие сведения о модели входной точки и фиксации
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/05/2019
ms.topic: article
keywords: Смешанной реальности, взаимодействие, проектирование
ms.openlocfilehash: e0e9c97053734ac0125fce40be7ffe9afbd2dd68
ms.sourcegitcommit: f5c1dedb3b9e29f27f627025b9e7613931a7ce18
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/27/2019
ms.locfileid: "64581314"
---
# <a name="point-and-commit"></a><span data-ttu-id="62f1f-104">Точки и фиксации</span><span class="sxs-lookup"><span data-stu-id="62f1f-104">Point and commit</span></span>
<span data-ttu-id="62f1f-105">Точки и фиксации — модель ввода позволяет пользователям целевой, выберите и манипулировать содержимое, двухмерные и трехмерные объекты на расстоянии.</span><span class="sxs-lookup"><span data-stu-id="62f1f-105">Point and commit is an input model enables users to target, select and manipulate 2D contents and 3D objects in a distance.</span></span> <span data-ttu-id="62f1f-106">Этот способ взаимодействия «Far» является интерактивной среды — в пупок и человека из которых не существовало во время их ежедневной работы с реальным миром.</span><span class="sxs-lookup"><span data-stu-id="62f1f-106">This "Far" interaction technique is a navel interactive experience that human being didn't really have during their daily interaction with the real world.</span></span> <span data-ttu-id="62f1f-107">Например в super герой фильма, Магнитооптический способен обращением и манипуляций дальней объектом через руки в расстояние, но человек не может сделать это на самом деле.</span><span class="sxs-lookup"><span data-stu-id="62f1f-107">For example, in a super hero movie, Magneto is capable of reaching out and manipulating a far object via hands in a distance, but human can't do it in reality.</span></span> <span data-ttu-id="62f1f-108">В Microsoft HoloLens (AR) и Microsoft смешанной реальности (VR) мы Оснастите пользователей магического энергии, критические физическое ограничение из реального мира не только для того, чтобы обеспечить более выгодным поведение в holographic содержимое, но для вступления взаимодействия и эффективный.</span><span class="sxs-lookup"><span data-stu-id="62f1f-108">In both Microsoft HoloLens (AR) and Microsoft Mixed Reality (VR), we equip users this magical power, breaking the physical constraint of real world not only to have delightful experience with holographic contents but to make the interaction more effective and efficient.</span></span>

## <a name="device-support"></a><span data-ttu-id="62f1f-109">Поддержка устройств</span><span class="sxs-lookup"><span data-stu-id="62f1f-109">Device support</span></span>
<table>
    <colgroup>
    <col width="40%" />
    <col width="20%" />
    <col width="20%" />
    <col width="20%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="62f1f-110"><strong>Модель ввода</strong></span><span class="sxs-lookup"><span data-stu-id="62f1f-110"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="62f1f-111"><a href="hololens-hardware-details.md"><strong>HoloLens (1-го поколения)</strong></a></span><span class="sxs-lookup"><span data-stu-id="62f1f-111"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="62f1f-112"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="62f1f-112"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="62f1f-113"><a href="immersive-headset-hardware-details.md"><strong>Иммерсивную</strong></a></span><span class="sxs-lookup"><span data-stu-id="62f1f-113"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="62f1f-114">Точки, чтобы зафиксировать (дальней стороны взаимодействия)</span><span class="sxs-lookup"><span data-stu-id="62f1f-114">Point and commit (far hand interaction)</span></span></td>
        <td><span data-ttu-id="62f1f-115">❌ Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="62f1f-115">❌ Not supported</span></span></td>
        <td><span data-ttu-id="62f1f-116">Рекомендуется ✔️</span><span class="sxs-lookup"><span data-stu-id="62f1f-116">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="62f1f-117">Рекомендуется ✔️</span><span class="sxs-lookup"><span data-stu-id="62f1f-117">✔️ Recommended</span></span></td>
    </tr>
</table>
<br>
<span data-ttu-id="62f1f-118">Точки и фиксации была одной из основных моделей ввода на 2 HoloLens, использование нового ясно сформулированные Рука системы отслеживания.</span><span class="sxs-lookup"><span data-stu-id="62f1f-118">Point and commit has been one of the primary input models on HoloLens 2, utilizing the new articulated hand tracking system.</span></span> <span data-ttu-id="62f1f-119">Этот входной модель также является основной модель ввода на иммерсивную при помощи контроллеры движения.</span><span class="sxs-lookup"><span data-stu-id="62f1f-119">This input model is also the primary input model on immersive headsets through the use of motion controllers.</span></span> <span data-ttu-id="62f1f-120">Точки, чтобы зафиксировать является модель ввода, мы советуем использовать для замены, Head, помощи и зафиксировать на HoloLens (1-го поколения).</span><span class="sxs-lookup"><span data-stu-id="62f1f-120">Point and Commit is the input model that we suggest to replace the Head Gaze and Commit on HoloLens (1st gen).</span></span> 

## <a name="hand-rays"></a><span data-ttu-id="62f1f-121">Лучи вручную</span><span class="sxs-lookup"><span data-stu-id="62f1f-121">Hand rays</span></span>
<span data-ttu-id="62f1f-122">На 2 HoloLens мы создадим неполадок в центре palm луча вручную.</span><span class="sxs-lookup"><span data-stu-id="62f1f-122">On HoloLens 2, we create a hand ray shooting out from the center of a palm.</span></span> <span data-ttu-id="62f1f-123">Рэй рассматривается как расширение вручную.</span><span class="sxs-lookup"><span data-stu-id="62f1f-123">The ray is treated as an extension of the hand.</span></span> <span data-ttu-id="62f1f-124">В конце луча, реализуя тем самым расположение, где пересекает луч с объектом hitted присоединяется курсора кольцо фигуры.</span><span class="sxs-lookup"><span data-stu-id="62f1f-124">A donut shape cursor is attached at the end of the ray to imply the location where the ray intersects with a hitted object.</span></span> <span data-ttu-id="62f1f-125">Объект, который перемещает курсор будет принимать жестовую команды от руки.</span><span class="sxs-lookup"><span data-stu-id="62f1f-125">The object that the cursor lands will receive gestural commands from the hand.</span></span> 

<span data-ttu-id="62f1f-126">Простейшие жестовую команда запускается с использованием пальцами выполнения жест касания.</span><span class="sxs-lookup"><span data-stu-id="62f1f-126">The very basic gestural command is triggered by using thumb and index finger to perform air tap gesture.</span></span> <span data-ttu-id="62f1f-127">С помощью Рэй вручную и с помощью касания для фиксации, пользователи могут активировать кнопку или гиперссылку на веб-содержимого.</span><span class="sxs-lookup"><span data-stu-id="62f1f-127">By using hand ray to point and air tap to commit, users can activate a button or a hyperlink on a web content.</span></span> <span data-ttu-id="62f1f-128">С помощью дополнительные составного жестов пользователи способны навигации веб-содержимого и управления объектами в расстояние.</span><span class="sxs-lookup"><span data-stu-id="62f1f-128">With more composite gestures, users are capable of navigating the web content and manipulating 3D objects in a distance.</span></span> <span data-ttu-id="62f1f-129">Графический дизайн луча, вручную следует также реагировать на них точки и зафиксировать состояния:</span><span class="sxs-lookup"><span data-stu-id="62f1f-129">The visual design of the hand ray should also react to point and commit states:</span></span> <br>
* <span data-ttu-id="62f1f-130">В указывающего состояние луч является тире, готового и курсор является фигурой кольцо.</span><span class="sxs-lookup"><span data-stu-id="62f1f-130">In the pointing state, the ray is dash lined, and the cursor is a donut shape.</span></span>
* <span data-ttu-id="62f1f-131">в состоянии «фиксация» луч превращается в сплошная линия, и курсор сжимается с точкой.</span><span class="sxs-lookup"><span data-stu-id="62f1f-131">in the committing state, the ray turns into a solid line, and the cursor shrinks to a dot.</span></span><br><br>
![](images/Hand-Rays-720px.jpg)<br>

## <a name="transition-between-near-and-far"></a><span data-ttu-id="62f1f-132">Переход между практически так и удаленными</span><span class="sxs-lookup"><span data-stu-id="62f1f-132">Transition between near and far</span></span>
<span data-ttu-id="62f1f-133">Вместо использования определенных жестов, например, указание с вытянутым указательным пальцем для направления луч, мы разрабатываем луч, выход из центра palm, освобождения и резервирование пять пальцев для дополнительные жестовую манипуляции.</span><span class="sxs-lookup"><span data-stu-id="62f1f-133">Instead of using specific gestures, such as pointing with index finger to direct the ray, we design the ray coming out from the center of the palm, releasing and reserving the five fingers for more gestural manipulations.</span></span> <span data-ttu-id="62f1f-134">Таким образом HoloLens 2 поддерживает только тот же набор жестами руками для взаимодействия с ближней и дальней.</span><span class="sxs-lookup"><span data-stu-id="62f1f-134">Therefore, HoloLens 2 supports exactly the same set of hand gestures for both near and far interaction.</span></span> <span data-ttu-id="62f1f-135">Нет Дополнительные учебные необходим в том случае, когда пользователи транзитной из рядом дальней взаимодействия и наоборот.</span><span class="sxs-lookup"><span data-stu-id="62f1f-135">No additional learning is needed when users transit from near to far interactions, and vice versa.</span></span> <span data-ttu-id="62f1f-136">Пользователи могут использовать же жест захвата для управления объектами на различных расстояниях.</span><span class="sxs-lookup"><span data-stu-id="62f1f-136">Users can use the same grab gesture to manipulate objects at different distances.</span></span> <span data-ttu-id="62f1f-137">Вызов лучей — автоматически и с учетом расположения на основе:</span><span class="sxs-lookup"><span data-stu-id="62f1f-137">The invocation of the rays is automatic and proximity based:</span></span> <br>
* <span data-ttu-id="62f1f-138">Если объект находится в пределах arm, достигнут расстояние (примерно 50 cm), лучей отключены автоматически поощряя практически взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="62f1f-138">when an object is within arm reached distance (roughly 50 cm), the rays are turned off automatically encouraging for near interaction.</span></span> 
* <span data-ttu-id="62f1f-139">Если объект является относительно 50 cm, включены лучей.</span><span class="sxs-lookup"><span data-stu-id="62f1f-139">When the object is farther than 50 cm, the rays are turned on.</span></span>

<span data-ttu-id="62f1f-140">Этот механизм упрощает переход плавным и легким.</span><span class="sxs-lookup"><span data-stu-id="62f1f-140">This mechanism makes the transition smooth and seamless.</span></span><br>
![](images/Transition-Between-Near-And-Far-720px.jpg)<br>

## <a name="2d-slate-interaction"></a><span data-ttu-id="62f1f-141">2D баннера взаимодействия</span><span class="sxs-lookup"><span data-stu-id="62f1f-141">2D slate interaction</span></span>
<span data-ttu-id="62f1f-142">2D Сланец является holographic содержимого 2D приложения, такие как веб-браузер для размещения контейнеров.</span><span class="sxs-lookup"><span data-stu-id="62f1f-142">A 2D slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="62f1f-143">Концепции проектирования для гораздо взаимодействия с 2D листа заключается в использовании лучи вручную и с помощью касания для фиксации.</span><span class="sxs-lookup"><span data-stu-id="62f1f-143">The design concept for far interacting with a 2D slate is to use hand rays to point and air tap to commit.</span></span><br>

<span data-ttu-id="62f1f-144">Для взаимодействия с планшета констант:</span><span class="sxs-lookup"><span data-stu-id="62f1f-144">For interacting with the slate contant:</span></span><br>

* <span data-ttu-id="62f1f-145">Пользователи могут указывать на гиперссылки и кнопки, а затем жест касания для ее активации.</span><span class="sxs-lookup"><span data-stu-id="62f1f-145">Users can point at a hyperlink or a button, then air tap to activate it.</span></span> 
* <span data-ttu-id="62f1f-146">Пользователи могут использовать одной стороны, чтобы выполнять прокрутку вверх и вниз баннера содержимое жест навигации.</span><span class="sxs-lookup"><span data-stu-id="62f1f-146">Users can use one hand to perform a navigation gesture to scroll a slate content up and down.</span></span> 
* <span data-ttu-id="62f1f-147">Для выполнения жестов навигации в zoom in и out баннера содержимое, пользователи могут использовать две руки.</span><span class="sxs-lookup"><span data-stu-id="62f1f-147">Users can use two hands to perform navigation gestures to zoom in and out the slate content.</span></span><br><br>

![](images/2D-Slate-Interaction-Far-720px.jpg)<br>

<span data-ttu-id="62f1f-148">Для управления 2D синевато самой:</span><span class="sxs-lookup"><span data-stu-id="62f1f-148">For manipulating the 2D slate itself:</span></span><br>

* <span data-ttu-id="62f1f-149">Пользователи указывают Рэй вручную в углах или по краям, чтобы отобразить ближайший affordance манипуляции.</span><span class="sxs-lookup"><span data-stu-id="62f1f-149">Users point the hand ray at the corners or edges to reveal the closest manipulation affordance.</span></span> 
* <span data-ttu-id="62f1f-150">Применяя affordance жест манипуляции, пользователей можно выполнять универсальный код масштабирования через affordance угла и можно обратное течение Сланец через edge affordance.</span><span class="sxs-lookup"><span data-stu-id="62f1f-150">By applying a manipulation gesture on the affordance, users can perform uniform scaling through the corner affordance and can reflow the slate via the edge affordance.</span></span> 
* <span data-ttu-id="62f1f-151">Применяя holobar в верхней части 2D Сланец жест манипуляции, пользователи могут переместить весь лист.</span><span class="sxs-lookup"><span data-stu-id="62f1f-151">By applying a manipulation gesture on the holobar at the top of the 2D slate, users can move the whole slate.</span></span><br>

<br>

## <a name="3d-object-manipulation"></a><span data-ttu-id="62f1f-152">Манипуляции трехмерного объекта</span><span class="sxs-lookup"><span data-stu-id="62f1f-152">3D object manipulation</span></span>
<span data-ttu-id="62f1f-153">В прямого управления для пользователей для управления трехмерный объект обработки на основе Affordance и Non-affordnace основе манипуляции двумя способами.</span><span class="sxs-lookup"><span data-stu-id="62f1f-153">In direct manipulation, there are two ways for users to manipulate 3D object, Affordance Based Manipulation and Non-affordnace Based Manipulation.</span></span> <span data-ttu-id="62f1f-154">В модели, точки и фиксации пользователи не может иметь те же задачи, через лучей вручную.</span><span class="sxs-lookup"><span data-stu-id="62f1f-154">In point and commit model, users are capable of achieving exactly the same tasks through the hand rays.</span></span> <span data-ttu-id="62f1f-155">Нет дополнительных обучения не требуется.</span><span class="sxs-lookup"><span data-stu-id="62f1f-155">No additional learning is needed.</span></span><br>

### <a name="affordance-based-manipulation"></a><span data-ttu-id="62f1f-156">На основе affordance манипуляции</span><span class="sxs-lookup"><span data-stu-id="62f1f-156">Affordance based manipulation</span></span>
<span data-ttu-id="62f1f-157">Пользователи использовать лучи руки и выявить ограничивающий прямоугольник и читаемости манипуляции.</span><span class="sxs-lookup"><span data-stu-id="62f1f-157">Users use hand rays to point and reveal the bounding box and manipulation affordances.</span></span> <span data-ttu-id="62f1f-158">Пользователи могут применять жест манипуляции в ограничивающий прямоугольник для перемещения всего объекта, на читаемости edge для поворота и coner читаемости равномерно масштабировать.</span><span class="sxs-lookup"><span data-stu-id="62f1f-158">Users can apply the manipulation gesture on the bounding box to move the whole object, on the edge affordances to rotate and on the coner affordances to scale uniformly.</span></span> <br>

![](images/3D-Object-Manipulation-Far-720px.jpg) <br>


### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="62f1f-159">Non-affordance основе манипуляции</span><span class="sxs-lookup"><span data-stu-id="62f1f-159">Non-affordance based manipulation</span></span>
<span data-ttu-id="62f1f-160">Пользователи точки с лучи вручную для отображения ограничивающего прямоугольника, а затем прямо применять манипуляции жесты на нем.</span><span class="sxs-lookup"><span data-stu-id="62f1f-160">Users point with hand rays to reveal the bounding box then directly apply manipulation gestures on it.</span></span> <span data-ttu-id="62f1f-161">С одной стороны перенос и поворот объекта связаны с движения и ориентации вручную.</span><span class="sxs-lookup"><span data-stu-id="62f1f-161">With one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="62f1f-162">С двумя руки пользователей можно перевод, масштабировать и поворачивать в соответствии с относительный движений две руки.</span><span class="sxs-lookup"><span data-stu-id="62f1f-162">With two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span><br>

<br>

## <a name="instinctual-gesturers"></a><span data-ttu-id="62f1f-163">Instinctual gesturers</span><span class="sxs-lookup"><span data-stu-id="62f1f-163">Instinctual gesturers</span></span>
<span data-ttu-id="62f1f-164">Концепция instinctual жесты для точки и фиксации синхронизирован с, для прямого управления.</span><span class="sxs-lookup"><span data-stu-id="62f1f-164">The concept of instinctual gestures for point and commit is in sync with that for direct manipulation.</span></span> <span data-ttu-id="62f1f-165">Какие жесты пользователи Предположим, что для выполнения трехмерного объекта они управлялись проектирования пользовательского интерфейса читаемости.</span><span class="sxs-lookup"><span data-stu-id="62f1f-165">What gestures users suppose to perform on a 3D object are guided by the design of UI affordances.</span></span> <span data-ttu-id="62f1f-166">Небольшой контрольной точки будет мотивировать пользователям сжатия с пальцами, то время как массивные объекты пользователей перейти с 5 палец.</span><span class="sxs-lookup"><span data-stu-id="62f1f-166">A small control point would motivate users to pinch with thumb and index finger, while a large object makes users to grab with 5 finger.</span></span>

![](images/Instinctual-Gestures-Far-720px.jpg)<br>

## <a name="symmetric-design-between-hands-and-6-dof-controller"></a><span data-ttu-id="62f1f-167">Симметричный разработки от руки и 6 DoF контроллера</span><span class="sxs-lookup"><span data-stu-id="62f1f-167">Symmetric design between hands and 6 DoF controller</span></span> 
<span data-ttu-id="62f1f-168">Во-первых концепцию модель точки и фиксации для дальней взаимодействия создается и определяется для смешанной реальности портала (MRP), где пользователи wear иммерсивных гарнитуры и взаимодействия с объектом, 3d через контроллеры движения.</span><span class="sxs-lookup"><span data-stu-id="62f1f-168">The concept of point and commit model for far interaction is firstly created and defined for the Mixed Reality Portal (MRP), where users wear an immersive headset and interact with the 3d object via motion controllers.</span></span> <span data-ttu-id="62f1f-169">Устранение неисправностей контроллеров движения out лучи для дальней объектов и указывает.</span><span class="sxs-lookup"><span data-stu-id="62f1f-169">The motion controllers shoot out rays for pointing and manipulating far objects.</span></span> <span data-ttu-id="62f1f-170">Есть кнопки на контроллерах для дальнейшего фиксации различным своим функциональным возможностям.</span><span class="sxs-lookup"><span data-stu-id="62f1f-170">There are buttons on the controllers for further committing different functionalities.</span></span> <span data-ttu-id="62f1f-171">Мы использовать модель взаимодействия лучи и вложите их в обоих руки.</span><span class="sxs-lookup"><span data-stu-id="62f1f-171">We leverage the interaction model of rays and attach them on both hands.</span></span> <span data-ttu-id="62f1f-172">При такой структуре симметричный пользователям, знакомым с MRP не требуется изучать другой способ взаимодействия далеко указывает и манипуляции при первом использовании HoloLen 2 и наоборот.</span><span class="sxs-lookup"><span data-stu-id="62f1f-172">With this symmetric design, users who are familiar with MRP won't need to learn another interaction model for far pointing and manipulation while first time using HoloLen 2, and vice versa.</span></span>    

![](images/Symmetric-Design-For-Rays-720px.jpg)<br>


## <a name="see-also"></a><span data-ttu-id="62f1f-173">См. также</span><span class="sxs-lookup"><span data-stu-id="62f1f-173">See also</span></span>
* [<span data-ttu-id="62f1f-174">Взглядом и фиксации</span><span class="sxs-lookup"><span data-stu-id="62f1f-174">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="62f1f-175">Прямые манипуляции</span><span class="sxs-lookup"><span data-stu-id="62f1f-175">Direct manipulation</span></span>](direct-manipulation.md)
* [<span data-ttu-id="62f1f-176">Основы взаимодействия</span><span class="sxs-lookup"><span data-stu-id="62f1f-176">Interaction fundamentals</span></span>](interaction-fundamentals.md)
