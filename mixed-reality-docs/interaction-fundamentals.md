---
title: Общие сведения о Многорежимные взаимодействия
description: Обзор Многорежимные взаимодействия
author: shengkait
ms.author: shengkait
ms.date: 04/11/2019
ms.topic: article
ms.localizationpriority: high
keywords: Смешанный реальность, взглядом, взглядом, предназначенные для взаимодействия, проектирования, hololens, MMR, multimodal
ms.openlocfilehash: 771ebe44dc984c9d4550638bef405810d86b8d69
ms.sourcegitcommit: 1c0fbee8fa887525af6ed92174edc42c05b25f90
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/16/2019
ms.locfileid: "65730825"
---
# <a name="introducing-instinctual-interactions"></a><span data-ttu-id="44031-104">Знакомство с instinctual взаимодействия</span><span class="sxs-lookup"><span data-stu-id="44031-104">Introducing instinctual interactions</span></span>

<span data-ttu-id="44031-105">Философии простой, instinctual взаимодействия является вовлеченным во всей платформе Microsoft смешанной реальности (MMR), от оборудования, программного обеспечения.</span><span class="sxs-lookup"><span data-stu-id="44031-105">The philosophy of simple, instinctual interactions is woven throughout the Microsoft Mixed Reality (MMR) platform, from hardware to software.</span></span>

<span data-ttu-id="44031-106">Эти instinctual взаимодействия использовать все доступные входные технологий, включая отслеживание поперек, наличии отслеживания, отслеживания и естественного языка, в моделях беспрепятственного взаимодействия Многорежимные.</span><span class="sxs-lookup"><span data-stu-id="44031-106">These instinctual interactions utilize all available input technologies, including inside-out tracking, hand tracking, eye tracking, and natural language, in seamless multimodal interaction models.</span></span> <span data-ttu-id="44031-107">Зависимости от нашим исследованиям, проектированию и разработке multimodals и не зависят от отдельных входных данных, важно при создании instinctive опыт.</span><span class="sxs-lookup"><span data-stu-id="44031-107">Based on our research, designing and developing multimodals, and not based on single inputs, is critical when creating instinctive experiences.</span></span>

<span data-ttu-id="44031-108">Моделей Instinctual взаимодействия также естественным образом выровнять на типах устройств.</span><span class="sxs-lookup"><span data-stu-id="44031-108">The Instinctual Interaction models also naturally align across device types.</span></span>  <span data-ttu-id="44031-109">К примеру дальней взаимодействие на иммерсивных гарнитура с 6 степени свободы (DoF) контроллер и дальней взаимодействия на HoloLens 2 используют те же читаемости, шаблоны и поведения.</span><span class="sxs-lookup"><span data-stu-id="44031-109">For example, far interaction on an immersive headset with a 6 degrees of freedom (DoF) controller and far interaction on a HoloLens 2 use the same affordances, patterns, and behaviors.</span></span>  <span data-ttu-id="44031-110">Не только удобна этом для разработчиков и конструкторов, но является естественным для конечных пользователей.</span><span class="sxs-lookup"><span data-stu-id="44031-110">Not only is this convenient for developers and designers, but it feels natural to end users.</span></span>


<span data-ttu-id="44031-111">Наконец, хотя мы понимаем, что существуют тысячи вступают в силу, привлекательными и магического взаимодействия в MR, мы пришли к выводу, намеренно применение модели одно взаимодействие сквозного в приложение — лучший способ обеспечить, организовать и более удобной.</span><span class="sxs-lookup"><span data-stu-id="44031-111">Lastly, while we recognize that there are thousands of effective, engaging, and magical interactions possible in MR, we have found that intentionally employing a single interaction model end to end in an application is the best way to ensure users are successful and have a great experience.</span></span>  <span data-ttu-id="44031-112">С этой целью мы включили три действия в этом руководстве взаимодействия:</span><span class="sxs-lookup"><span data-stu-id="44031-112">To that end, we've included three things in this interaction guidance:</span></span>
* <span data-ttu-id="44031-113">Мы структурировали этот о будущем три модели основного механизма взаимодействия и компонентов, а также шаблоны для каждого</span><span class="sxs-lookup"><span data-stu-id="44031-113">We've structured this guidance around the three primary interaction models and the components and patterns required for each</span></span>
* <span data-ttu-id="44031-114">Сюда включены дополнительные указания на других преимуществ, предоставляемых нашей платформы</span><span class="sxs-lookup"><span data-stu-id="44031-114">We've included supplemental guidance on other benefits that our platform provides</span></span>
* <span data-ttu-id="44031-115">Мы включили в рекомендации, помогающие выбрать модель соответствующие взаимодействия для вашего сценария</span><span class="sxs-lookup"><span data-stu-id="44031-115">We've included guidance to help select the appropriate interaction model for your scenario</span></span>

## <a name="multimodal-interaction-models"></a><span data-ttu-id="44031-116">Моделей Многорежимные взаимодействия</span><span class="sxs-lookup"><span data-stu-id="44031-116">Multimodal interaction models</span></span>

<span data-ttu-id="44031-117">На основе нашей исследований и работы с клиентами для даты, мы узнали три модели основного механизма взаимодействия, в соответствии с задачами большинство функций, смешанной реальности.</span><span class="sxs-lookup"><span data-stu-id="44031-117">Based on our research and work with customers to date, we've discovered three primary interaction models that suit the majority of Mixed Reality experiences.</span></span>  

<span data-ttu-id="44031-118">Считать эти модели взаимодействия пользователя ментальной модели для выполнения своих потоков.</span><span class="sxs-lookup"><span data-stu-id="44031-118">Think of these interaction models as the user's mental model for completing their flows.</span></span>

<span data-ttu-id="44031-119">Каждая из этих моделей взаимодействия, удобный, эффективные и может использоваться сама по себе, а все оптимизированы для набора потребности клиентов.</span><span class="sxs-lookup"><span data-stu-id="44031-119">Each of these interaction models is convenient, powerful, and usable in its own right, and all are optimized for a set of customer needs.</span></span> <span data-ttu-id="44031-120">Просмотр диаграммы ниже, для сценариев, примеры и преимущества каждой модели взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="44031-120">View the chart below, for scenarios, examples, and benefits of each interaction model.</span></span>  

<span data-ttu-id="44031-121">**Модель**</span><span class="sxs-lookup"><span data-stu-id="44031-121">**Model**</span></span> | <span data-ttu-id="44031-122">**[Руки и средства](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-and-tools)**</span><span class="sxs-lookup"><span data-stu-id="44031-122">**[Hands and Tools](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-and-tools)**</span></span> | <span data-ttu-id="44031-123">**[Автономно](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-free)**</span><span class="sxs-lookup"><span data-stu-id="44031-123">**[Hands free](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-free)**</span></span> | <span data-ttu-id="44031-124">**[Взглядом и фиксации](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-and-commit?)**</span><span class="sxs-lookup"><span data-stu-id="44031-124">**[Gaze and Commit](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-and-commit?)**</span></span>
|--------- | --------------| ------------| ---------|
<span data-ttu-id="44031-125">**Примеры сценариев**</span><span class="sxs-lookup"><span data-stu-id="44031-125">**Example Scenarios**</span></span> | <span data-ttu-id="44031-126">Трехмерные эффекты Пространственные, например пространственного макета содержимого обработки или моделирования</span><span class="sxs-lookup"><span data-stu-id="44031-126">3D spatial experiences, e.g. spatial layout and design, content manipulation, or simulation</span></span> | <span data-ttu-id="44031-127">Контекстные взаимодействия, где руки пользователя будут заняты, например на обучение, обслуживание задания</span><span class="sxs-lookup"><span data-stu-id="44031-127">Contextual experiences where a user's hands are occupied, e.g. on the-job learning, maintenance</span></span>| <span data-ttu-id="44031-128">По щелчку возможности, например, трехмерный презентаций, демонстраций</span><span class="sxs-lookup"><span data-stu-id="44031-128">Click-through experiences, e.g. 3D presentations, demos</span></span>
<span data-ttu-id="44031-129">**по размеру**</span><span class="sxs-lookup"><span data-stu-id="44031-129">**Fit**</span></span> | <span data-ttu-id="44031-130">Отлично подходят для новых пользователей, связанных wit голоса, глаз взглядом отслеживания или head.</span><span class="sxs-lookup"><span data-stu-id="44031-130">Great for new users, coupled wit voice, eye tracking or head gaze.</span></span> <span data-ttu-id="44031-131">Короткое время обучения.</span><span class="sxs-lookup"><span data-stu-id="44031-131">Low learning curve.</span></span> <span data-ttu-id="44031-132">Согласованное UX в наличии отслеживания и контроллеров DoF 6.</span><span class="sxs-lookup"><span data-stu-id="44031-132">Consistent UX across hand tracking and 6 DoF controllers.</span></span> | <span data-ttu-id="44031-133">Некоторые обучения требуется.</span><span class="sxs-lookup"><span data-stu-id="44031-133">Some learning required.</span></span> <span data-ttu-id="44031-134">Если руки — это пары, недоступны для поддержки голосовых вызовов и естественного языка</span><span class="sxs-lookup"><span data-stu-id="44031-134">If hands are unavailable pairs well with voice and natural language</span></span> | <span data-ttu-id="44031-135">Требуется обучению на HMDs, но не на мобильных устройствах.</span><span class="sxs-lookup"><span data-stu-id="44031-135">Requires training on HMDs but not on mobile.</span></span> <span data-ttu-id="44031-136">Рекомендации для контроллеров доступны лучше всего подходит для HoloLens (1-го поколения)</span><span class="sxs-lookup"><span data-stu-id="44031-136">Best for accessible controllers Best for HoloLens (1st gen)</span></span> |
<span data-ttu-id="44031-137">**Оборудование**</span><span class="sxs-lookup"><span data-stu-id="44031-137">**Hardware**</span></span> | <span data-ttu-id="44031-138">HoloLens 2 иммерсивную</span><span class="sxs-lookup"><span data-stu-id="44031-138">HoloLens 2 Immersive headsets</span></span> | <span data-ttu-id="44031-139">HoloLens HoloLens 2 (1-го поколения) иммерсивную</span><span class="sxs-lookup"><span data-stu-id="44031-139">HoloLens 2 HoloLens (1st gen) Immersive headsets</span></span> | <span data-ttu-id="44031-140">HoloLens 2 иммерсивную</span><span class="sxs-lookup"><span data-stu-id="44031-140">HoloLens 2 Immersive headsets</span></span> | <span data-ttu-id="44031-141">HoloLens HoloLens 2 (1-го поколения) иммерсивную Mobile AR</span><span class="sxs-lookup"><span data-stu-id="44031-141">HoloLens 2 HoloLens (1st gen) Immersive headsets Mobile AR</span></span> |

<span data-ttu-id="44031-142">Подробные сведения по использованию всех доступных входов, дополняющих друг друга в каждой модели взаимодействия — на страницах, выполните, а также иллюстрации и ссылки на образцы содержимого из наших MRTK Unity.</span><span class="sxs-lookup"><span data-stu-id="44031-142">Detailed information for using all available inputs seamlessly together in each interaction model is on the pages that follow, as well as illustrations and links to sample content from our Unity MRTK.</span></span>


## <a name="choose-an-interaction-model-for-your-customer"></a><span data-ttu-id="44031-143">Выберите модель взаимодействия для вашего клиента</span><span class="sxs-lookup"><span data-stu-id="44031-143">Choose an interaction model for your customer</span></span>


<span data-ttu-id="44031-144">Скорее всего у разработчиков и дизайнеров также некоторые идеи помнить видов взаимодействие, они должны иметь их пользователи.</span><span class="sxs-lookup"><span data-stu-id="44031-144">Most likely, developers and creators also already have some ideas in mind of the kinds of interaction experience they want their users to have.</span></span>
<span data-ttu-id="44031-145">Чтобы стимулировать подход, ориентированный на клиента, для разработки, мы рекомендуем следовать указанных ниже инструкций для выбора модели взаимодействия, которая оптимизирована для вашего клиента.</span><span class="sxs-lookup"><span data-stu-id="44031-145">To encourage a customer-focused approach to design, we recommend following the guidance below to select the interaction model that's optimized for your customer.</span></span>

### <a name="why-follow-this-guidance"></a><span data-ttu-id="44031-146">Почему следуйте инструкциям этого руководства?</span><span class="sxs-lookup"><span data-stu-id="44031-146">Why follow this guidance?</span></span>

* <span data-ttu-id="44031-147">Для цели и субъективные критерии, такие как физического и когнитивной усилия, intuitiveness и learnability тестируется наших моделей взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="44031-147">Our interaction models are tested for objective and subjective criteria such as physical and cognitive effort, intuitiveness, and learnability.</span></span> 
* <span data-ttu-id="44031-148">Поскольку взаимодействие отличается, звуковые и читаемости и поведение объекта может также отличаться между моделями взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="44031-148">Because interaction differs, visual and audio affordances and object behavior may also differ between the interaction models.</span></span>  
* <span data-ttu-id="44031-149">Объединение частей несколько моделей взаимодействия создает риск конкурирующих читаемости, например лучи одновременных вручную и курсора взглядом head, которые перегрузки и запутывания пользователей.</span><span class="sxs-lookup"><span data-stu-id="44031-149">Combining parts of multiple interaction models together creates the risk of competing affordances, such as simultaneous hand rays and a head-gaze cursor, which overwhelm and confuse users.</span></span>

<span data-ttu-id="44031-150">Ниже приведены некоторые примеры как оптимизировать читаемости и поведение для каждой модели взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="44031-150">Here are some examples of how affordances and behaviors are optimized for each interaction model.</span></span>  <span data-ttu-id="44031-151">Мы часто см. в разделе новых пользователей как похожие вопросы, такие как «как узнать, работает система, как узнать, что можно сделать, и как узнать, если понимать, что я только что сделал?»</span><span class="sxs-lookup"><span data-stu-id="44031-151">We often see new users as similar questions, such as "how do I know the system is working, how do I know what I can do, and how do I know if it understood what I just did?"</span></span>

<br>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="44031-152"><strong>Модель</strong></span><span class="sxs-lookup"><span data-stu-id="44031-152"><strong>Model</strong></span></span></td>
        <td><span data-ttu-id="44031-153"><strong>Как узнать, она работает?</strong></span><span class="sxs-lookup"><span data-stu-id="44031-153"><strong>How do I know it's working?</strong></span></span></td>
        <td><span data-ttu-id="44031-154"><strong>Как узнать, что можно сделать?</strong></span><span class="sxs-lookup"><span data-stu-id="44031-154"><strong>How do I know what I can do?</strong></span></span></td>
        <td><span data-ttu-id="44031-155"><strong>Как узнать, что я только что сделал?</strong></span><span class="sxs-lookup"><span data-stu-id="44031-155"><strong>How do I know what I just did?</strong></span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="44031-156"><a href="hands-and-tools.md">Руки и средства</a></span><span class="sxs-lookup"><span data-stu-id="44031-156"><a href="hands-and-tools.md">Hands and tools</a></span></span></td>
        <td><span data-ttu-id="44031-157">Я вижу mesh руки, я вижу срезах affordance или наличии / лучи контроллера.</span><span class="sxs-lookup"><span data-stu-id="44031-157">I see a hand mesh, I see a fingertip affordance or hand/ controller rays.</span></span></td>
        <td><span data-ttu-id="44031-158">Я вижу grabbable дескрипторы или отображаются, когда приближается к мою руку ограничивающий прямоугольник.</span><span class="sxs-lookup"><span data-stu-id="44031-158">I see grabbable handles or a bounding box appear when my hand is near.</span></span></td>
        <td><span data-ttu-id="44031-159">Я услышать звуковые сигналы и анимации см. в разделе о захвата и выпуска.</span><span class="sxs-lookup"><span data-stu-id="44031-159">I hear audible tones and see animations on grab and release.</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="44031-160"><a href="gaze-and-commit.md">Направление головы и фиксация</a></span><span class="sxs-lookup"><span data-stu-id="44031-160"><a href="gaze-and-commit.md">Head-gaze and commit</a></span></span></td>
        <td><span data-ttu-id="44031-161">Я вижу курсора в центре моей поле зрения.</span><span class="sxs-lookup"><span data-stu-id="44031-161">I see a cursor in the center of my field of view.</span></span></td>
        <td><span data-ttu-id="44031-162">Head взглядом курсор меняет состояние при превышении определенных объектов.</span><span class="sxs-lookup"><span data-stu-id="44031-162">The head-gaze cursor changes state when over certain objects.</span></span></td>
        <td><span data-ttu-id="44031-163">Я см. в разделе / услышать visual и звуковые подтверждений, когда действия.</span><span class="sxs-lookup"><span data-stu-id="44031-163">I see/ hear visual and audible confirmations when I take action.</span></span></td>
    </tr>   
    <tr>
        <td><span data-ttu-id="44031-164"><a href="hands-free.md">Без участия пользователя (Head взглядом и простоя)</a></span><span class="sxs-lookup"><span data-stu-id="44031-164"><a href="hands-free.md">Hands-free (Head-gaze and dwell)</a></span></span></td>
        <td><span data-ttu-id="44031-165">Я вижу курсора в центре моей поле зрения.</span><span class="sxs-lookup"><span data-stu-id="44031-165">I see a cursor in the center of my field of view.</span></span></td>
        <td><span data-ttu-id="44031-166">Я вижу индикатор хода выполнения, когда я буду распространяться элементом объекта.</span><span class="sxs-lookup"><span data-stu-id="44031-166">I see a progress indicator when I dwell on an interactable object.</span></span></td>
        <td><span data-ttu-id="44031-167">Я см. в разделе / услышать visual и звуковые подтверждений, когда действия.</span><span class="sxs-lookup"><span data-stu-id="44031-167">I see/ hear visual and audible confirmations when I take action.</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="44031-168"><a href="hands-free.md">Автоматическая (голосовые команды)</a></span><span class="sxs-lookup"><span data-stu-id="44031-168"><a href="hands-free.md">Hands-free (Voice commanding)</a></span></span></td>
        <td><span data-ttu-id="44031-169">Я вижу, что признак прослушивания и заголовки, которые показывают системе слышали.</span><span class="sxs-lookup"><span data-stu-id="44031-169">I see a listening indicator and captions that show what the system heard.</span></span></td>
        <td><span data-ttu-id="44031-170">Я получаю голосовых запросов и подсказки.</span><span class="sxs-lookup"><span data-stu-id="44031-170">I get voice prompts and hints.</span></span>  <span data-ttu-id="44031-171">Когда я говорю «что можно сказать?»</span><span class="sxs-lookup"><span data-stu-id="44031-171">When I say "what can I say?"</span></span> <span data-ttu-id="44031-172">Я вижу обратной связи.</span><span class="sxs-lookup"><span data-stu-id="44031-172">I see feedback.</span></span></td>
        <td><span data-ttu-id="44031-173">Я см. в разделе / услышать visual и звуковые подтверждений при отдадите команду, или получить устранения неоднозначности UX, при необходимости.</span><span class="sxs-lookup"><span data-stu-id="44031-173">I see/ hear visual and audible confirmations when I give a command, or get disambiguation UX when needed.</span></span></a></td>
    </tr>
</table>

### <a name="below-are-the-questions-that-weve-found-help-teams-select-an-interaction-model"></a><span data-ttu-id="44031-174">Ниже приведены вопросы, что выяснилось, что выбор команд справки модель взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="44031-174">Below are the questions that we've found help teams select an interaction model:</span></span>
 
1.  <span data-ttu-id="44031-175">Вопрос.  Хотите ли мои пользователи затронуты голограммы и манипуляций со holographic точности?</span><span class="sxs-lookup"><span data-stu-id="44031-175">Q:  Do my users want to touch holograms and perform precision holographic manipulations?</span></span><br><br>
<span data-ttu-id="44031-176">Ответ.  Если это так, ознакомьтесь с модель взаимодействия руки и средства целевая точность и манипуляции с руки или контроллеров движения.</span><span class="sxs-lookup"><span data-stu-id="44031-176">A:  If so, check out the Hands and tools interaction model for precision targeting and manipulation with hands or motion controllers.</span></span>
 
2.  <span data-ttu-id="44031-177">Вопрос.  Необходимо сохранить опускают руки, бесплатно, для реальных задач моих пользователей?</span><span class="sxs-lookup"><span data-stu-id="44031-177">Q:  Do my users need to keep their hands free, for real-world tasks?</span></span><br><br>
<span data-ttu-id="44031-178">Ответ.  Если это так, рассмотрим модель взаимодействия без участия пользователя, то есть отличный вариант без участия пользователя при взаимодействии на основе взглядом и голоса.</span><span class="sxs-lookup"><span data-stu-id="44031-178">A:  If so, take a look at the Hands-free interaction model, which provides a great hands-free experience through gaze- and voice-based interactions.</span></span>
 
3.  <span data-ttu-id="44031-179">Вопрос.  У пользователей есть времени на изучение взаимодействия для моего приложения смешанной реальности или этого требуется взаимодействие с наименьшей кривой обучения возможно?</span><span class="sxs-lookup"><span data-stu-id="44031-179">Q:  Do my users have time to learn interactions for my mixed reality application, or do they need the interactions with the lowest learning curve possible?</span></span><br><br>
<span data-ttu-id="44031-180">Ответ.  Мы советуем использовать модель руки и средства, наименьшей кривой обучения и интуитивно взаимодействий, до тех пор, пока пользователи имеют возможность использовать опускают руки к взаимодействию.</span><span class="sxs-lookup"><span data-stu-id="44031-180">A:  We recommend the Hands and Tools model for the lowest learning curve and most intuitive interactions, as long as users are able to use their hands for interaction.</span></span>
 
4.  <span data-ttu-id="44031-181">Вопрос.  Следует ли пользователи использовать контроллеры движения для команды и управление</span><span class="sxs-lookup"><span data-stu-id="44031-181">Q:  Do my users use motion controllers for pointing and manipulation?</span></span><br><br>
<span data-ttu-id="44031-182">Ответ.  Модель руки и средств включает все рекомендации для удобной с контроллерами движения.</span><span class="sxs-lookup"><span data-stu-id="44031-182">A:  The Hands and tools model includes all guidance for a great experience with motion controllers.</span></span>
 
5.  <span data-ttu-id="44031-183">Вопрос.  Следует ли пользователи использовать контроллеру специальных возможностей или общие контроллер Bluetooth, например clicker?</span><span class="sxs-lookup"><span data-stu-id="44031-183">Q:  Do my users use an accessibility controller or a common Bluetooth controller, such as a clicker?</span></span><br><br>
<span data-ttu-id="44031-184">Ответ.  Мы рекомендуем взглядом Head, чтобы зафиксировать модели для всех контроллеров не отслеживаются.</span><span class="sxs-lookup"><span data-stu-id="44031-184">A:  We recommend the Head-gaze and Commit model for all non-tracked controllers.</span></span>  <span data-ttu-id="44031-185">Она разработана, чтобы разрешить пользователю проходить весь опыт простой механику «целевой объект и фиксации».</span><span class="sxs-lookup"><span data-stu-id="44031-185">It's designed to allow a user to traverse an entire experience with a simple "target and commit" mechanic.</span></span> 
 
6.  <span data-ttu-id="44031-186">Вопрос. Дальнейших действий, Мои пользователи только посредством интерфейса, «щелкая» (например, в, 3d слайд-шоу среду), в отличие от перехода плотных макеты элементов управления пользовательского интерфейса?</span><span class="sxs-lookup"><span data-stu-id="44031-186">Q: Do my users only progress through an experience by "clicking through" (for example in a 3d slideshow-like environment), as opposed to navigating dense layouts of UI controls?</span></span><br><br>
<span data-ttu-id="44031-187">Ответ.  Если пользователям не нужно управлять массу пользовательского интерфейса, взглядом Head, чтобы зафиксировать предлагает стремящихся параметр, где пользователям не нужно беспокоиться о целевой настройке.</span><span class="sxs-lookup"><span data-stu-id="44031-187">A:  If users do not need to control a lot of UI, Head-gaze and commit offers a learnable option where users do not have to worry about targeting.</span></span> 
 
7.  <span data-ttu-id="44031-188">Вопрос.  Следует ли пользователи использовать оба HoloLens (1-го поколения) и HoloLens 2 / Windows Иммерсивных (VR гарнитуры)</span><span class="sxs-lookup"><span data-stu-id="44031-188">Q:  Do my users use both HoloLens (1st gen) and HoloLens 2/ Windows Immersive (VR headsets)</span></span><br><br>
<span data-ttu-id="44031-189">Ответ.  Поскольку модель взаимодействия для HoloLens взглядом Head, чтобы зафиксировать (1-го поколения), мы рекомендуем creators, осуществляющих поддержку HoloLens (1-го поколения) использовать Head взглядом и фиксации для любой функции или режимы, могут столкнуться пользователи на HoloLens (1-го поколения) гарнитуры.</span><span class="sxs-lookup"><span data-stu-id="44031-189">A:  Since Head-gaze and commit is the interaction model for HoloLens (1st gen), we recommend that creators who support HoloLens (1st gen) use Head-gaze and commit for any features or modes that users may experience on a HoloLens (1st gen) headset.</span></span>  <span data-ttu-id="44031-190">См. ниже в разделе на *переход моделей взаимодействия* Дополнительные сведения о внесении удобной для нескольких поколений HoloLens.</span><span class="sxs-lookup"><span data-stu-id="44031-190">Please see the next section below on *Transitioning interaction models* for details on making a great experience for multiple HoloLens generations.</span></span>
 
8.  <span data-ttu-id="44031-191">Вопрос. Как насчет для пользователей, которые обычно мобильных (охватывающий большое пространство или перемещать между пробелы), и пользователи, как правило, выполняются в одном месте?</span><span class="sxs-lookup"><span data-stu-id="44031-191">Q: What about for users who are generally mobile (covering a large space or moving between spaces), versus users who tend to work in a single space?</span></span><br><br>
<span data-ttu-id="44031-192">Ответ.  Любой модели взаимодействия будет работать для этих пользователей.</span><span class="sxs-lookup"><span data-stu-id="44031-192">A:  Any of the interaction models will work for these users.</span></span>  

> [!NOTE]
> <span data-ttu-id="44031-193">Дополнительные рекомендации для разработки приложений для [ожидается в ближайшее время](index.md#news-and-notes).</span><span class="sxs-lookup"><span data-stu-id="44031-193">More guidance specific to app design [coming soon](index.md#news-and-notes).</span></span>


## <a name="transition-interaction-models"></a><span data-ttu-id="44031-194">Переход моделей взаимодействия</span><span class="sxs-lookup"><span data-stu-id="44031-194">Transition interaction models</span></span>
<span data-ttu-id="44031-195">Также встречаются случаи, где, используя несколько моделей взаимодействия может потребоваться вашего варианта использования.</span><span class="sxs-lookup"><span data-stu-id="44031-195">There are also cases where your use cases may require that utilizing more than one interaction model.</span></span>  <span data-ttu-id="44031-196">Например приложения «создание потока» использует модель взаимодействия руки и средства, но вы хотите использовать режим без участия пользователя для технических специалистов.</span><span class="sxs-lookup"><span data-stu-id="44031-196">For example, your app's "creation flow" utilizes the Hands and tools interaction model, but you want to employ a Hands-free mode for field technicians.</span></span>  

<span data-ttu-id="44031-197">Если для работы требуется несколько моделей взаимодействия, мы обнаружили, что многие пользователи могут возникнуть сложности, перевод из одной модели в другой — особенно для конечных пользователей, незнакомых с MR.</span><span class="sxs-lookup"><span data-stu-id="44031-197">If your experience does require multiple interaction models, we've found that many end users may encounter difficulty transitioning from one model to another -- especially end users who are new to MR.</span></span>

> [!Note]
> <span data-ttu-id="44031-198">Чтобы помочь руководство проектировщикам и разработчикам через варианты, которые могут быть сложны в MR, мы работаем над Дополнительные рекомендации по использованию нескольких моделей взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="44031-198">To help guide designers and developers through choices that can be difficult in MR, we're working on more guidance for using multiple interaction models.</span></span>
 

## <a name="see-also"></a><span data-ttu-id="44031-199">См. также</span><span class="sxs-lookup"><span data-stu-id="44031-199">See also</span></span>
* [<span data-ttu-id="44031-200">Направление головы и фиксация</span><span class="sxs-lookup"><span data-stu-id="44031-200">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="44031-201">Непосредственное манипулирование</span><span class="sxs-lookup"><span data-stu-id="44031-201">Direct manipulation</span></span>](direct-manipulation.md)
* [<span data-ttu-id="44031-202">Наведение и фиксация</span><span class="sxs-lookup"><span data-stu-id="44031-202">Point and commit</span></span>](point-and-commit.md)
* [<span data-ttu-id="44031-203">Нацеливание взглядом</span><span class="sxs-lookup"><span data-stu-id="44031-203">Gaze targeting</span></span>](gaze-targeting.md)
* [<span data-ttu-id="44031-204">Жесты</span><span class="sxs-lookup"><span data-stu-id="44031-204">Gestures</span></span>](gestures.md)
* [<span data-ttu-id="44031-205">Проектирование голосового взаимодействия</span><span class="sxs-lookup"><span data-stu-id="44031-205">Voice design</span></span>](voice-design.md)
* [<span data-ttu-id="44031-206">Контроллеры движения</span><span class="sxs-lookup"><span data-stu-id="44031-206">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="44031-207">Проектирование пространственного звука</span><span class="sxs-lookup"><span data-stu-id="44031-207">Spatial sound design</span></span>](spatial-sound-design.md)
* [<span data-ttu-id="44031-208">Проектирование пространственного сопоставления</span><span class="sxs-lookup"><span data-stu-id="44031-208">Spatial mapping design</span></span>](spatial-mapping-design.md)
* [<span data-ttu-id="44031-209">Комфорт</span><span class="sxs-lookup"><span data-stu-id="44031-209">Comfort</span></span>](comfort.md)
