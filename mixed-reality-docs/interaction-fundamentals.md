---
title: Общие сведения о Многорежимные взаимодействия
description: Обзор Многорежимные взаимодействия
author: shengkait
ms.author: shengkait
ms.date: 04/11/2019
ms.topic: article
ms.localizationpriority: high
keywords: Смешанный реальность, взглядом, взглядом, предназначенные для взаимодействия, проектирования, hololens, MMR, multimodal
ms.openlocfilehash: 9d0e639d7474c7e8728282acfa8d288cfeec7043
ms.sourcegitcommit: c20563b8195c0c374a927b96708d958b127ffc8f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/21/2019
ms.locfileid: "65974907"
---
# <a name="introducing-instinctual-interactions"></a>Знакомство с instinctual взаимодействия

Философии простой, instinctual взаимодействия является вовлеченным во всей платформе Microsoft смешанной реальности (MMR), от оборудования, программного обеспечения.

Эти instinctual взаимодействия использовать все доступные входные технологий, включая отслеживание поперек, наличии отслеживания, отслеживания и естественного языка, в моделях беспрепятственного взаимодействия Многорежимные. Зависимости от нашим исследованиям, проектированию и разработке multimodals и не зависят от отдельных входных данных, важно при создании instinctive опыт.

Моделей Instinctual взаимодействия также естественным образом выровнять на типах устройств.  К примеру дальней взаимодействие на иммерсивных гарнитура с 6 степени свободы (DoF) контроллер и дальней взаимодействия на HoloLens 2 используют те же читаемости, шаблоны и поведения.  Не только удобна этом для разработчиков и конструкторов, но является естественным для конечных пользователей.


Наконец, хотя мы понимаем, что существуют тысячи вступают в силу, привлекательными и магического взаимодействия в MR, мы пришли к выводу, намеренно применение модели одно взаимодействие сквозного в приложение — лучший способ обеспечить, организовать и более удобной.  С этой целью мы включили три действия в этом руководстве взаимодействия:
* Мы структурировали этот о будущем три модели основного механизма взаимодействия и компонентов, а также шаблоны для каждого
* Сюда включены дополнительные указания на других преимуществ, предоставляемых нашей платформы
* Мы включили в рекомендации, помогающие выбрать модель соответствующие взаимодействия для вашего сценария

## <a name="multimodal-interaction-models"></a>Моделей Многорежимные взаимодействия

На основе нашей исследований и работы с клиентами для даты, мы узнали три модели основного механизма взаимодействия, в соответствии с задачами большинство функций, смешанной реальности.  

Считать эти модели взаимодействия пользователя ментальной модели для выполнения своих потоков.

Каждая из этих моделей взаимодействия, удобный, эффективные и может использоваться сама по себе, а все оптимизированы для набора потребности клиентов. Просмотр диаграммы ниже, для сценариев, примеры и преимущества каждой модели взаимодействия.  

**Модель** | **[Руки и средства](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-and-tools)** | **[Автономно](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-free)** | **[Взглядом и фиксации](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-and-commit?)**
|--------- | --------------| ------------| ---------|
**Примеры сценариев** | Трехмерные эффекты Пространственные, например пространственного макета содержимого обработки или моделирования | Контекстные взаимодействия, где руки пользователя будут заняты, например на обучение, обслуживание задания| По щелчку возможности, например, трехмерный презентаций, демонстраций
**по размеру** | Отлично подходят для новых пользователей, связанных wit голоса, глаз взглядом отслеживания или head. Короткое время обучения. Согласованное UX в наличии отслеживания и контроллеров DoF 6. | Некоторые обучения требуется. Если руки — это пары, недоступны для поддержки голосовых вызовов и естественного языка | Требуется обучению на HMDs, но не на мобильных устройствах. Рекомендации для контроллеров доступны лучше всего подходит для HoloLens (1-го поколения) |
**Оборудование** | HoloLens 2 иммерсивную | HoloLens HoloLens 2 (1-го поколения) иммерсивную | HoloLens 2 иммерсивную | HoloLens HoloLens 2 (1-го поколения) иммерсивную Mobile AR |

Подробные сведения по использованию всех доступных входов, дополняющих друг друга в каждой модели взаимодействия — на страницах, выполните, а также иллюстрации и ссылки на образцы содержимого из наших MRTK Unity.


## <a name="choose-an-interaction-model-for-your-customer"></a>Выберите модель взаимодействия для вашего клиента


Скорее всего у разработчиков и дизайнеров также некоторые идеи помнить видов взаимодействие, они должны иметь их пользователи.
Чтобы стимулировать подход, ориентированный на клиента, для разработки, мы рекомендуем следовать указанных ниже инструкций для выбора модели взаимодействия, которая оптимизирована для вашего клиента.

### <a name="why-follow-this-guidance"></a>Почему следуйте инструкциям этого руководства?

* Для цели и субъективные критерии, такие как физического и когнитивной усилия, intuitiveness и learnability тестируется наших моделей взаимодействия. 
* Поскольку взаимодействие отличается, звуковые и читаемости и поведение объекта может также отличаться между моделями взаимодействия.  
* Объединение частей несколько моделей взаимодействия создает риск конкурирующих читаемости, например лучи одновременных вручную и курсора взглядом head, которые перегрузки и запутывания пользователей.

Ниже приведены некоторые примеры как оптимизировать читаемости и поведение для каждой модели взаимодействия.  Мы часто см. в разделе новых пользователей как похожие вопросы, такие как «как узнать, работает система, как узнать, что можно сделать, и как узнать, если понимать, что я только что сделал?»

<br>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>Модель</strong></td>
        <td><strong>Как узнать, она работает?</strong></td>
        <td><strong>Как узнать, что можно сделать?</strong></td>
        <td><strong>Как узнать, что я только что сделал?</strong></td>
    </tr>
    <tr>
        <td><a href="hands-and-tools.md">Руки и средства</a></td>
        <td>Я вижу mesh руки, я вижу срезах affordance или наличии / лучи контроллера.</td>
        <td>Я вижу grabbable дескрипторы или отображаются, когда приближается к мою руку ограничивающий прямоугольник.</td>
        <td>Я услышать звуковые сигналы и анимации см. в разделе о захвата и выпуска.</td>
    </tr>
    <tr>
        <td><a href="gaze-and-commit.md">Направление головы и фиксация</a></td>
        <td>Я вижу курсора в центре моей поле зрения.</td>
        <td>Head взглядом курсор меняет состояние при превышении определенных объектов.</td>
        <td>Я см. в разделе / услышать visual и звуковые подтверждений, когда действия.</td>
    </tr>   
    <tr>
        <td><a href="hands-free.md">Без участия пользователя (Head взглядом и простоя)</a></td>
        <td>Я вижу курсора в центре моей поле зрения.</td>
        <td>Я вижу индикатор хода выполнения, когда я буду распространяться элементом объекта.</td>
        <td>Я см. в разделе / услышать visual и звуковые подтверждений, когда действия.</td>
    </tr>
    <tr>
        <td><a href="hands-free.md">Автоматическая (голосовые команды)</a></td>
        <td>Я вижу, что признак прослушивания и заголовки, которые показывают системе слышали.</td>
        <td>Я получаю голосовых запросов и подсказки.  Когда я говорю «что можно сказать?» Я вижу обратной связи.</td>
        <td>Я см. в разделе / услышать visual и звуковые подтверждений при отдадите команду, или получить устранения неоднозначности UX, при необходимости.</a></td>
    </tr>
</table>

### <a name="below-are-the-questions-that-weve-found-help-teams-select-an-interaction-model"></a>Ниже приведены вопросы, что выяснилось, что выбор команд справки модель взаимодействия.
 
1.  Вопрос.  Хотите ли мои пользователи затронуты голограммы и манипуляций со holographic точности?<br><br>
Ответ.  Если это так, ознакомьтесь с модель взаимодействия руки и средства целевая точность и манипуляции с руки или контроллеров движения.
 
2.  Вопрос.  Необходимо сохранить опускают руки, бесплатно, для реальных задач моих пользователей?<br><br>
Ответ.  Если это так, рассмотрим модель взаимодействия без участия пользователя, то есть отличный вариант без участия пользователя при взаимодействии на основе взглядом и голоса.
 
3.  Вопрос.  У пользователей есть времени на изучение взаимодействия для моего приложения смешанной реальности или этого требуется взаимодействие с наименьшей кривой обучения возможно?<br><br>
Ответ.  Мы советуем использовать модель руки и средства, наименьшей кривой обучения и интуитивно взаимодействий, до тех пор, пока пользователи имеют возможность использовать опускают руки к взаимодействию.
 
4.  Вопрос.  Следует ли пользователи использовать контроллеры движения для команды и управление<br><br>
Ответ.  Модель руки и средств включает все рекомендации для удобной с контроллерами движения.
 
5.  Вопрос.  Следует ли пользователи использовать контроллеру специальных возможностей или общие контроллер Bluetooth, например clicker?<br><br>
Ответ.  Мы рекомендуем взглядом Head, чтобы зафиксировать модели для всех контроллеров не отслеживаются.  Она разработана, чтобы разрешить пользователю проходить весь опыт простой механику «целевой объект и фиксации». 
 
6.  Вопрос. Дальнейших действий, Мои пользователи только посредством интерфейса, «щелкая» (например, в, 3d слайд-шоу среду), в отличие от перехода плотных макеты элементов управления пользовательского интерфейса?<br><br>
Ответ.  Если пользователям не нужно управлять массу пользовательского интерфейса, взглядом Head, чтобы зафиксировать предлагает стремящихся параметр, где пользователям не нужно беспокоиться о целевой настройке. 
 
7.  Вопрос.  Следует ли пользователи использовать оба HoloLens (1-го поколения) и HoloLens 2 / Windows Иммерсивных (VR гарнитуры)<br><br>
Ответ.  Поскольку модель взаимодействия для HoloLens взглядом Head, чтобы зафиксировать (1-го поколения), мы рекомендуем creators, осуществляющих поддержку HoloLens (1-го поколения) использовать Head взглядом и фиксации для любой функции или режимы, могут столкнуться пользователи на HoloLens (1-го поколения) гарнитуры.  См. ниже в разделе на *переход моделей взаимодействия* Дополнительные сведения о внесении удобной для нескольких поколений HoloLens.
 
8.  Вопрос. Как насчет для пользователей, которые обычно мобильных (охватывающий большое пространство или перемещать между пробелы), и пользователи, как правило, выполняются в одном месте?<br><br>
Ответ.  Любой модели взаимодействия будет работать для этих пользователей.  

> [!NOTE]
> Дополнительные рекомендации для разработки приложений для [ожидается в ближайшее время](index.md#news-and-notes).


## <a name="transition-interaction-models"></a>Переход моделей взаимодействия
Также встречаются случаи, где, используя несколько моделей взаимодействия может потребоваться вашего варианта использования.  Например приложения «создание потока» использует модель взаимодействия руки и средства, но вы хотите использовать режим без участия пользователя для технических специалистов.  

Если для работы требуется несколько моделей взаимодействия, мы обнаружили, что многие пользователи могут возникнуть сложности, перевод из одной модели в другой — особенно для конечных пользователей, незнакомых с MR.

> [!Note]
> Чтобы помочь руководство проектировщикам и разработчикам через варианты, которые могут быть сложны в MR, мы работаем над Дополнительные рекомендации по использованию нескольких моделей взаимодействия.
 

## <a name="see-also"></a>См. также
* [Направление головы и фиксация](gaze-and-commit.md)
* [Направление головы и остановка](gaze-and-dwell.md)
* [Непосредственное манипулирование с использованием рук](direct-manipulation.md)
* [Наведение и фиксация с использованием рук](point-and-commit.md)
* [Жесты](gestures.md)
* [Голосовые команды](voice-design.md)
* [Контроллеры движения](motion-controllers.md)
* [Проектирование пространственного звука](spatial-sound-design.md)
* [Проектирование пространственного сопоставления](spatial-mapping-design.md)
* [Комфорт](comfort.md)

